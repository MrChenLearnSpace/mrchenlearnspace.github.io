{"meta":{"title":"浪子之心","subtitle":"","description":"MrChen Bolg","author":"Jack Chen","url":"https://mrchenlearnspace.github.io","root":"/"},"pages":[{"title":"categories","date":"2014-12-22T04:39:04.000Z","updated":"2021-11-01T08:11:41.958Z","comments":true,"path":"categories/index.html","permalink":"https://mrchenlearnspace.github.io/categories/index.html","excerpt":"","text":""},{"title":"search","date":"2014-12-22T04:39:04.000Z","updated":"2021-11-01T12:38:13.524Z","comments":true,"path":"search/index.html","permalink":"https://mrchenlearnspace.github.io/search/index.html","excerpt":"","text":""},{"title":"about","date":"2021-11-01T07:43:01.000Z","updated":"2021-11-01T07:44:41.191Z","comments":true,"path":"about/index.html","permalink":"https://mrchenlearnspace.github.io/about/index.html","excerpt":"","text":""},{"title":"tags","date":"2014-12-22T04:39:04.000Z","updated":"2021-11-01T07:26:33.243Z","comments":true,"path":"tags/index.html","permalink":"https://mrchenlearnspace.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"ml-agent学习记录","slug":"ml-agent学习记录","date":"2023-12-29T15:38:45.000Z","updated":"2024-01-06T15:08:00.150Z","comments":true,"path":"2023/12/29/ml-agent学习记录/","link":"","permalink":"https://mrchenlearnspace.github.io/2023/12/29/ml-agent%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/","excerpt":"","text":"环境装gpu加cuda，略，b站有安装视频 原理强化学习是观察（observation）到决定（decision）到行动（action）到奖励（reward）后循环反馈到观察的过程。 代理制作流程构建Agent新建的脚本要继承于Agent 加入观察参数123456public override void CollectObservations(VectorSensor sensor) &#123; sensor.AddObservation(transform.position); foreach (Transform target in targets) &#123; sensor.AddObservation(target.position); &#125;&#125; Space Size：这是观察空间或动作空间的大小。对于观察空间，它是智能体每次观察到的信息的维度。对于动作空间，它是智能体可以执行的动作的数量或类型。 Stacked Vectors：这是一个参数，用于指定智能体在每次决策时应该考虑多少个连续的观察。例如，如果Stacked Vectors设置为3，那么智能体在做出决策时，会考虑当前的观察以及前两个观察。这可以帮助智能体理解观察之间的时间关系，例如物体的运动方向和速度。其中Space Size和塞入的观察参数大小相关 行动下一步123456789101112131415public override void OnActionReceived(ActionBuffers actions) &#123; float moveX = actions.ContinuousActions[0]; float moveY = actions.ContinuousActions[1]; //print(new Vector3(moveX, 0, moveY)); transform.position += new Vector3(moveX, 0, moveY) * speed; for(int i=0;i&lt;targets.Count;i++) &#123; float tempDistant = Vector3.Distance(targets[i].position, transform.position); if (tempDistant &lt; distants[i]) AddReward(0.001f); else AddReward(-0.0005f); distants[i] = tempDistant; &#125; &#125; 获取下一步行动的参数 重置训练场景123456789public override void OnEpisodeBegin() &#123; distants.Clear(); transform.position = RandomPosition(); foreach (Transform t in targets) &#123; t.position= RandomPosition(); distants.Add(Vector3.Distance(t.position, transform.position)); &#125; SetReward(1);&#125; 手动控制ai（可选）12345public override void Heuristic(in ActionBuffers actionsOut) &#123; ActionSegment&lt;float&gt; continuousAction = actionsOut.ContinuousActions; continuousAction[0] = Input.GetAxisRaw(&quot;Horizontal&quot;); continuousAction[1] = Input.GetAxisRaw(&quot;Vertical&quot;);&#125; 重点记得加入脚本Decision Request卡了很久没动就是忘记挂这个组件了，，”Decision Requester”组件是用来控制智能体决策频率的一个组件。 “Decision Requester”组件有一个”Decision Period”参数，它指定了智能体应该多久做一次决策。例如，如果”Decision Period”设置为5，那么智能体每5个步骤会做一次决策。 在智能体不做决策的步骤中，它会重复执行上一次的动作。这可以减少智能体需要做决策的次数，从而提高训练速度。 注意，”Decision Requester”组件只在训练时有效。在推理（即使用训练好的模型）时，智能体会在每个步骤都做决策。 附件激活conda环境1conda activate 环境名 训练ml-agentBasic.yaml训练参数，run2文件夹 1mlagents-learn Basic.yaml --run-id=run2 --train --force 查看训练数据1tensorboard --logdir=results //result可递归文件夹下","categories":[{"name":"Unity","slug":"Unity","permalink":"https://mrchenlearnspace.github.io/categories/Unity/"}],"tags":[{"name":"强化学习","slug":"强化学习","permalink":"https://mrchenlearnspace.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"}]},{"title":"正则表达式","slug":"正则表达式","date":"2023-01-06T15:38:45.000Z","updated":"2024-01-06T15:02:50.264Z","comments":true,"path":"2023/01/06/正则表达式/","link":"","permalink":"https://mrchenlearnspace.github.io/2023/01/06/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/","excerpt":"","text":"语法更多细节查看正则表达式 – 语法 | 菜鸟教程 (runoob.com) 限定符ab+c + 号代表前面的字符（b）必须至少出现一次（1次或多次）ab*c *号代表前面的字符（b）可以不出现，也可以出现一次或者多次（0次、或1次、或多次） ab?c ?问号代表前面的字符(b)最多只可以出现一次（0次或1次) {n} n 是一个非负整数。匹配确定的 n 次。例如，o{2} 不能匹配 “Bob” 中的 o，但是能匹配 “food” 中的两个 o。 {n,} n 是一个非负整数。至少匹配n 次。例如，o{2,} 不能匹配 “Bob” 中的 o，但能匹配 “foooood” 中的所有 o。o{1,} 等价于 o+。o{0,} 则等价于 **o***。 {n,m} m 和 n 均为非负整数，其中 n &lt;&#x3D; m。最少匹配 n 次且最多匹配 m 次。例如，o{1,3} 将匹配 “fooooood” 中的前三个 o。o{0,1} 等价于 **o?**。请注意在逗号和两个数之间不能有空格。 普通字符[ABC] 匹配 […] 中的所有字符，例如 [aeiou] 匹配字符串 “gtaobao” 中所有的 e o u a 字母。 [^ABC] 匹配除了 […] 中字符的所有字符 [A-Z] [A-Z] 表示一个区间，匹配所有大写字母，[a-z] 表示所有小写字母。 . 匹配除换行符（\\n、\\r）之外的任何单个字符。 [\\s\\S] 匹配所有。\\s 是匹配所有空白符，包括换行，\\S 非空白符，不包括换行。 \\w 匹配字母、数字、下划线。等价于 [A-Za-z0-9_]。 \\d 匹配任意一个阿拉伯数字（0 到 9）。等价于 [0-9] 使用 [\\d\\w\\s] 定位符^ 匹配输入字符串的开始位置，除非在方括号表达式中使用，当该符号在方括号表达式中使用时，表示不接受该方括号表达式中的字符集合。要匹配 ^ 字符本身，请使用 ^ $ 匹配输入字符串的结尾位置。如果设置了 RegExp 对象的 Multiline 属性，则 $ 也匹配 ‘\\n’ 或 ‘\\r’。要匹配 $ 字符本身，请使用 $。","categories":[{"name":"编程","slug":"编程","permalink":"https://mrchenlearnspace.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"正则表达式","slug":"正则表达式","permalink":"https://mrchenlearnspace.github.io/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"}]},{"title":"MongoDB增删改查","slug":"MongoDB增删改查","date":"2022-12-29T15:38:45.000Z","updated":"2024-01-06T15:02:40.253Z","comments":true,"path":"2022/12/29/MongoDB增删改查/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/12/29/MongoDB%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/","excerpt":"","text":"使用MongoDB Driver它是 MongoDB 的官方驱动程序，提供了在 .NET 中操作 MongoDB 的功能。在Nuget包管理器中下载即可，其他编译器找到相关链接库部分就行。 此下示例均采用同步模式，并只更新一个。多个操作时将One改成Many。 已 查找为例，实现异步。 1234567891011121314//写在Mongo类里面的异步函数public async void FindAsync() &#123; FilterDefinition&lt;BsonDocument&gt; filterDefinition = Builders&lt;BsonDocument&gt;.Filter.Eq(&quot;HP&quot;, 50); var documents = await collection.FindAsync(filterDefinition); foreach (var document in documents.ToEnumerable()) &#123; Console.WriteLine($&quot;HP: &#123;document[&quot;HP&quot;]&#125;, atk: &#123;document[&quot;atk&quot;]&#125;&quot;); &#125;&#125;//Main函数执行Mongo mongo = new Mongo();mongo.FindAsync(); Connect Database12MongoClient client = new MongoClient(&quot;mongodb://127.0.0.1:27017&quot;);IMongoDatabase mongo = client.GetDatabase(&quot;DatabaseName&quot;); Insert Data12345678910//获得集合 IMongoCollection&lt;BsonDocument&gt; collection = mongo.GetCollection&lt;BsonDocument&gt;(&quot;player&quot;);BsonDocument filter = new BsonDocument &#123;//abc是字符串string &#123; &quot;id&quot;,&quot;12345&quot;&#125;, &#123;&quot;data&quot;,abc &#125;, &#123; &quot;ip&quot;,&quot;127.0.0.1&quot;&#125;&#125;;collection.InsertOne(filter); Delete Data12345//寻找相关数据FilterDefinition&lt;BsonDocument&gt; file = Builders&lt;BsonDocument&gt;.Filter.Eq(&quot;id&quot;, &quot;12345&quot;);collection.DeleteOne(file);//一个collection.DeleteMany(file);//全部 Update Data123456789// 创建筛选器定义FilterDefinition&lt;BsonDocument&gt; filter = Builders&lt;BsonDocument&gt;.Filter.Eq(&quot;name&quot;, &quot;John&quot;);// 创建更新器定义UpdateDefinition&lt;BsonDocument&gt; update = Builders&lt;BsonDocument&gt;.Update.Set(&quot;age&quot;, 30).Set(&quot;ip&quot;, &quot;127.0.0.1&quot;);// 更新集合中的文档UpdateResult result = await collection.UpdateManyAsync(filter, update);collection.UpdateMany(filter, update); Check Data12345678910111213//选择条件 FilterDefinition&lt;BsonDocument&gt; filterDefinition = Builders&lt;BsonDocument&gt;.Filter.Where( x =&gt; x[&quot;_id&quot;] == id &amp;&amp; x[&quot;pw&quot;] == pw); FilterDefinition&lt;BsonDocument&gt; file = Builders&lt;BsonDocument&gt;.Filter.Eq(&quot;id&quot;, &quot;12345&quot;); //寻找全部 List&lt;BsonDocument&gt; list = collection.Find(file).ToList();//打印全部 foreach (var doc in list) &#123; Console.WriteLine(doc); &#125;//转化为相关变量list[0][&quot;data&quot;].ToString() 查找相关条件的数量12FilterDefinition&lt;BsonDocument&gt; file = Builders&lt;BsonDocument&gt;.Filter.Eq(&quot;id&quot;, &quot;12345&quot;);int count=collection.CountDocuments(findDefinition) 更新整个实体类12FilterDefinition&lt;BsonDocument&gt; file = Builders&lt;BsonDocument&gt;.Filter.Eq(&quot;id&quot;, &quot;12345&quot;);collection.ReplaceOne(filterDefinition, app);//app为要更新的文档","categories":[{"name":"数据库","slug":"数据库","permalink":"https://mrchenlearnspace.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"https://mrchenlearnspace.github.io/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"}]},{"title":"Unity资源导入","slug":"Unity资源导入","date":"2022-12-29T15:38:45.000Z","updated":"2024-01-06T15:08:26.714Z","comments":true,"path":"2022/12/29/Unity资源导入/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/12/29/Unity%E8%B5%84%E6%BA%90%E5%AF%BC%E5%85%A5/","excerpt":"","text":"编辑器在Unity编辑器中引用磁盘文件可以使用 UnityEditor.AssetDatabase 类。该类提供了一些静态方法，可以从磁盘文件中加载资源。 下面是一些常用的加载磁盘文件的方法： ImportAsset(): 从磁盘文件中导入资源到 Unity 工程中。 LoadAssetAtPath(): 从磁盘文件中加载指定路径的资源。 例如，要从磁盘文件中加载名为 “MyAsset.png” 的图片资源，可以使用下面的代码： 1234using UnityEditor;Texture2D myAsset = AssetDatabase.LoadAssetAtPath&lt;Texture2D&gt;(&quot;Assets/MyAsset.png&quot;); 还可以使用 AssetDatabase.ImportAsset 从文件系统导入资源到Unity工程中,返回的是包含资源的路径的字符串数组 1234using UnityEditor;string[] importedAssets = AssetDatabase.ImportAsset(&quot;path/to/MyAsset.png&quot;); 运行中使用ab包导入使用C#文件流","categories":[{"name":"Unity","slug":"Unity","permalink":"https://mrchenlearnspace.github.io/categories/Unity/"}],"tags":[{"name":"资源导入","slug":"资源导入","permalink":"https://mrchenlearnspace.github.io/tags/%E8%B5%84%E6%BA%90%E5%AF%BC%E5%85%A5/"}]},{"title":"游戏服务器学习","slug":"游戏服务器学习","date":"2022-11-06T09:38:45.000Z","updated":"2022-12-29T16:05:09.829Z","comments":true,"path":"2022/11/06/游戏服务器学习/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/11/06/%E6%B8%B8%E6%88%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"游戏大厅棋牌类大厅 MMORPG大厅 大厅功能（1）服务器启动，等待客户端连入 （2）维护一个当前所有连入的客户端的数据列表，数据内容包含IP地址，名字等。 （3）如果客户端创建了一个游戏服务(房间)，则把该游戏服务加入到一个列表中，并向其他客户端刷新列表数据,触发该客户端成为游戏的主机。（4）当有客户端选择加入某个游戏服务时,帮助它连接到主机。 （5）维护当前所有游戏服务的参加游戏人数、游戏是否已经开始等相关信息，这些信息由服务器向建立服务的主机玩家获取。（6）当一场游戏结束后，服务器从主机玩家那里获取游戏结果和分数等信息，并更新排行榜。 服务器热更当引用无依赖的库Dll生成库代码 123456789using System;namespace ClassLibrary1 &#123; public class Class1 &#123; public void add() &#123; Console.WriteLine(&quot;uuuuuuuuu&quot;); &#125; &#125;&#125; 服务器部分CodeLoader.cs 12345678910111213141516171819202122232425using System;using System.Collections.Generic;using System.IO;using System.Reflection;using System.Runtime.Loader;using System.Text;namespace MMONetworkServer &#123; class CodeLoader &#123; AssemblyLoadContext assemblyLoadContext; Assembly hotfix; public void Reload() &#123; assemblyLoadContext?.Unload(); GC.Collect(); assemblyLoadContext = new AssemblyLoadContext(&quot;ClassLibrary1&quot;, true); byte[] dllBytes = File.ReadAllBytes(@&quot;F:\\project\\VSProject\\ClassLibrary1\\bin\\Debug\\netcoreapp3.1\\ClassLibrary1.dll&quot;);//加载dll byte[] pdbBytes = File.ReadAllBytes(@&quot;F:\\project\\VSProject\\ClassLibrary1\\bin\\Debug\\netcoreapp3.1\\ClassLibrary1.pdb&quot;);//加载pdb hotfix = assemblyLoadContext.LoadFromStream(new MemoryStream(dllBytes), new MemoryStream(pdbBytes)); object obj = hotfix.CreateInstance(&quot;ClassLibrary1.Class1&quot;); MethodInfo mm = obj.GetType().GetMethod(&quot;add&quot;); mm.Invoke(obj, null); &#125; &#125;&#125; Main.cs 12345678910111213141516171819using System;using System.IO;using System.Reflection;using System.Runtime.Loader;namespace MMONetworkServer &#123; class Program &#123; static void Main(string[] args) &#123; CodeLoader codeLoader = new CodeLoader(); while(true) &#123; Console.ReadLine(); codeLoader.Reload(); &#125; &#125; &#125;&#125; 运行后修改add函数然后生成新的dll，让main重载。 运用到游戏，思路逻辑写入热更项目中，非热更部分做好接口，通过反射创建实例。 思路2让热更项目依赖于总项目，然后总项目调用热更新部分时使用反射来获取相关实例。CodeLoader.cs 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152using System;using System.Collections.Generic;using System.IO;using System.Reflection;using System.Runtime.Loader;using System.Text;namespace MMONetworkServer.Core &#123; public class CodeLoader &#123; AssemblyLoadContext assemblyLoadContext; Assembly hotfix; Dictionary&lt;string, object&gt; hotfixInstance = new Dictionary&lt;string, object&gt;(); public static CodeLoader instance ; public CodeLoader() &#123; instance = this; &#125; public static CodeLoader GetInstance() &#123; return instance; &#125; public void Reload() &#123; hotfixInstance.Clear(); assemblyLoadContext?.Unload(); GC.Collect(); assemblyLoadContext = new AssemblyLoadContext(&quot;ClassLibrary1&quot;, true); byte[] dllBytes = File.ReadAllBytes(@&quot;F:\\project\\VSProject\\ClassLibrary1\\bin\\Debug\\netcoreapp3.1\\ClassLibrary1.dll&quot;);//加载dll byte[] pdbBytes = File.ReadAllBytes(@&quot;F:\\project\\VSProject\\ClassLibrary1\\bin\\Debug\\netcoreapp3.1\\ClassLibrary1.pdb&quot;);//加载pdb hotfix = assemblyLoadContext.LoadFromStream(new MemoryStream(dllBytes), new MemoryStream(pdbBytes)); //object obj = hotfix.CreateInstance(&quot;ClassLibrary1.Class1&quot;); //MethodInfo mm = obj.GetType().GetMethod(&quot;add&quot;); //mm.Invoke(obj, null); foreach(Type type in hotfix.GetTypes()) &#123; object instance = Activator.CreateInstance(type); hotfixInstance.Add(type.FullName, instance); Console.WriteLine(type.FullName); &#125; &#125; public object Find(string className) &#123; return hotfixInstance[className]; &#125; public void FindFunRun(string className,string funName,object[] objs) &#123; MethodInfo mm = Find(className).GetType().GetMethod(funName); mm.Invoke(Find(className), objs); &#125; &#125;&#125; 当总项目使用热更部分时 1234567891011121314151617181920212223242526272829private void HandleMsg(Conn conn, ProtocolBase protoBase) &#123; string name = protoBase.GetName(); string methodName = &quot;Msg&quot; + name; //连接协议分发 if (conn.player == null || name == &quot;HeatBeat&quot; || name == &quot;Logout&quot;) &#123; MethodInfo mm = CodeLoader.GetInstance().Find(&quot;MMONetworkServer.Logic.HandleConnMsg&quot;).GetType().GetMethod(methodName); if (mm == null) &#123; string str = &quot;[警告]HandleMsg没有处理连接方法 &quot;; Console.WriteLine(str + methodName); return; &#125; Object[] obj = new object[] &#123; conn, protoBase &#125;; Console.WriteLine(&quot;[处理连接消息]&quot; + conn.GetAdress() + &quot; :&quot; + name); mm.Invoke(CodeLoader.GetInstance().Find(&quot;MMONetworkServer.Logic.HandleConnMsg&quot;), obj); &#125; //角色协议分发 else &#123; MethodInfo mm = CodeLoader.GetInstance().Find(&quot;MMONetworkServer.Logic.HandlePlayerMsg&quot;).GetType().GetMethod(methodName); if (mm == null) &#123; string str = &quot;[警告]HandleMsg没有处理玩家方法&quot;; Console.WriteLine(str + methodName); return; &#125; Object[] obj = new object[] &#123; conn.player, protoBase &#125;; Console.WriteLine(&quot;[处理玩家消息]&quot; + conn.player.id + &quot; :&quot; + name); mm.Invoke(CodeLoader.GetInstance().Find(&quot;MMONetworkServer.Logic.HandlePlayerMsg&quot;), obj); &#125;&#125; 事件部分因为依赖于总项目所以能直接编译。 对于反射部分的优化使用委托来完成。学习渠道参考文章 性能测试 反射12345678//HandleConnMsgMethodInfo mm = CodeLoader.GetInstance().Find(&quot;MMONetworkServer.Logic.HandleConnMsg&quot;).GetType().GetMethod(methodName);Object[] obj = new object[] &#123; conn, protoBase &#125;;mm.Invoke(CodeLoader.GetInstance().Find(&quot;ServerLoginHotfix.HandleConnMsg&quot;), obj);//HandlePlayerMsgMethodInfo mm = CodeLoader.GetInstance().Find(&quot;MMONetworkServer.Logic.HandlePlayerMsg&quot;).GetType().GetMethod(methodName);Object[] obj = new object[] &#123; conn.player, protoBase &#125;;Console.WriteLine(&quot;[处理玩家消息]&quot; + conn.player.id + &quot; :&quot; + name); 委托12345678//HandleConnMsgMethodInfo mm = CodeLoader.GetInstance().Find(&quot;MMONetworkServer.Logic.HandleConnMsg&quot;).GetType().GetMethod(methodName);Action&lt;Conn, ProtocolBase&gt; updateDel = (Action&lt;Conn,ProtocolBase&gt;)Delegate.CreateDelegate(typeof(Action&lt;Conn, ProtocolBase&gt;), null, mm);updateDel(conn, protoBase);//HandlePlayerMsgMethodInfo mm = CodeLoader.GetInstance().Find(&quot;MMONetworkServer.Logic.HandleConnMsg&quot;).GetType().GetMethod(methodName);Action&lt;IPlayer, ProtocolBase&gt; updateDel = (Action&lt;IPlayer, ProtocolBase&gt;)Delegate.CreateDelegate(typeof(Action&lt;IPlayer, ProtocolBase&gt;), null, mm);updateDel(conn.player, protoBase); 比较运行速度虽然上面参考文章上写着委托比反射快，但我测试数据如下 反射 委托 [处理玩家消息] Time: 00:00:00.188 3370 [处理玩家消息] Time: 00:00:00.188 6885 [处理玩家消息] Time: 00:00:00.022 5805 [处理玩家消息] Time: 00:00:00.023 2066 [处理玩家消息] Time: 00:00:00.010 5767 [处理玩家消息] Time: 00:00:00.006 4742 [处理玩家消息] Time: 00:00:00.000 7305 [处理玩家消息] Time: 00:00:00.000 8893 [处理玩家消息] Time: 00:00:00.005 2011 [处理玩家消息] Time: 00:00:00.005 4224 [处理玩家消息] Time: 00:00:00.000 6916 [处理玩家消息] Time: 00:00:00.000 7680 可能是因为我在codeloader读取数据集时将所有类进行了实例化，因此加快了反射的速度。 内存开销委托会比反射造成内存开销小，因为舍去了将运行参数装箱拆箱的过程，减少了内存gc。 热更类的变化 委托方法调用方法及方法内使用的变量和参数的逻辑类将进行静态处理否则将会委托绑定不到具体对象。例如 12345678910public partial class HandleConnMsg &#123; static HandlePlayerEvent handlePlayerEvent = new HandlePlayerEvent(); static LogicManager logicManager; public static void MsgHeatBeat(Conn conn, ProtocolBase protoBase) &#123; conn.lastTickTime = Sys.GetTimeStamp(); Console.WriteLine(&quot;[更新心跳时间]&quot; + conn.GetAdress()); &#125;&#125; 委托的具体参数一定要一致，不能为某个类的子类，否则会委托与具体函数签名不一致。 12345public partial class HandlePlayerMsg &#123; public static void MsgWWWW(IPlayer iplayer, ProtocolBase protoBase) &#123; Console.WriteLine(&quot;wwwwwww&quot;); &#125;&#125; ​ 反射可以直接写为player，但委托要与委托变量一致 数据库Mysql数据库二进制文件的方式在Mysql存储二进制数据那一栏选Blob 12345string formatStr = &quot;update player set data =@data,ip =&#x27;&#123;0&#125;&#x27; where id = &#x27;&#123;1&#125;&#x27;;&quot;;string cmdStr = string.Format(formatStr,ip, id);MySqlCommand cmd = new MySqlCommand(cmdStr, sqlConn);cmd.Parameters.Add(&quot;@data&quot;, MySqlDbType.Blob);cmd.Parameters[0].Value = playerStream; playerStream为二进制数据文件","categories":[{"name":"游戏","slug":"游戏","permalink":"https://mrchenlearnspace.github.io/categories/%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"https://mrchenlearnspace.github.io/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"}]},{"title":"网络部分知识开发和应用","slug":"网络部分知识开发和应用","date":"2022-10-15T09:38:45.000Z","updated":"2022-11-30T12:10:20.112Z","comments":true,"path":"2022/10/15/网络部分知识开发和应用/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/10/15/%E7%BD%91%E7%BB%9C%E9%83%A8%E5%88%86%E7%9F%A5%E8%AF%86%E5%BC%80%E5%8F%91%E5%92%8C%E5%BA%94%E7%94%A8/","excerpt":"","text":"网络模型socket结构 iocp（Input&#x2F;output completion port）SocketAPI输入&#x2F;输出完成端口，常常使用在windows系统中，采用异步的方式对每个socket进行监听和接收。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364 public void Start(string host, int port) &#123; timer.Elapsed += new System.Timers.ElapsedEventHandler(HandleMainTimer); timer.AutoReset = false; timer.Enabled = true; conns = new Conn[maxConn]; for (int i = 0; i &lt; maxConn; i++) &#123; conns[i] = new Conn(); &#125; listenfd = new Socket(AddressFamily.InterNetwork, SocketType.Stream, ProtocolType.Tcp); IPAddress ipAdr = IPAddress.Parse(host); IPEndPoint ipEp = new IPEndPoint(ipAdr, port); listenfd.Bind(ipEp); listenfd.Listen(maxConn); listenfd.BeginAccept(AcceptCb, null); Console.WriteLine (&quot;[服务器]启动成功&quot;);&#125; private void AcceptCb(IAsyncResult ar) &#123; Socket socket = listenfd.EndAccept(ar); try &#123; //接收客户端 int index = NewIndex(); if (index &lt; 0) &#123; socket.Close(); Console.WriteLine(&quot;[警告]连接已满&quot;); &#125; else &#123; Conn conn = conns[index]; conn.Init(socket); string host = conn.GetAdress(); Console.WriteLine(&quot;客户端连接:[&quot; + host + &quot;] conn池ID:&quot; + index); conn.socket.BeginReceive(conn.readBuff, conn.buffCount, conn.BuffRemain(), SocketFlags.None, ReciveCb, conn);//接收的同时调用ReciveCb回调函数 &#125; listenfd.BeginAccept(AcceptCb, null);//再次调用AcceprCb回调函数 &#125; catch (Exception e) &#123; Console.WriteLine(&quot;AccpetCb 失败:&quot; + e.Message); &#125;&#125;private void ReciveCb(IAsyncResult ar) &#123; Conn conn = (Conn)ar.AsyncState;//这个AsyncState就是上面那个BeginRecive函数里面最后一个参数 lock (conn) &#123; try &#123; int count = conn.socket.EndReceive(ar);//返回接收的字节数 //没有信息就关闭 if (count &lt;= 0) &#123; Console.WriteLine(&quot;收到[&quot; + conn.GetAdress() + &quot;] 断开连接&quot;); conn.Close(); return; &#125; conn.buffCount += count; ProcessData(conn); //继续接收 conn.socket.BeginReceive(conn.readBuff, conn.buffCount, conn.BuffRemain(), SocketFlags.None, ReciveCb, conn); &#125; catch (Exception e) &#123; Console.WriteLine(&quot;Recive失败&quot; + e.Message); &#125; &#125;&#125; 缺点异步操作可能会产生死锁等线程问题 状态检测PollPoll函数采用同步循环的方式进行监听 123456789if(socket有可读数据）socket.Receive() if(socket缓冲区可写）socket. Send () if(socket发生程序）错误处理 服务器实现 123456789初始化listenfd初始化clients列表while(true)&#123; if(listenfd可读） Accept; for(遍历clien七s列表） ｛ if（这个客户端可读） 消息处理; &#125;&#125; 具体实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374static Socket listenfd;//客户端Socket及状态信息static Dictionary&lt;Socket, ClientState&gt; clients = new Dictionary&lt;Socket, ClientState&gt;();public static void Main(string[] args) &#123; //Socket listenfd = new Socket(AddressFamily.InterNetwork, SocketType.Stream, ProtocolType.Tcp); //Bind IPAddress ipAdr = IPAddress.Parse(&quot;l27.0.0.l&quot;); IPEndPoint ipEp = new IPEndPoint(ipAdr, 8888); listenfd.Bind(ipEp); //Listen listenfd.Listen(0); Console.WriteLine(&quot; （服务器］启动成功&quot;); //主循环 while (true) &#123; //检查listenfd if (listenfd.Poll(0, SelectMode.SelectRead)) &#123; ReadListenfd(listenfd); &#125; //检查clientfd foreach (ClientState s in clients.Values) &#123; Socket clientfd = s.socket; if (clientfd.Poll(0, SelectMode.SelectRead)) &#123; if (!ReadClientfd(clientfd)) break; &#125; //防止CPU占用过高 System.Threading.Thread.Sleep(1); &#125; &#125;&#125;public static void ReadListenfd(Socket listenfd) &#123; Console.WriteLine(&quot;Accept&quot;); Socket clientfd = listenfd.Accept(); ClientState state = new ClientState(); state.socket = clientfd; clients.Add(clientfd, state);&#125;//读取 Clientfdpublic static bool ReadClientfd(Socket clientfd) &#123; ClientState state = clients[clientfd]; //接收 int count = 0; try &#123; count = clientfd.Receive(state.readBuff); &#125; catch (SocketException ex) &#123; clientfd.Close(); clients.Remove(clientfd); Console.WriteLine(&quot;Receive SocketExcep七ion &quot; + ex.ToString()); return false; &#125; //客户端关闭 if (count == 0) &#123; clientfd.Close(); clients.Remove(clientfd); Console.WriteLine(&quot;Socket Close&quot;); return false; &#125; //广播 string recvStr = System.Text.Encoding.Default.GetString(state.readBuff, 0, count); Console.WriteLine(&quot;Receive&quot; + recvStr); string sendStr = clientfd.RemoteEndPoint.ToString() + &quot;:&quot; + recvStr; byte[] sendBytes = System.Text.Encoding.Default.GetBytes(sendStr); foreach (ClientState cs in clients.Values) &#123; cs.socket.Send(sendBytes); &#125; return true;&#125; 注意 在主循环最后涸用了System.Threading. Thread.Sleep(I)， 让程序挂起1毫秒， 这样做的目的是避免死循环， 让 CPU 有个短暂的喘息时间。 ReadClientfd会返回true或false, 返回false表示该客户端断开（收到长度为0的数据）。 由于客户端断开后，ReadClientfd会删除clients列表中对应的客户端信息， 导致clients列表改变， 而ReadClientfd又是在foreach (ClientState s in clients.Values)的循环中被调用的， clients列表变化会导致遍历失败， 因此程序在检测到客户端关闭后将退出foreach循环。 是将 Poll 的超时时间设置为 0, 程序不会有任何等待。 如果设置较长的超时时间，服务端将无法及时处理多个客户端同时连接的情况。 当然 ， 这样设置也会导致程序的CPU占用率很高。缺点cpu占用率过高多路复用SelectSelect函数同时检测多个Socket的状态 在设性要监听的Socket列表后 ， 如果有一个（或多个）Socket可读 （或可写 ， 或发生错误信息）， 那就返同这些可读的 Socket, 如果没有可读的 ， 那就阻塞 12345678910111213141516171819202122232425262728293031323334353637static Socket listenfd;//客户端 Socket及状态信息static Dictionary&lt;Socket, ClientState&gt; clients = new Dictionary&lt;Socket, Clientpublic static void Main(string[] args) &#123; //Socket listenfd = new Socket(AddressFamily.InterNetwork, SocketType.Stream, Proto //Bind IPAddress ipAdr = IPAddress.Parse(&quot;l27.0.0.l&quot;); IPEndPoint ipEp = new IPEndPoint(ipAdr, 8888); listenfd.Bind(ipEp); //Listen listenfd.Listen(0); Console.WriteLine(&quot;［服务器］启动成功&quot;); //checkRead List&lt;Socket&gt; checkRead = new List&lt;Socket&gt;(); //主循环 while (true) &#123; //填充 checkRead列表 checkRead.Clear(); checkRead.Add(listenfd); foreach (ClientState s in clients.Values) &#123; checkRead.Add(s.socket); //select Socket.Select(checkRead, null, null, 1000); //检查可读对象 foreach (Socket s in checkRead) &#123; if (s == listenfd) &#123; ReadListenfd(s); &#125; else &#123; ReadClientfd(s); &#125; &#125; &#125; &#125;&#125; 过程服务端使用主循环结构 while(true){…} ， 不断地调用 Select 检测 Socket 状态， 其步骤如下： 将监听 Socket (listenfd) 和客户端 Socket （遍历 clients 列表）添加到待检测 Socket可读状态的列表 checkList 中。 调用 Select, 程序中设置超时时间为 1 秒， 若 l 秒内没有任何可读信息， Select 方法将 checkList 列表变成空列表， 然后返回。 对 Select 处理后的每个 Socket 做处理， 如果监听 Socket (listenfd) 可读， 说明有客户端连接， 需凋用 Accept。 如果客户端 Socket 可读， 说明客户端发送了消息（或关闭）， 将消息广播给所有客户端适用空间由于程序在 Update 中不停地检测数据， 性能较差。 商业上为了做到性能上的极致， 大多使用异步（或使用多线程模拟异步程序）。解决粘包问题的方法长度信息法长度信息法是指在每个数据包前面加上长度信息。 每次接收到数据后 ， 先读取表示长度的字节 ， 如果缓冲区的数据长度大千要取的字节数， 则取出相应的字节 ， 否则等待下一次数据接收。 固定长度法固定一个长度发送消息时多余部分用其他字符填充 结束符号法在消息最后加一个特殊字符 大端小端问题来自于平台的不同导致高地址和低地址的顺序不同 相反则是大端模式，常用的X86结构是小端模式 ， 很多的ARM、 DSP都为小端模式， 但KEIL CS I则为大端模式 ， 有些 ARM 处理器还可以由硬件来选择是大端模式还是小端模式。 也就是说市面上的手机有些采用大端模式， 有些采用小端模式 解决方案采用Reverse统一顺序。 1234if(!BitConverter.IsLittleEndian)&#123; Debug.Log(&quot;[Send] Reverse lenBytes&quot;); lenBytes.Reverse();&#125; 123456789101112//int16时Int16 bodyLength = (short)((readBuff[1] &lt;&lt;8) | readBuff[O]);//int32时Int32 bodyLength =readBuff[O]; for(int i=1;i&lt;4;i++)&#123; bodyLength = (readBuff[i]&lt;&lt;(8*i))|bodyLength ;&#125; BytesArray用来储存发送和接收的数据结构。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119using System;public class ByteArray &#123; //默认大小 const int DEFAULT_SIZE = 1024; //初始大小 int initSize = 0; //缓冲区 public byte[] bytes; //读写位置 public int readIdx = 0; public int writeIdx = 0; //容量 private int capacity = 0; //剩余空间 public int remain &#123; get &#123; return capacity-writeIdx; &#125;&#125; //数据长度 public int length &#123; get &#123; return writeIdx-readIdx; &#125;&#125; //构造函数 public ByteArray(int size = DEFAULT_SIZE)&#123; bytes = new byte[size]; capacity = size; initSize = size; readIdx = 0; writeIdx = 0; &#125; //构造函数 public ByteArray(byte[] defaultBytes)&#123; bytes = defaultBytes; capacity = defaultBytes.Length; initSize = defaultBytes.Length; readIdx = 0; writeIdx = defaultBytes.Length; &#125; //重设尺寸 public void ReSize(int size)&#123; if(size &lt; length) return; if(size &lt; initSize) return; int n = 1; while(n&lt;size) n*=2; capacity = n; byte[] newBytes = new byte[capacity]; Array.Copy(bytes, readIdx, newBytes, 0, writeIdx-readIdx); bytes = newBytes; writeIdx = length; readIdx = 0; &#125; //写入数据 public int Write(byte[] bs, int offset, int count)&#123; if(remain &lt; count)&#123; ReSize(length + count); &#125; Array.Copy(bs, offset, bytes, writeIdx, count); writeIdx+=count; return count; &#125; //读取数据 public int Read(byte[] bs, int offset, int count)&#123; count = Math.Min(count, length); Array.Copy(bytes, 0, bs, offset, count); readIdx+=count; CheckAndMoveBytes(); return count; &#125; //检查并移动数据 public void CheckAndMoveBytes()&#123; if(length &lt; 8)&#123; MoveBytes(); &#125; &#125; //移动数据 public void MoveBytes()&#123; Array.Copy(bytes, readIdx, bytes, 0, length); writeIdx = length; readIdx = 0; &#125; //读取Int16 public Int16 ReadInt16()&#123; if(length &lt; 2) return 0; Int16 ret = BitConverter.ToInt16(bytes, readIdx); readIdx += 2; CheckAndMoveBytes(); return ret; &#125; //读取Int32 public Int32 ReadInt32()&#123; if(length &lt; 4) return 0; Int32 ret = BitConverter.ToInt32(bytes, readIdx); readIdx += 4; CheckAndMoveBytes(); return ret; &#125; //打印缓冲区 public override string ToString()&#123; return BitConverter.ToString(bytes, readIdx, length); &#125; //打印调试信息 public string Debug()&#123; return string.Format(&quot;readIdx(&#123;0&#125;) writeIdx(&#123;1&#125;) bytes(&#123;2&#125;)&quot;, readIdx, writeIdx, BitConverter.ToString(bytes, 0, capacity) ); &#125;&#125; 异步处理参数如下这是客户端部分，当具体到服务器应该去除静态 123456789101112131415161718192021222324//定义套接字 static Socket socket; //接收缓冲区 static ByteArray readBuff; //写入队列 static Queue&lt;ByteArray&gt; writeQueue; //是否正在连接 static bool isConnecting = false; //是否正在关闭 static bool isClosing = false; //消息列表 static List&lt;MsgBase&gt; msgList = new List&lt;MsgBase&gt;(); //消息列表长度 static int msgCount = 0; //每一次Update处理的消息量 readonly static int MAX_MESSAGE_FIRE = 10; //是否启用心跳 public static bool isUsePing = true; //心跳间隔时间 public static int pingInterval = 30; //上一次发送PING的时间 static float lastPingTime = 0; //上一次收到PONG的时间 static float lastPongTime = 0; 异步连接引用致Unity网络游戏实战第二版 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788//连接public static void Connect(string ip, int port)&#123; //状态判断 if(socket!=null &amp;&amp; socket.Connected)&#123; Debug.Log(&quot;Connect fail, already connected!&quot;); return; &#125; if(isConnecting)&#123; Debug.Log(&quot;Connect fail, isConnecting&quot;); return; &#125; //初始化成员 InitState(); //参数设置 socket.NoDelay = true; //Connect isConnecting = true; socket.BeginConnect(ip, port, ConnectCallback, socket);&#125;//初始化状态private static void InitState()&#123; //Socket socket = new Socket(AddressFamily.InterNetwork, SocketType.Stream, ProtocolType.Tcp); //接收缓冲区 readBuff = new ByteArray(); //写入队列 writeQueue = new Queue&lt;ByteArray&gt;(); //是否正在连接 isConnecting = false; //是否正在关闭 isClosing = false; //消息列表 msgList = new List&lt;MsgBase&gt;(); //消息列表长度 msgCount = 0; //上一次发送PING的时间 lastPingTime = Time.time; //上一次收到PONG的时间 lastPongTime = Time.time; //监听PONG协议 if(!msgListeners.ContainsKey(&quot;MsgPong&quot;))&#123; AddMsgListener(&quot;MsgPong&quot;, OnMsgPong); &#125;&#125;//Connect回调private static void ConnectCallback(IAsyncResult ar)&#123; try&#123; Socket socket = (Socket) ar.AsyncState; socket.EndConnect(ar); Debug.Log(&quot;Socket Connect Succ &quot;); FireEvent(NetEvent.ConnectSucc,&quot;&quot;); isConnecting = false; //开始接收 socket.BeginReceive( readBuff.bytes, readBuff.writeIdx, readBuff.remain, 0, ReceiveCallback, socket); &#125; catch (SocketException ex)&#123; Debug.Log(&quot;Socket Connect fail &quot; + ex.ToString()); FireEvent(NetEvent.ConnectFail, ex.ToString()); isConnecting = false; &#125;&#125; //关闭连接public static void Close()&#123; //状态判断 if(socket==null || !socket.Connected)&#123; return; &#125; if(isConnecting)&#123; return; &#125; //还有数据在发送 if(writeQueue.Count &gt; 0)&#123; isClosing = true; &#125; //没有数据在发送 else&#123; socket.Close(); FireEvent(NetEvent.Close, &quot;&quot;); &#125; &#125; 异步发送引用致Unity网络游戏实战第二版 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273//发送数据public static void Send(MsgBase msg) &#123; //状态判断 if(socket==null || !socket.Connected)&#123; return; &#125; if(isConnecting)&#123; return; &#125; if(isClosing)&#123; return; &#125; //数据编码 #带修改用linq改进 byte[] nameBytes = MsgBase.EncodeName(msg); byte[] bodyBytes = MsgBase.Encode(msg); int len = nameBytes.Length + bodyBytes.Length; byte[] sendBytes = new byte[2+len]; //组装长度 sendBytes[0] = (byte)(len%256); sendBytes[1] = (byte)(len/256); //组装名字 Array.Copy(nameBytes, 0, sendBytes, 2, nameBytes.Length); //组装消息体 Array.Copy(bodyBytes, 0, sendBytes, 2+nameBytes.Length, bodyBytes.Length); //写入队列 /#带修改用linq改进 ByteArray ba = new ByteArray(sendBytes); int count = 0; //writeQueue的长度 lock(writeQueue)&#123; writeQueue.Enqueue(ba); count = writeQueue.Count; &#125; //send if(count == 1)&#123; socket.BeginSend(sendBytes, 0, sendBytes.Length, 0, SendCallback, socket); &#125;&#125;//Send回调public static void SendCallback(IAsyncResult ar)&#123; //获取state、EndSend的处理 Socket socket = (Socket) ar.AsyncState; //状态判断 if(socket == null || !socket.Connected)&#123; return; &#125; //EndSend int count = socket.EndSend(ar); //获取写入队列第一条数据 ByteArray ba; lock(writeQueue)&#123; ba = writeQueue.First(); &#125; //完整发送 ba.readIdx+=count; if(ba.length == 0)&#123; lock(writeQueue)&#123; writeQueue.Dequeue(); ba = writeQueue.First(); &#125; &#125; //继续发送 if(ba != null)&#123; socket.BeginSend(ba.bytes, ba.readIdx, ba.length, 0, SendCallback, socket); &#125; //正在关闭 else if(isClosing) &#123; socket.Close(); &#125; &#125; 异步接收引用致Unity网络游戏实战第二版 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758//Receive回调public static void ReceiveCallback(IAsyncResult ar)&#123; try &#123; Socket socket = (Socket) ar.AsyncState; //获取接收数据长度 int count = socket.EndReceive(ar); readBuff.writeIdx+=count; //处理二进制消息 OnReceiveData(); //继续接收数据 if(readBuff.remain &lt; 8)&#123; readBuff.MoveBytes(); readBuff.ReSize(readBuff.length*2); &#125; socket.BeginReceive( readBuff.bytes, readBuff.writeIdx, readBuff.remain, 0, ReceiveCallback, socket); &#125; catch (SocketException ex)&#123; Debug.Log(&quot;Socket Receive fail&quot; + ex.ToString()); &#125;&#125;//数据处理public static void OnReceiveData()&#123; //消息长度 if(readBuff.length &lt;= 2) &#123; return; &#125; //获取消息体长度 int readIdx = readBuff.readIdx; byte[] bytes =readBuff.bytes; Int16 bodyLength = (Int16)((bytes[readIdx+1] &lt;&lt; 8 )| bytes[readIdx]); if(readBuff.length &lt; bodyLength) return; readBuff.readIdx+=2; //解析协议名 int nameCount = 0; string protoName = MsgBase.DecodeName(readBuff.bytes, readBuff.readIdx, out nameCount); if(protoName == &quot;&quot;)&#123; Debug.Log(&quot;OnReceiveData MsgBase.DecodeName fail&quot;); return; &#125; readBuff.readIdx += nameCount; //解析协议体 int bodyCount = bodyLength - nameCount; MsgBase msgBase = MsgBase.Decode(protoName, readBuff.bytes, readBuff.readIdx, bodyCount); readBuff.readIdx += bodyCount; readBuff.CheckAndMoveBytes(); //添加到消息队列 lock(msgList)&#123; msgList.Add(msgBase); msgCount++; &#125; //继续读取消息 if(readBuff.length &gt; 2)&#123; OnReceiveData(); &#125;&#125; ProtoBuf和json功能一样作为序列化的工具，当产生消耗更小，优化带宽。 使用1234567891011121314151617//将protobuf对象序列化为Byte数组 public static byte[] Encode(ProtoBuf.IExtensible msgBase) &#123; using (var memory = new System.IO.MemoryStream()) &#123; ProtoBuf.Serializer.Serialize(memory, msgBase); return memory.ToArray(); &#125; &#125; //解码 public static ProtoBuf.IExtensible Decode(string protoName, byte[] bytes, int offset, int count)&#123; using (var memory = new System.IO.MemoryStream(bytes, offset, count)) &#123; System.Type t = System.Type.GetType(protoName); return (ProtoBuf.IExtensible)ProtoBuf.Serializer.NonGeneric.Deserialize(t, memory); &#125; &#125; proto编写格式 1234567891011message MsgMove&#123; optional int32 x = 1; optional int32 y = 2; optional int32 z = 3;&#125;message MsgAttack&#123; optional string desc = 1;&#125; 生成代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465//------------------------------------------------------------------------------// &lt;auto-generated&gt;// This code was generated by a tool.//// Changes to this file may cause incorrect behavior and will be lost if// the code is regenerated.// &lt;/auto-generated&gt;//------------------------------------------------------------------------------// Generated from: proto/BattleMsg.protonamespace proto.BattleMsg&#123; [global::System.Serializable, global::ProtoBuf.ProtoContract(Name=@&quot;MsgMove&quot;)] public partial class MsgMove : global::ProtoBuf.IExtensible &#123; public MsgMove() &#123;&#125; private int _x = default(int); [global::ProtoBuf.ProtoMember(1, IsRequired = false, Name=@&quot;x&quot;, DataFormat = global::ProtoBuf.DataFormat.TwosComplement)] [global::System.ComponentModel.DefaultValue(default(int))] public int x &#123; get &#123; return _x; &#125; set &#123; _x = value; &#125; &#125; private int _y = default(int); [global::ProtoBuf.ProtoMember(2, IsRequired = false, Name=@&quot;y&quot;, DataFormat = global::ProtoBuf.DataFormat.TwosComplement)] [global::System.ComponentModel.DefaultValue(default(int))] public int y &#123; get &#123; return _y; &#125; set &#123; _y = value; &#125; &#125; private int _z = default(int); [global::ProtoBuf.ProtoMember(3, IsRequired = false, Name=@&quot;z&quot;, DataFormat = global::ProtoBuf.DataFormat.TwosComplement)] [global::System.ComponentModel.DefaultValue(default(int))] public int z &#123; get &#123; return _z; &#125; set &#123; _z = value; &#125; &#125; private global::ProtoBuf.IExtension extensionObject; global::ProtoBuf.IExtension global::ProtoBuf.IExtensible.GetExtensionObject(bool createIfMissing) &#123; return global::ProtoBuf.Extensible.GetExtensionObject(ref extensionObject, createIfMissing); &#125; &#125; [global::System.Serializable, global::ProtoBuf.ProtoContract(Name=@&quot;MsgAttack&quot;)] public partial class MsgAttack : global::ProtoBuf.IExtensible &#123; public MsgAttack() &#123;&#125; private string _desc = &quot;&quot;; [global::ProtoBuf.ProtoMember(1, IsRequired = false, Name=@&quot;desc&quot;, DataFormat = global::ProtoBuf.DataFormat.Default)] [global::System.ComponentModel.DefaultValue(&quot;&quot;)] public string desc &#123; get &#123; return _desc; &#125; set &#123; _desc = value; &#125; &#125; private global::ProtoBuf.IExtension extensionObject; global::ProtoBuf.IExtension global::ProtoBuf.IExtensible.GetExtensionObject(bool createIfMissing) &#123; return global::ProtoBuf.Extensible.GetExtensionObject(ref extensionObject, createIfMissing); &#125; &#125; &#125; 具体使用12345678MsgMove msgMove = new MsgMove();msgMove.x = 214;byte[] bs = Encode(msgMove);Debug.Log(System.BitConverter.ToString(bs));//解码ProtoBuf.IExtensible m = Decode(&quot;proto.BattleMsg.MsgMove&quot;, bs, 0, bs.Length);MsgMove m2 = (MsgMove)m;Debug.Log(m2.x); 命令行调试1234567891011121314151617181920212223242526272829303132333435363738394041void main()&#123; var args = GetCommandlineArgs(); if (args.TryGetValue(&quot;-mode&quot;, out string mode)) &#123; //通过mode字符串启动服务器或者客户端 switch (mode) &#123; case &quot;server&quot;: break; case &quot;host&quot;: break; case &quot;client&quot;: break; &#125; &#125;&#125;private Dictionary&lt;string, string&gt; GetCommandlineArgs() &#123; Dictionary&lt;string, string&gt; argDictionary = new Dictionary&lt;string, string&gt;(); var args = System.Environment.GetCommandLineArgs(); for (int i = 0; i &lt; args.Length; ++i) &#123; var arg = args[i].ToLower(); if (arg.StartsWith(&quot;-&quot;)) &#123; var value = i &lt; args.Length - 1 ? args[i + 1].ToLower() : null; value = (value?.StartsWith(&quot;-&quot;) ?? false) ? null : value; argDictionary.Add(arg, value); &#125; &#125; return argDictionary; &#125; 启动指令 1xxx.exe -mode server","categories":[{"name":"游戏","slug":"游戏","permalink":"https://mrchenlearnspace.github.io/categories/%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"网络","slug":"网络","permalink":"https://mrchenlearnspace.github.io/tags/%E7%BD%91%E7%BB%9C/"}]},{"title":"Games104网络基础部分","slug":"Games104网络基础部分","date":"2022-09-26T16:38:45.000Z","updated":"2022-11-14T14:24:00.239Z","comments":true,"path":"2022/09/27/Games104网络基础部分/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/09/27/Games104%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86/","excerpt":"","text":"面临的挑战实现网络物体一致 网络延迟 网络掉线和重连 反作弊和防信息泄露 对于不同设备连接和实现同步 多个游戏的子系统实现同步 承载更多的用户高并发 高可用性 高性能 TCP优点面向连接 可靠和有序 流控制 拥塞控制 缺点太慢了 UDP优点快 缺点无连接 不可靠和无序 没有流控制 没有拥塞控制 对于UDP和TCP的混合使用使用在udp的连接下使用自动重传协议 ARQ和 前向纠错 FEC ARQ通过滑动窗口和选择性重传 在选择性重复ARQ中，只有损坏或丢失的帧被重传 接收端发送每一帧的ack，发送端维护每一帧的超时时间 当接收端收到损坏的数据包时，它将发送一个NACK，发送端将发送&#x2F;重传接收到NACK的帧 FECXOF异或Let E &#x3D; XOR (A, B, C, D)• A &#x3D; XOR (B, C, D, E)• B &#x3D; XOR (A, C, D, E)• C &#x3D; XOR (A, B, D, E)• D &#x3D; XOR (A, B, C, E)如果有报文丢失，可以和其他4个报文一起恢复在连续数据传输中，只能丢失一个数据包。如果A和B同时丢失，则算法无法恢复 Reed-Solomon Codes 定制您的UDP基于ARQ和FEC可靠性选择性重复ARQ 混合 ARQ 和 FEC使用在ARQ之前，采用FEC进行纠错 实时更小的重传超时时间RTO增长没有拥塞控制速度重传机制没有延迟ACK传输 灵活性设计协议速度支持可靠和不可靠 时钟同步RTT往返时间 NTP网络时间协议理想情况下，上行和下行速度一样。现实中，不一样的处理方法 多求几次RTT然后去除最高值，取剩下的平均值。 Remote Procedure Call（RPC）远程调用函数 Interface Definition Language接口定义语言类似于用来两边对话的格式，例如ProtoBuf RPC Stubs客户端存根是一个过程，它在客户端看来就像是一个可调用的服务器过程•客户端程序认为它在调用服务器，但实际上它是在调用客户端存根服务器端存根看起来像服务器的调用者•服务器程序认为它是由客户端调用的，但实际上它是由服务器端存根调用的•存根相互发送消息，使RPC透明地发生 Stub Compiler票据编译器比如ProtoBuf直接做好了。•“存根编译器”读取IDL声明，并为每个服务器过程生成两个存根过程•服务器程序员实现服务的过程，并将它们与服务器端存根链接客户端程序员实现客户端程序，并将其与客户端存根链接•存根管理客户端和服务器之间远程通信的所有细节#Real RPC Package Journey 网络拓扑结构原始的p2p两者进行相互连接就行每个客户端向所有人广播游戏事件其他人•鲁棒性•作弊更容易•所有节点之间需要同步，以保持分布式游戏状态的一致性 通过建立hostServe的P2P•玩家可以充当“服务器”，即主机•如果主机断开连接，游戏可能会结束•主机需要处理玩家无法控制的游戏参与者，如机器人运用游戏如下 优点 更加灵活 移除多人游戏中“服务器问题”的问题。 在服务器上没有额外的成本缺点 作弊就容易多了 每个玩家都需要一个像样的网络连接才能让游戏正常运行 3.只能处理有限数量的玩家 专用的服务器Dedicated Server•权力模拟游戏世界•向玩家分发数据•高性能要求高 优点 易于维护以及避免作弊 能否应对庞大的游戏世界 游戏的响应性并不依赖于每个客户端的网络条件缺点 服务器成本高 更多的工作在服务器端程序 单点故障游戏同步Snapshot Synchronization 快照同步基本步骤•客户端向服务器发送输入•服务器模拟游戏世界•生成整个游戏状态快照•发送给客户•客户端根据快照更新显示优化对比上一帧快照只发送变化的部分Lockstep Synchronization帧同步步骤帧同步初始化加载……•确保每个节点的初始数据客户是确定的•游戏模型•静态数据•……•同步时钟准确性同步•客户端向服务器发送输入•服务器接收和排序•等待所有客户端输入后再转发•客户端从服务器接收数据后，执行游戏逻辑缺点需要全部用户都收集完成后才实现同步，出现了网慢者得利的情况。Bucket Synchronization 桶同步•桶:固定时间段•每一个桶•收集所有指示•向所有玩家广播•不需要等待所有玩家的命令被接收才转发如果超时服务器将不做出反应，或滞留下一帧处理。同步的准确性难点 •确定的•相同的输入序列需要在所有机器上产生相同的游戏状态•确定性难处•浮点•随机数•容器和算法(排序，添加，删除等)•数学工具(向量，四元数等)•物理模拟(非常困难)•代码逻辑执行顺序 浮点数使用统一标准IEEE 754数学库的统一，浮点编译器的情况，及运行平台的情况解决方案:避免精度边界问题定制精度定点数学库查表(三角函数等)放大和截断 随机数使用随机种子保证每台设备的随即结果相同。 跟踪和调试获取校验和的方法所有数据校验关键数据校验其他方法 自动定位错误服务器比较不同客户端的校验和客户端上传50帧完整的日志在比较的日志中查找不一致的地方 延迟因为网络造成的延时 解决方案使用缓冲到缓存器中 重连快照可以定期保存在本地客户端，并序列化到磁盘当重新连接发生时，从磁盘序列化数据恢复游戏状态服务器在快照后发送玩家命令加速以赶上游戏进度 怎样追赶上帧在示例代码中，每次跟踪10帧如果最初是每秒10帧，当追逐帧时，它可能运行每秒100帧 State Synchronization状态同步实现：将相关的状态传给服务器，让服务器判断结果，并通知所以客户端。比如玩家将移动和攻击这个状态传给服务器。 物体的复制协议状态数据保证了大多数当前状态的最终交付对象的位置对象的生命值 150 +属性事件瞬时事件的不可靠通知请开枪这把枪是开的炸弹引爆更多的事件控制数据高频，从玩家控制输入中提取的快速更新数据的最佳传输方式当前所有玩家的模拟杆值病人自己当前的位置更多的属性游戏状态•游戏状态是表示游戏世界的必要条件。例句:HP,MP状态同步•服务器不会为所有客户端生成单个更新。它向客户端发送一个定制的数据包•如果游戏世界太复杂，你可以设置一个兴趣区域Area Of Interest(AOI)来减少服务器开销服务器授权游戏世界服务器•游戏世界授权从客户端接收输入和状态•运行游戏逻辑•发送状态客户端•接收数据，模拟游戏世界•游戏玩法改进授权和复制的客户端授权(1P)•玩家的本地游戏客户端服务器•授权服务器复制(3 P)•在其他玩家的客户端中模拟角色如玩家只能对玩家的状态进行改变，在其他客户端中出现的是复制品。愚蠢的客户端问题客户端在收到之前不能做任何事情服务器状态更新如何看到即时回应?客户端预测守望先锋的举例 • RTT &#x3D; 160ms• Half RTT &#x3D; 80ms• Command frame &#x3D; 16ms所以我们将预测96ms的动作。 服务器和解 授权客户端:缓冲区• 记录客户预测时的每一个状态• 与客户端接收到的过去服务器数据进行比较 环形状态缓冲区•在客户端存储我们过去几帧的所有状态过程•如果客户端计算出与服务器相同的结果，客户端将继续其愉快的方式来模拟下一个输入 如果被服务器上的运动被障碍阻塞• 位置错误!(红色)• 客户端必须接受新的服务器更新• 从新确认的位置开始回溯所有预测移动•如果客户端和服务器对结果不一致，我们就预测错了•必须和解环形输入缓冲区•在客户端上存储过去几帧的所有输入。过程•用服务器的结果覆盖客户端的结果•重放你所有的输入，以跟上你现在所相信的 丢包问题•客户端输入包无法到达服务器•服务器试图保留很小的未处理输入缓冲区•如果服务器耗尽了输入缓冲区，服务器将在一个窗口中复制你最后的输入•推送客户端尽快发送遗漏的输入当然不同游戏可能处理方案也不一样，可能直接停止了 状态同步VS帧同步 状态同步 帧同步 是否要写进逻辑 非必要的 必要的 响应 更好的响应 较差的响应 网络流量 通常高 通常低 开发效率高 复杂得多 易于开发，难于调试 玩家数量 玩家数量少 支持少量和大量的玩家 跨平台 相对容易 相对困难 重新连接 相对容易 相对困难 重放文件大小 大 小 作弊难度 相对难 相对容易","categories":[{"name":"游戏","slug":"游戏","permalink":"https://mrchenlearnspace.github.io/categories/%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"网络","slug":"网络","permalink":"https://mrchenlearnspace.github.io/tags/%E7%BD%91%E7%BB%9C/"}]},{"title":"地形系统Shader学习","slug":"地形系统Shader学习","date":"2022-07-07T16:49:45.000Z","updated":"2022-11-14T14:21:14.457Z","comments":true,"path":"2022/07/08/地形系统Shader学习/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/07/08/%E5%9C%B0%E5%BD%A2%E7%B3%BB%E7%BB%9FShader%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"基于混合因子的地形材质混合取第一套UV 取第一层材质的数据同样取出其他的材质， layer2，layer3. 使用顶点色材质的使用量HeightLerp输入Height 从高度图采样的高度Transition 用来控制材质使用量的参数，一般使用顶点色的4个通道BlendContrast 混合对比度，数值越大对比越明显输出得到一个基于高度的混合因子混合因子的制作 将三种材质混合以基础颜色为例粗糙度，AO，法线同上一样。 效果Combine通过修改顶点色RGB就能混合材质了 基于权重的地形材质混合混合权重的制作取最大值，最大值减去混合对比度，用原值减去混合对比度的差，同时保证数据不为负数，然后除以三值的和就行。 将三种材质混合因为是权重，且和等于一所以效果可以直接叠加。粗糙度，AO，法线同上一样。 用权重图代替顶点色使用插件paint in 3D插件实时绘制好权重图并替换顶点色 注意事项顶点色要保证权重之和小于等于1。确保使用的UV是地形一套的UV地形模型边缘悬崖可以用插值方法代替材质。 ​","categories":[{"name":"游戏","slug":"游戏","permalink":"https://mrchenlearnspace.github.io/categories/%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"Shader","slug":"Shader","permalink":"https://mrchenlearnspace.github.io/tags/Shader/"}]},{"title":"Games104总结粒子系统和声效","slug":"Games104总结粒子系统和声效","date":"2022-07-07T16:49:45.000Z","updated":"2022-11-14T14:24:07.061Z","comments":true,"path":"2022/07/08/Games104总结粒子系统和声效/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/07/08/Games104%E6%80%BB%E7%BB%93%E7%B2%92%E5%AD%90%E7%B3%BB%E7%BB%9F%E5%92%8C%E5%A3%B0%E6%95%88/","excerpt":"","text":"粒子系统属性坐标，初速度，大小，颜色，生命周期，… 粒子的生命周期 如果控制失败就会出现粒子越来越多，使系统资源殆尽 粒子的发射器指定生成规则，指定仿真逻辑，描述如何渲染粒子 粒子模拟力学模拟模拟控制粒子如何随时间变化粒子碰撞 三种粒子效果制作面片粒子，网格粒子，光带粒子（拖尾）光带粒子系统路径使用CatMull-Rom插值，效果会更柔和 粒子系统渲染透明度排序全局排序：准确，但性能消耗大层次结构:每个系统-&gt;每个发射器-&gt;发射器内部排序规则粒子之间:基于粒子与相机的距离系统或发射器之间:包围盒 完全解决粒子基于屏幕的解决办法，最坏情况充满整个屏幕 Low-Resolution Particles如图，通过Half-ResolutionDepth进行混合 GPU 粒子GPU处理粒子系统高度并行工作，适合模拟大量粒子释放你的CPU去编写游戏代码易于访问深度缓冲做碰撞 初始状态右边的图显示了一个空的池，最多包含8个粒子，开始时所有8个槽都处于死可用状态 注意的问题当摄像头没看粒子系统时被裁剪掉，当回头看时会显得很突兀 排序，渲染和交换活列表根据距离缓冲对活列表进行排序渲染粒子排序后的活列表剔除交换活着列表 深度缓冲碰撞 1.重新投影粒子位置到之前的帧屏幕空间纹理坐标 2.从昂贵的帧深度纹理读取深度值 3.检查粒子是否与深度缓冲碰撞，但不完全在它后面(厚度值被使用) 4.如果发生碰撞，计算表面法线和反弹粒子 声音系统Volume 声压(p):由声音引起的局部与环境气压的偏差波，国际单位制单位（帕）粒子速度(V):粒子在介质中传播波的速度，单位为SI (m&#x2F;s)声强(1):声波在单位面积上沿垂直于该面积方向所携带的功率，SI单位:W &#x2F; m2 声压级(Lp):声音相对于参考值的有效压力的对数量度，单位为国际标准单位(dB) 参考声压，是人类听觉的阈值，常用在空气中(大概是3米外蚊子飞过的声音) Pitch 决定声音的高或低 这取决于声音的频率波 音色（Timbre）泛音或谐波的组合频率相对强度 相位和噪声消除相同的频率，振幅，但不同的相位 人类听觉特性人耳可听见的声音频率范围:20-20KHz声压级范围(0-130db) 数字声音Pulse-code Modulation （PCM）对采样模拟声音信号进行编码的标准方法抽样，量化，编码 采样采样频率:每秒采样次数(Hz)采样的频率高一点 量化 位深度:位深度是每个样本中信息的位数 Audio Format 3维的声音的渲染一种单音音频信号从特定位置发出的 侦听器“虚拟麦克风”位置 ，速度，朝向 空间化用来确定声音相对于听者的方向的技术 Panning将一个音频信号分配到一个新的立体声或多声道声场主要思想:对于增益为1的立体声信号，左、右两个信道的增益之和应为1 线性平移当声音在中间平移时，能量会下降(x &#x3D; 0.5) 等平方平移 在平移过程中保持功率限制，而不是保持振幅不变，以保持恒定的响度 这个方程有几个可能的解，一个是正弦&#x2F;余弦方程 衰弱音量会随着听者的离开而衰减在现实世界中，球形声波的声压(P)随着距离球中心1&#x2F;r的距离减小: 障碍物 混响 回音多普勒效应 声场 中间件","categories":[{"name":"游戏","slug":"游戏","permalink":"https://mrchenlearnspace.github.io/categories/%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"Shader","slug":"Shader","permalink":"https://mrchenlearnspace.github.io/tags/Shader/"}]},{"title":"风格化水体渲染","slug":"风格化水体渲染","date":"2022-07-07T08:49:45.000Z","updated":"2022-11-14T14:21:21.339Z","comments":true,"path":"2022/07/07/风格化水体渲染/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/07/07/%E9%A3%8E%E6%A0%BC%E5%8C%96%E6%B0%B4%E4%BD%93%E6%B8%B2%E6%9F%93/","excerpt":"","text":"水体属性水体深度从深度图获取水下顶点的世界坐标，与水面顶点坐标相减得到当前顶点的水深度。 水体颜色当深水区时使用较深的颜色且透明的调为不透明，浅水区可以浅一点，透明度透明一点如图，使用lerp深度作为权重。 水体表面扰动参考之前的水面渲染 反射参考之前的水面渲染通过PlanarReflection.cs获得反射图，如果觉得性能消耗大，可以采用sspr或者反射探针得到。 折射&#x2F;水底使这是也会受到水面扰动的影响。 焦散 岸边泡沫 水体运动参考这篇文章 效果Combine","categories":[{"name":"游戏","slug":"游戏","permalink":"https://mrchenlearnspace.github.io/categories/%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"Shader","slug":"Shader","permalink":"https://mrchenlearnspace.github.io/tags/Shader/"}]},{"title":"雾效","slug":"雾效","date":"2022-07-04T09:38:45.000Z","updated":"2022-11-14T14:22:54.995Z","comments":true,"path":"2022/07/04/雾效/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/07/04/%E9%9B%BE%E6%95%88/","excerpt":"","text":"距离雾计算出顶点与摄像机的距离将范围映射到雾效范围中。 高度雾将距离雾中的距离改变为顶点坐标的y坐标。 太阳光对雾效的影响 全局雾效 通过深度图进行后处理雾效，获取相机的深度图，通过深度图进行世界坐标还原，将之前的的世界坐标替换掉，因为天空球和地形的高度雾效不同，所以用一个阈值区分，lerp 天空球 地形 阈值。可能会有锯齿，可以通过缩小天空球大小降低锯齿，或者关闭抗锯齿效果，产生原因是因为山脉边缘与天空球颜色采样差距较大。","categories":[{"name":"游戏","slug":"游戏","permalink":"https://mrchenlearnspace.github.io/categories/%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"Shader","slug":"Shader","permalink":"https://mrchenlearnspace.github.io/tags/Shader/"}]},{"title":"天空盒和水面渲染","slug":"天空盒和水面渲染","date":"2022-07-03T20:38:45.000Z","updated":"2022-11-14T14:22:34.839Z","comments":true,"path":"2022/07/04/天空盒和水面渲染/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/07/04/%E5%A4%A9%E7%A9%BA%E7%9B%92%E5%92%8C%E6%B0%B4%E9%9D%A2%E6%B8%B2%E6%9F%93/","excerpt":"","text":"天空球防止被相机裁剪 12345#if UNITY_REVERSED_Z o.vertex.z = o.vertex.w * 0.000001f;#else o.vertex.z = o.vertex.w * 0.999999f;#endif 渲染队列改成1000左右。 水面水面反射在平面的反射面建立一个摄像头，将渲染的Texture直接采样到平面上达到映射的效果，通过clipPlaneOffset 修正物体在通过改变反射矩阵修改具体位置。 开抄PlanarReflection.cs 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311using System;using System.Collections;using System.Collections.Generic;using UnityEngine;using UnityEngine.Rendering;[ExecuteInEditMode]public class PlanarReflection : MonoBehaviour &#123; public LayerMask _reflectionMask = -1; public bool _reflectSkybox = false; public float _clipPlaneOffset = 0.07F; //反射图属性名 const string _reflectionTex = &quot;_ReflectionTex&quot;; Camera _reflectionCamera; Vector3 _oldpos; RenderTexture _bluredReflectionTexture; Material _sharedMaterial; //模糊效果相关参数 public bool _blurOn = true; [Range(0.0f, 5.0f)] public float _blurSize = 1; [Range(0, 10)] public int _blurIterations = 2; [Range(1.0f, 4.0f)] public float _downsample = 1; //记录上述模糊参数，用于判断参数是否发生变化 private bool _oldBlurOn; private float _oldBlurSize; private int _oldBlurIterations; private float _oldDownsample; //模糊shader private Shader _blurShader; private Material _blurMaterial; //用来判断当前是否正在渲染反射图 private static bool _insideRendering; Material BlurMaterial &#123; get &#123; if (_blurMaterial == null) &#123; _blurMaterial = new Material(_blurShader); return _blurMaterial; &#125; return _blurMaterial; &#125; &#125; void Awake() &#123; _oldBlurOn = _blurOn; _oldBlurSize = _blurSize; _oldBlurIterations = _blurIterations; _oldDownsample = _downsample; &#125; void Start() &#123; _sharedMaterial = GetComponent&lt;MeshRenderer&gt;().sharedMaterial; _blurShader = Shader.Find(&quot;Hidden/KawaseBlur&quot;); if (_blurShader == null) Debug.LogError(&quot;缺少Hidden/KawaseBlur Shader&quot;); &#125; bool _blurParamChanged; void Update() &#123; if (_blurParamChanged) &#123; _oldBlurOn = _blurOn; _oldBlurSize = _blurSize; _oldBlurIterations = _blurIterations; _oldDownsample = _downsample; &#125; if (_blurOn != _oldBlurOn || _blurSize != _oldBlurSize || _blurIterations != _oldBlurIterations || _downsample!= _oldDownsample) &#123; _blurParamChanged = true; &#125; &#125; //创建反射用的摄像机 Camera CreateReflectionCamera(Camera cam) &#123; //生成Camera String reflName = gameObject.name + &quot;Reflection&quot; + cam.name; GameObject go = new GameObject(reflName); //go.hideFlags = HideFlags.HideAndDontSave; go.hideFlags = HideFlags.HideAndDontSave; Camera reflectCamera = go.AddComponent&lt;Camera&gt;(); //设置反射相机的参数 HoldCameraSettings(reflectCamera); //创建RT并绑定Camera if (!reflectCamera.targetTexture) &#123; reflectCamera.targetTexture = CreateTexture(cam); &#125; return reflectCamera; &#125; //设置反射相机的参数 void HoldCameraSettings(Camera heplerCam) &#123; heplerCam.backgroundColor = Color.black; heplerCam.clearFlags = _reflectSkybox ? CameraClearFlags.Skybox : CameraClearFlags.SolidColor; heplerCam.renderingPath = RenderingPath.Forward; heplerCam.cullingMask = _reflectionMask; heplerCam.allowMSAA = false; heplerCam.enabled = false; &#125; //创建RT RenderTexture CreateTexture(Camera sourceCam) &#123; int width = Mathf.RoundToInt(Screen.width / _downsample); int height = Mathf.RoundToInt(Screen.height / _downsample); RenderTextureFormat formatRT = sourceCam.allowHDR ? RenderTextureFormat.DefaultHDR : RenderTextureFormat.Default; RenderTexture rt = new RenderTexture(width, height, 24, formatRT); rt.hideFlags = HideFlags.DontSave; return rt; &#125; //内置回调函数，物体渲染之前会先调用该函数 void OnWillRenderObject() &#123; Camera currentCam = Camera.current; if (currentCam == null) &#123; return; &#125;#if !UNITY_EDITOR if (!currentCam.gameObject.CompareTag(&quot;MainCamera&quot;)) return;#endif if (_insideRendering) &#123; return; &#125; _insideRendering = true; if (_reflectionCamera == null) &#123; _reflectionCamera = CreateReflectionCamera(currentCam); &#125; //渲染反射图 RenderReflection(currentCam, _reflectionCamera); //是否对反射图进行模糊 if (_reflectionCamera &amp;&amp; _sharedMaterial) &#123; if (_blurOn) &#123; if (_bluredReflectionTexture == null) _bluredReflectionTexture = CreateTexture(currentCam); PostProcessTexture(currentCam, _reflectionCamera.targetTexture, _bluredReflectionTexture); _sharedMaterial.SetTexture(_reflectionTex, _bluredReflectionTexture); &#125; else &#123; _sharedMaterial.SetTexture(_reflectionTex, _reflectionCamera.targetTexture); &#125; &#125; _insideRendering = false; &#125; //调用反射相机，渲染反射图 void RenderReflection(Camera currentCam, Camera reflectCamera) &#123; if (reflectCamera == null) &#123; Debug.LogError(&quot;反射Camera无效&quot;); return; &#125; if (_sharedMaterial &amp;&amp; !_sharedMaterial.HasProperty(_reflectionTex)) &#123; Debug.LogError(&quot;Shader中缺少_ReflectionTex属性&quot;); return; &#125; //保持反射相机的参数 HoldCameraSettings(reflectCamera); if (_reflectSkybox) &#123; if (currentCam.gameObject.GetComponent(typeof(Skybox))) &#123; Skybox sb = (Skybox)reflectCamera.gameObject.GetComponent(typeof(Skybox)); if (!sb) &#123; sb = (Skybox)reflectCamera.gameObject.AddComponent(typeof(Skybox)); &#125; sb.material = ((Skybox)currentCam.GetComponent(typeof(Skybox))).material; &#125; &#125; bool isInvertCulling = GL.invertCulling; GL.invertCulling = true; Transform reflectiveSurface = this.transform; //waterHeight; Vector3 eulerA = currentCam.transform.eulerAngles; reflectCamera.transform.eulerAngles = new Vector3(-eulerA.x, eulerA.y, eulerA.z); reflectCamera.transform.position = currentCam.transform.position; Vector3 pos = reflectiveSurface.transform.position; pos.y = reflectiveSurface.position.y; Vector3 normal = reflectiveSurface.transform.up; float d = -Vector3.Dot(normal, pos) - _clipPlaneOffset; Vector4 reflectionPlane = new Vector4(normal.x, normal.y, normal.z, d); Matrix4x4 reflection = Matrix4x4.zero; reflection = CalculateReflectionMatrix(reflection, reflectionPlane); _oldpos = currentCam.transform.position; Vector3 newpos = reflection.MultiplyPoint(_oldpos); reflectCamera.worldToCameraMatrix = currentCam.worldToCameraMatrix * reflection; Vector4 clipPlane = CameraSpacePlane(reflectCamera, pos, normal, 1.0f); Matrix4x4 projection = currentCam.projectionMatrix; projection = CalculateObliqueMatrix(projection, clipPlane); reflectCamera.projectionMatrix = projection; reflectCamera.transform.position = newpos; Vector3 euler = currentCam.transform.eulerAngles; reflectCamera.transform.eulerAngles = new Vector3(-euler.x, euler.y, euler.z); reflectCamera.Render(); GL.invertCulling = isInvertCulling; &#125; static Matrix4x4 CalculateObliqueMatrix(Matrix4x4 projection, Vector4 clipPlane) &#123; Vector4 q = projection.inverse * new Vector4( Mathf.Sign(clipPlane.x), Mathf.Sign(clipPlane.y), 1.0F, 1.0F ); Vector4 c = clipPlane * (2.0F / (Vector4.Dot(clipPlane, q))); // third row = clip plane - fourth row projection[2] = c.x - projection[3]; projection[6] = c.y - projection[7]; projection[10] = c.z - projection[11]; projection[14] = c.w - projection[15]; return projection; &#125; static Matrix4x4 CalculateReflectionMatrix(Matrix4x4 reflectionMat, Vector4 plane) &#123; reflectionMat.m00 = (1.0F - 2.0F * plane[0] * plane[0]); reflectionMat.m01 = (-2.0F * plane[0] * plane[1]); reflectionMat.m02 = (-2.0F * plane[0] * plane[2]); reflectionMat.m03 = (-2.0F * plane[3] * plane[0]); reflectionMat.m10 = (-2.0F * plane[1] * plane[0]); reflectionMat.m11 = (1.0F - 2.0F * plane[1] * plane[1]); reflectionMat.m12 = (-2.0F * plane[1] * plane[2]); reflectionMat.m13 = (-2.0F * plane[3] * plane[1]); reflectionMat.m20 = (-2.0F * plane[2] * plane[0]); reflectionMat.m21 = (-2.0F * plane[2] * plane[1]); reflectionMat.m22 = (1.0F - 2.0F * plane[2] * plane[2]); reflectionMat.m23 = (-2.0F * plane[3] * plane[2]); reflectionMat.m30 = 0.0F; reflectionMat.m31 = 0.0F; reflectionMat.m32 = 0.0F; reflectionMat.m33 = 1.0F; return reflectionMat; &#125; Vector4 CameraSpacePlane(Camera cam, Vector3 pos, Vector3 normal, float sideSign) &#123; Vector3 offsetPos = pos + normal * _clipPlaneOffset; Matrix4x4 m = cam.worldToCameraMatrix; Vector3 cpos = m.MultiplyPoint(offsetPos); Vector3 cnormal = m.MultiplyVector(normal).normalized * sideSign; return new Vector4(cnormal.x, cnormal.y, cnormal.z, -Vector3.Dot(cpos, cnormal)); &#125; //对反射图进行图像处理(利用command buffer实现) private Dictionary&lt;Camera, CommandBuffer&gt; _cameras = new Dictionary&lt;Camera, CommandBuffer&gt;(); void PostProcessTexture(Camera cam, RenderTexture source, RenderTexture dest) &#123; //参数有变化需要刷新commandbuffer if (_blurParamChanged) &#123; if (_cameras.ContainsKey(cam)) cam.RemoveCommandBuffer(CameraEvent.BeforeForwardOpaque, _cameras[cam]); _cameras.Remove(cam); &#125; //已经设置了commandbuffer就不用再执行了 if (_cameras.ContainsKey(cam)) return; CommandBuffer buf = new CommandBuffer(); buf.name = &quot;Blur Reflection Texture&quot;; _cameras[cam] = buf; float width = source.width; float height = source.height; int rtW = Mathf.RoundToInt(width / _downsample); int rtH = Mathf.RoundToInt(height / _downsample); int blurredID = Shader.PropertyToID(&quot;_Temp1&quot;); int blurredID2 = Shader.PropertyToID(&quot;_Temp2&quot;); buf.GetTemporaryRT(blurredID, rtW, rtH, 0, FilterMode.Bilinear, source.format); buf.GetTemporaryRT(blurredID2, rtW, rtH, 0, FilterMode.Bilinear, source.format); buf.Blit((Texture)source, blurredID); for (int i = 0; i &lt; _blurIterations; i++) &#123; float iterationOffs = (i * 1.0f); buf.SetGlobalFloat(&quot;_Offset&quot;, iterationOffs / _downsample + _blurSize); buf.Blit(blurredID, blurredID2, BlurMaterial, 0); buf.Blit(blurredID2, blurredID, BlurMaterial, 0); &#125; buf.Blit(blurredID, dest); buf.ReleaseTemporaryRT(blurredID); buf.ReleaseTemporaryRT(blurredID2); cam.AddCommandBuffer(CameraEvent.BeforeForwardOpaque, buf); &#125;&#125; 水面扰动下面的Vertex pos 是为了降低远处波动。效果 代码实现粗糙用代码还原了一下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899Shader &quot;WaterCode&quot;&#123; Properties &#123; _ReflectionTex(&quot;ReflectionTex&quot;, 2D) = &quot;white&quot; &#123;&#125; _WaterNormal(&quot;WaterNormal&quot;, 2D) = &quot;white&quot; &#123;&#125; _WaterSpeed1(&quot;WaterSpeed1&quot;, Float) = 0.1 _NormalTilling(&quot;NormalTilling&quot;, Float) = 8 _WaterNoise(&quot;WaterNoise&quot;, Float) = 1 _Vector0(&quot;Vector 0&quot;, Vector) = (0,0,0,0) &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot;=&quot;Opaque&quot; &#125; LOD 100 Pass &#123; CGPROGRAM #pragma vertex vert #pragma fragment frag // make fog work #pragma multi_compile_fog #include &quot;UnityCG.cginc&quot; struct appdata &#123; float4 vertex : POSITION; float2 uv : TEXCOORD0; float4 tangent : TANGENT; float3 normal : NORMAL; &#125;; struct v2f &#123; float2 texcoord0 : TEXCOORD0; float4 pos : SV_POSITION; float4 screenPos:TEXCOORD1; float3 worldPos:TEXCOORD2; float3 worldTangent : TEXCOORD3; float3 worldNormal : TEXCOORD4; float3 worldBitangent : TEXCOORD5; &#125;; sampler2D _ReflectionTex; float4 _ReflectionTex_ST; sampler2D _WaterNormal; float _NormalTilling; float _WaterSpeed1; float4 _Vector0; float _WaterNoise; v2f vert (appdata v) &#123; v2f o; o.pos = UnityObjectToClipPos(v.vertex); o.worldPos = mul(unity_ObjectToWorld, v.vertex).xyz; o.worldTangent = normalize( mul(unity_ObjectToWorld, v.tangent).xyz); o.worldNormal = normalize( mul(unity_ObjectToWorld, float4(v.normal,0.0)).xyz); o.worldBitangent = normalize(cross(o.worldNormal,o.worldTangent)*v.tangent.w); o.screenPos = ComputeScreenPos(o.pos); o.texcoord0 = v.uv; return o; &#125; fixed4 frag (v2f i) : SV_Target &#123; half4 screenPos = i.screenPos; float3 worldTangent = normalize(i.worldTangent); float3 worldNormal = normalize(i.worldNormal); float3 worldBitangent = normalize(i.worldBitangent); float3 tanToWorld0 = float3( worldTangent.x, worldBitangent.x, worldNormal.x ); float3 tanToWorld1 = float3( worldTangent.y, worldBitangent.y, worldNormal.y ); float3 tanToWorld2 = float3( worldTangent.z, worldBitangent.z, worldNormal.z ); half2 uv1_WaterNormal = i.worldPos.xz/_NormalTilling + _Time*_WaterSpeed1; half2 uv2_WaterNormal = i.worldPos.xz/_NormalTilling - _Time*_WaterSpeed1; half3 waterNormal = (tex2D(_WaterNormal,uv1_WaterNormal)+tex2D(_WaterNormal,uv2_WaterNormal)).xyz*0.5f; waterNormal.z =sqrt( 1.0f- dot( waterNormal.xy,waterNormal.xy)); //水面波动法线 waterNormal = float3(dot(tanToWorld0,waterNormal), dot(tanToWorld1,waterNormal), dot(tanToWorld2,waterNormal)); //screenPos screenPos = screenPos / screenPos.w; screenPos.z = ( UNITY_NEAR_CLIP_VALUE &gt;= 0 ) ? screenPos.z : screenPos.z * 0.5 + 0.5; half2 uv_result_reflection = screenPos.xy+ (waterNormal.xy/ (i.pos.w+1))*_WaterNoise; // sample the texture fixed4 col = tex2D(_ReflectionTex,uv_result_reflection); // apply fog return col; &#125; ENDCG &#125; &#125;&#125; 折射效果用让水底贴图与水面反射贴图用菲尼尔因子做插值，当角度越垂直，水底越清晰。 折射扭曲用WaterNoise做他的uv进行扰动，达到效果。 水底高度给水底做视差贴图的效果，造成视差高度的效果。","categories":[{"name":"游戏","slug":"游戏","permalink":"https://mrchenlearnspace.github.io/categories/%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"Shader","slug":"Shader","permalink":"https://mrchenlearnspace.github.io/tags/Shader/"}]},{"title":"UI背包系统","slug":"UI背包系统","date":"2022-06-04T14:00:45.000Z","updated":"2022-11-14T14:25:09.356Z","comments":true,"path":"2022/06/04/UI背包系统/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/06/04/UI%E8%83%8C%E5%8C%85%E7%B3%BB%E7%BB%9F/","excerpt":"","text":"项目练习链接 关闭打开菜单栏123456public void OpenMyBag() &#123; if(Input.GetKeyDown(KeyCode.O)) &#123; isOpen = !bag.activeSelf; bag.SetActive(isOpen); &#125;&#125; Grid Layerout Group他的子节点将会被填充到格子中 UI栏 的初始化如果游戏默认开始物品栏是关闭的一定要记住先要初始化。 ScriptableObject经常配合CreateAssetMenu使用 123456789using System.Collections;using System.Collections.Generic;using UnityEngine;[CreateAssetMenu(fileName = &quot;New Bag&quot;,menuName = &quot;Inventory/New Bag&quot;)]public class CreateBag : ScriptableObject&#123; // Start is called before the first frame update public List&lt;CreateItem&gt; items = new List&lt;CreateItem&gt;();&#125; 显示物品栏物体12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667using System.Collections;using System.Collections.Generic;using UnityEngine;using UnityEngine.UI;public class InventoryManager : MonoBehaviour&#123; public static InventoryManager instance; public CreateBag myBag; public GameObject slotGrid; // public Slot slotPrefab; public GameObject emptySlot; public Text itemInfromation; public List&lt;GameObject&gt; slots = new List&lt;GameObject&gt;();//管理生成的18个slots void Awake() &#123; if (instance != null) Destroy(this); instance = this; &#125; private void OnEnable() &#123; RefreshItem(); instance.itemInfromation.text = &quot;&quot;; &#125; public static void UpdateItemInfo(string itemDescription) &#123; instance.itemInfromation.text = itemDescription; &#125; /*public static void CreateNewItem(Item item) &#123; Slot newItem = Instantiate(instance.slotPrefab, instance.slotGrid.transform.position, Quaternion.identity); newItem.gameObject.transform.SetParent(instance.slotGrid.transform); newItem.slotItem = item; newItem.slotImage.sprite = item.itemImage; newItem.slotNum.text = item.itemHeld.ToString(); &#125;*/ public static void RefreshItem() &#123; //循环删除slotGrid下的子集物体 for (int i = 0; i &lt; instance.slotGrid.transform.childCount; i++) &#123; if (instance.slotGrid.transform.childCount == 0) break; Destroy(instance.slotGrid.transform.GetChild(i).gameObject); instance.slots.Clear(); &#125; //重新生成对应myBag里面的物品的slot for (int i = 0; i &lt; instance.myBag.items.Count; i++) &#123; // CreateNewItem(instance.myBag.itemList[i]); instance.slots.Add(Instantiate(instance.emptySlot)); instance.slots[i].transform.SetParent(instance.slotGrid.transform); instance.slots[i].GetComponent&lt;Slot&gt;().slotID = i; instance.slots[i].GetComponent&lt;Slot&gt;().SetupSlot(instance.myBag.items[i]); &#125; &#125;&#125; 拖拽物品CanvasGroup 1GetComponent&lt;CanvasGroup&gt;().blocksRaycasts = false; 射线阻挡关闭，开启对ui面板的碰撞 事件系统的接口12345IBeginDragHandler, IDragHandler, IEndDragHandler//接口//接口提供的方法public void OnBeginDrag(PointerEventData eventData);public void OnDrag(PointerEventData eventData);public void OnEndDrag(PointerEventData eventData); 在OnEndDrag方法最后一定要射线阻挡开启，不然无法再次选中移动的物品ItemOnDrag的代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263using System.Collections;using System.Collections.Generic;using UnityEngine;using UnityEngine.EventSystems;public class ItemOnDrag : MonoBehaviour, IBeginDragHandler, IDragHandler, IEndDragHandler&#123; public Transform originalParent; public CreateBag myBag; private int currentItemID;//当前物品ID public void OnBeginDrag(PointerEventData eventData) &#123; originalParent = transform.parent; currentItemID = originalParent.GetComponent&lt;Slot&gt;().slotID; transform.SetParent(transform.parent.parent); transform.position = eventData.position; GetComponent&lt;CanvasGroup&gt;().blocksRaycasts = false;//射线阻挡关闭 &#125; public void OnDrag(PointerEventData eventData) &#123; transform.position = eventData.position; //Debug.Log(eventData.pointerCurrentRaycast.gameObject.name);//输出鼠标当前位置下到第一个碰到到物体名字 &#125; public void OnEndDrag(PointerEventData eventData) &#123; if(eventData.pointerCurrentRaycast.gameObject==null) &#123; transform.SetParent(originalParent.transform); transform.position = originalParent.transform.position; &#125;else if (eventData.pointerCurrentRaycast.gameObject.name == &quot;Item Image&quot;)//判断下面物体名字是：Item Image 那么互换位置 &#123; transform.SetParent(eventData.pointerCurrentRaycast.gameObject.transform.parent.parent); transform.position = eventData.pointerCurrentRaycast.gameObject.transform.parent.parent.position; //itemList的物品存储位置改变 var temp = myBag.items[currentItemID]; myBag.items[currentItemID] = myBag.items[eventData.pointerCurrentRaycast.gameObject.GetComponentInParent&lt;Slot&gt;().slotID]; myBag.items[eventData.pointerCurrentRaycast.gameObject.GetComponentInParent&lt;Slot&gt;().slotID] = temp; eventData.pointerCurrentRaycast.gameObject.transform.parent.position = originalParent.position; eventData.pointerCurrentRaycast.gameObject.transform.parent.SetParent(originalParent); &#125; else if (eventData.pointerCurrentRaycast.gameObject.name == &quot;slot(Clone)&quot;) &#123; //否则直接挂在检测到到Slot下面 transform.SetParent(eventData.pointerCurrentRaycast.gameObject.transform); transform.position = eventData.pointerCurrentRaycast.gameObject.transform.position; //itemList的物品存储位置改变 myBag.items[eventData.pointerCurrentRaycast.gameObject.GetComponentInParent&lt;Slot&gt;().slotID] = myBag.items[currentItemID]; myBag.items[currentItemID] = null; &#125; else &#123; transform.SetParent(originalParent.transform); transform.position = originalParent.transform.position; &#125; GetComponent&lt;CanvasGroup&gt;().blocksRaycasts = true;//射线阻挡开启，不然无法再次选中移动的物品 &#125;&#125; 详情见项目 敌方血条显示血条在空间显示血条显示在角色的正上方，将Canvas的渲染模式修改为世界空间坐标下，在角色正上方建立一个空物件，标识血条出现的位置用代码实现同步。 图标始终面向摄像头1Target.transform.forward = - Camera.main.transform.forward;","categories":[{"name":"编程","slug":"编程","permalink":"https://mrchenlearnspace.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"游戏","slug":"游戏","permalink":"https://mrchenlearnspace.github.io/tags/%E6%B8%B8%E6%88%8F/"}]},{"title":"大话设计模式观后感之行为型设计模式","slug":"大话设计模式观后感之行为型模式","date":"2022-06-02T02:38:45.000Z","updated":"2022-11-14T14:21:09.595Z","comments":true,"path":"2022/06/02/大话设计模式观后感之行为型模式/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/06/02/%E5%A4%A7%E8%AF%9D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E8%A7%82%E5%90%8E%E6%84%9F%E4%B9%8B%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"观察者模式观察者模式定义了一种一对多的依赖关系，让多个观察者对象同时监听某一个主题对象。这个主题对象在状态发生变化时，会通知所有观察者对象，使它们能够自动更新自己。 例子 抽象通知接口 Boss实例 抽象观察者 具体观察者的实现 观察者缺点尽管已经用了依赖倒转原则，但是. 抽象通知者’还是依赖. 抽象观察者’，也就是说，万一没有了抽象观察者这样的接口，我这通知的功能就完不成了。另外就是每个具体观察者，它不-定是‘更新’的方法要调用呀，就像刚才说的，我希望的是‘工具箱’是隐藏，. 自动窗口’是打开，这根本就不是同名的方法。这应该就是不足的地方吧。 解决方案–事件委托委托就是一种引用方法的类型。-旦为委托分配了方法，.委托将与该方法具有完全相同的行为。委托方法的使用可以像其他任何方法一样，具有参数和返回值。委托可以看作是对函数的抽象，是函数的‘类’， 委托的实例将代表一个具体的函数。一个委托可以搭载多个方法，所有方法被依次唤起 更重要的是，它可以使得委托对象所搭载的方法并不需要属于同一个类。但委托也是有前提的，那就是委托对象所搭载的所有方法必须具有相同的原形和形式，也就是拥有相同的参数列表和返回值类型。消除了观察者抽象类，在客户端进行灵活的调用不同类的相关具有相同参数和返回值的不同名函数，实现解耦。 观察者的具体实现 通知者接口 声明委托委托可以定义在类里面，类外面，也可以在命名空间下，根据不同的需要来确定委托方法的使用范围。 通知者的实现 客户端灵活调用 事件关键字的使用在委托类型前加上event 代表声明事件。否则是声明委托。事件只能对委托进行加减不能进行赋值 1234delegate void EventHandle()public event EventHandle MyEvent;//事件public EventHandle MyDelegate ;//委托 对于接口和抽象类接口成员属性、方法、索引指示器和事件，但不能包含常量、域、操作符、构造函数和析构函数，而且也不能包含任何静态成员C# 接口的成员不能有 public、protected、internal、private 等修饰符。原因很简单，接口里面的方法都需要由外面接口实现去实现方法体，那么其修饰符必然是 public。C# 接口中的成员默认是 public 的，java 中是可以加 public 的。","categories":[{"name":"编程","slug":"编程","permalink":"https://mrchenlearnspace.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://mrchenlearnspace.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"大话设计模式观后感之结构型设计模式","slug":"大话设计模式观后感之结构型模式","date":"2022-06-02T02:19:45.000Z","updated":"2022-11-14T14:20:53.504Z","comments":true,"path":"2022/06/02/大话设计模式观后感之结构型模式/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/06/02/%E5%A4%A7%E8%AF%9D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E8%A7%82%E5%90%8E%E6%84%9F%E4%B9%8B%E7%BB%93%E6%9E%84%E5%9E%8B%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"外观模式外观模式(Facade)，为子系统中的一组接口提供一个一致的界面，此模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。 在原子系统加一层封装，提供系统相关功能完成分层。 例子 修改后 将子系统功能聚合起来 适用场景 在设计初期阶段，应该要有意识的将不同的两个层分离 在开发阶段，子系统往往因为不断的重构演化而变得越来越复杂，大多数的模式使用时也都会产生很多很小的类，这本是好事，但也给外部调用它们的用户程序带来了使用上的困难，增加外观 Facade可以提供一个简单的接口，减少它们之间的依赖。 在维护一个遗留的大型系统时，可能这个系统已经非常难以维护和扩展了，但因为它包含非常重要的功能，新的需求开发必须要依赖于它。此时用外观模式Facade也是非常合适的。你可以为新系统开发一个外观 Facade类，来提供设计粗糙或高度复杂的遗留代码的比较清晰简单的接口，让新系统与Facade对象交互，Facade 与遗留代码交互所有复杂的工作。 信息的隐藏促进了软件的复用迪米特原则 应该让一个软件中的子系统间的通信和相互依赖关系达到最小，而具体办法就是引入一个外观对象，它为子系统间提供了一个单一而简单的屏障。 适配器模式适配器模式(Adapter)，将一个类的接口转换成客户希望的另外一个接口。Adapter模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。 个人理解：这只是一个亡羊补牢的办法，到项目后期时，因为无法修改整个系统，才使用这个方法来统一接口。 例子 把中文的进攻方法修改成英文。 适用场景此方法适合用于开发后期，前期更应统一接口，切记。 使用一个已经存在的类，但如果它的接口，也就是它的方法和你的要求不相同时，就应该考虑用适配器模式。 两个类所做的事情相同或相似，但是具有不同的接口时要使用它。 在双方都不太容易修改的时候再使用适配器模式适配。 适配器模式与.NET应用在.NET 中有一个类库已经实现的、非常重要的适配器,那就是DataAdapter. DataAdapter 用作DataSet和数据源之间的适配器以便检索和保存数据。DataAdapter通过映射FilI(这更改了DataSet中的数据以便与数据源中的数据相匹配）和Update(这更改了数据源中的数据以便与DataSet中的数据相匹配）来提供这一适配器[MSDN]。由于数据源可能是来自SQL Server，可能来自Oracle，也可能来自Access、DB2，这些数据在组织上可能有不同之处，但我们希望得到统一的DataSet(实质是XML 数据)，此时用DataAdapter就是非常好的手段，我们不必关注不同数据库的数据细节，就可以灵活的使用数据。 桥接模式桥接模式(Bridge)，将抽象部分与它的实现部分分离，使它们都可以独立地变化。 常用于项目设计初期。我觉得桥接模式所说的‘将抽象部分与它的实现部分分离，还是不好理解，我的理解就是实现系统可能有多角度分类，每一种分类都有可能变化，那么就把这种多角度分离出来让它们独立变化，减少它们之间的耦合。 解耦这些不同方向的变化，通过对象组合的方式，把两个角色之间的继承关系改为了组合的关系，从而使这两者可以应对各自独立的变化。 面对变化，找出变化并封装之。 例子 修改后 适用场景适用于项目开发前期设计好 组合模式组合模式(Composite)，将对象组合成树形结构以表示‘部分-整体’的层次结构。组合模式使得用户对单个对象和组合对象的使用具有一致性。做一个抽象的类，叶子节点主要是对于本节点的处理，composite更多的是对于之下的节点的管理。 代码实现Component Leaf Composite 例子 透明方式与安全模式Component中声明所有用来管理子对象的方法，其中包括Add、Remove等。这样实现Component 接口的所有子类都具备了Add和Remove。这样做的好处就是叶节点和枝节点对于外界没有区别，它们具备完全一致的行为接口叫做透明方式。但问题也很明显，因为 Leaf类本身不具备Add(、Remove0方法的功能，所以实现它是没有意义的Leaf类当中不用Add和Remove方法是安全方式，也就是在Component 接口中不去声明Add和Remove方法，那么子类的Leaf也就不需要去实现它，而是在Composite声明所有用来管理子类对象的方法，这样做就不会出现刚才提到的问题，不过由于不够透明，所以树叶和树枝类将不具有相同的接口，客户端的调用需要做相应的判断,带来了不便。” 使用场景当你发现需求中是体现部分与整体层次的结构时，以及你希望用户可以忽略组合对象与单个对象的不同，统一地使用组合结构中的所有对象时，就应该考虑用组合模式了。 好处组合模式这样就定义了包含人力资源部和财务部这些基本对象和分公司、办事处等组合对象的类层次结构。基本对象可以被组合成更复杂的组合对象，而这个组合对象又可以被组合，这样不断地递归下去，客户代码中，任何用到基本对象的地方都可以使用组合对象了。用户是不用关心到底是处理一个叶节点还是处理一个组合组件，也就用不着为定义组合而写一些选择判断语句了。组合模式让客户可以一致地使用组合结构和单个对象。任何用到基本对象的地方都可以使用组合对象。 装饰模式装饰模式（Decorator)，动态地给一个对象添加一些额外的职责，就增加功能来说，装饰模式比生成子类更为灵活。装饰模式顺序很重要。装饰模式是为已有功能动态地添加更多功能的一种方式。 例子实现过程有点套娃 使用场景当系统需要新功能的时候，是向旧的类中添加新的代码。这些新加的代码通常装饰了原有类的核心职责或主要行为。在主类中加入了新的字段，新的方法和新的逻辑，从而增加了主类的复杂度，就像你起初的那个‘人’类，而这些新加入的东西仅仅是为了满足一些只在某种特定情况下才会执行的特殊行为的需要。而装饰模式却提供了一个非常好的解决方案，它把每个要装饰的功能放在单独的类中，并让这个类包装它所要装饰的对象，因此，当需要执行特殊行为时，客户代码就可以在运行时根据需要有选择地、按顺序地使用装饰功能包装对象了 优点装饰模式的优点，把类中的装饰功能从类中搬移去除，这样可以简化原有的类这样做更大的好处就是有效地把类的核心职责和装饰功能区分开了。而且可以去除相关类中重复的装饰逻辑。 享元模式代理模式区别外观模式，适配器模式和桥接模式外观模式和适配器 都是对现存系统的封装，有人说外观模式其实就是另外一组对象的适配器，这种说法是不准确的，因为外观定义的是一个新的接口，而适配器则是复用一个原有的接口，适配器是使两个已有的接口协同工作，而外观则是为现存系统提供一个更为方便的访问接口。如果硬要说外观模式是适配，那么适配器是用来适配对象的，而外观模式则是用来适配整个子系统的。也就是说，外观模式所针对的对象的粒度更大。 个人理解：外观模式是新建一个类对原有的类进行封装功能，提供统一的接口，而适配器模式是对于原来的类进行继承，对相关类进行重写，并统一接口。 代理模式和外观模式代理模式和适配器模式","categories":[{"name":"编程","slug":"编程","permalink":"https://mrchenlearnspace.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://mrchenlearnspace.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"人物3渲2学习总结","slug":"人物3渲2学习总结","date":"2022-05-11T05:38:45.000Z","updated":"2022-11-14T14:22:02.340Z","comments":true,"path":"2022/05/11/人物3渲2学习总结/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/05/11/%E4%BA%BA%E7%89%A93%E6%B8%B22%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/","excerpt":"","text":"描边法线外扩法中文一般称为“法线外扩法”、“背面膨胀法”，日文资料中会称作「背面法」，它们指的是同一个技术 解决方式第一个Pass：正常打光和绘制第二个Pass： Vertex Shader阶段将顶点向顶点法线方向移动一定距离Rasterization阶段将Cull Mode设置为Cull Front 1234567891011121314151617181920212223242526272829303132333435363738394041424344Pass&#123;Name &quot;OUTLINE&quot;Cull FrontZWrite OnColorMask RGBBlend SrcAlpha OneMinusSrcAlpha CGPROGRAM #pragma vertex vert #pragma fragment frag #include &quot;UnityCG.cginc&quot; struct appdata &#123; float4 vertex : POSITION; float3 normal : NORMAL; float4 texCoord : TEXCOORD0; float4 vertexColor : COLOR; &#125;; struct v2f &#123; float4 pos : POSITION; float4 color : COLOR; float4 tex : TEXCOORD0; &#125;; sampler2D _MainTex; float _Outline; float4 _OutlineColor; v2f vert(appdata v) &#123; // just make a copy of incoming vertex data but scaled according to normal direction v2f o; o.pos = UnityObjectToClipPos(v.vertex); float3 norm = mul((float3x3)UNITY_MATRIX_IT_MV, v.normal); float2 offset = TransformViewToProjection(norm.xy); // float2 offset = (norm.xy); o.pos.xy += offset * _Outline*0.0001; o.tex = v.texCoord; o.color = v.vertexColor; return o; &#125; fixed4 frag (v2f i) : SV_Target &#123; half4 base_col = tex2D(_MainTex,i.tex); return _OutlineColor*base_col; &#125; ENDCG&#125; 缺点 描边出现断裂，或者出现了看起来很奇怪的描边解决方案：用法线刷修改顶点让顶点平滑，出现这个问题的原因是每个面的法线都是垂直于平面的，所以在边角处就连接不上了。一般这种问题的解决方案是另外存储一套平滑法线。具体做法是计算与该点位置相同的所有点的法线的平均值并存储在顶点上。 描边线条控制想眼睛，头发这种细节描边需要修正的头发，由于模型的复杂性，在使用法线外扩法时往往会出现不太想要的描边。为了防止出现这些不受欢迎的描边，可以给每个顶点设置一个深度值、将顶点埋进里面从而被遮挡住。《罪恶装备Xrd》里就将这个信息写入了顶点色B通道中。细节：由于法线外扩法是基于模型的，所以实际上对线条还是有较高的自由度来控制。如果想要做到有粗细变化的描边，可以参考罪恶装备Xrd中将粗细变化的数值写入顶点色当中。实际上就是一个外扩系数：数值越大，越向外扩，线条越粗。至于线条的颜色，如果顶点色或者其他UV通道够用，可以将描边颜色写进顶点里面。然后相乘。菲涅尔方程解决方法N*V适用于球形物体的描边问题但平面时不好控制轮廓线顶点着色器blender 的Freestyle解决方法他们首先通过预处理的方式提取那些感兴趣的边缘，保存到额外的Mesh资源上。在渲染时通过Geometry Shader将这些边缘绘制出来。出于性能跟兼容性问题还是尽量避免使用Geometry Shader的好。但是这种思路还是非常不错的，因为这种方式对线条的控制也有很高的自由度，并且相比起法线外扩法可以创造更多细节。而且目前Compute Shader已经相当成熟且普及了，所以考虑用Compute Shader＋软光栅的方式说不定也是一条走得通的道路。问题颜色不能自定义，塞到顶点色里面，而且性价比不高。基于图像空间的线条检测 参考文章通过检测场景图像中 Normal 和 Depth 的不连续性，我们可以获得细节较为丰富的勾线。无论场景的复杂性如何，这种方法的性能都是恒定的，我们还添加了对勾线颜色的色相、明度、饱和度的调整，使勾线更为自然。 常用的算法是Sobel算子缺点则是较难控制勾线的宽度，如果我们想实现距离相关的线宽，我们只能在几个像素的范围内调整它，因此基于图像的方法主要适用于场景线条渲染，对于靠近摄像头很近的物体，我们最好使用 Backface 的方法。看这里实现方式 对于后处理进行canny卷积我卷失败了，没卷出来以后有时间再搞。和上一方法有异曲同工之处。转化为灰度图进行canny卷积 打光皮肤和衣服部分多通道Ramp的shading方法 采用多层上色，我的效果好拉，没官方好看。 解释RampLayerSoftness越大越软阴影，小则硬我没将_TintBase 叠加上去我没加阴影是因为，当阴影加上后会映在人身上看起来就不二次元了。 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384Properties : [Header(Tint Base)] _DiffuseRamp (&quot;DiffuseRamp&quot;, 2D) = &quot;Black&quot; &#123;&#125; _SpecularRamp (&quot;SpecularRamp&quot;, 2D) = &quot;Black&quot; &#123;&#125; _TintBase (&quot;Tint Base&quot;, COLOR) = (0,0,0,1) [Header(RampLayer1)] _RampLayerOffset1 (&quot;RampLayerOffset1&quot;, Range(-0.5,0.5)) = 0.5 _TintLayer1 (&quot;Tint_Layer1&quot;, COLOR) = (0,0,0,1) [Header(RampLayer2)] _RampLayerOffset2 (&quot;RampLayerOffset2&quot;, Range(-0.5,0.5)) = 0.5 _RampLayerSoftness2 (&quot;RampLayerSoftness2&quot;, Range(0,1)) = 0.5 __TintLayer2 (&quot;Tint Layer2&quot;, COLOR) = (0,0,0,1) [Header(RampLayer3)] _RampLayerOffset3 (&quot;RampLayerOffset3&quot;, Range(-0.5,0.5)) = 0.5 _RampLayerSoftness3 (&quot;RampLayerSoftness3&quot;, Range(0,1)) = 0.5 __TintLayer3 (&quot;Tint Layer3&quot;, COLOR) = (0,0,0,1) [Header(Specular)] _Shineness (&quot;Shineness&quot;, Float) = 0.5 _SpecularColor (&quot;Specular Color&quot;, COLOR) = (0,0,0,1) _SpecularIntensity (&quot;SpecularIntensity&quot;, Float) = 1 _SpecularSmooth (&quot;Specular Smooth&quot;, Float) = 1Pass : sampler2D _DiffuseRamp; sampler2D _SpecularRamp; float4 _TintBase; float4 __TintLayer1; float _RampLayerOffset1; float4 __TintLayer2; float _RampLayerOffset2; float _RampLayerSoftness2; float4 __TintLayer3; float _RampLayerOffset3; float _RampLayerSoftness3; float _Shineness; float _SpecularIntensity; float4 _SpecularColor; float _SpecularSmooth;frag : half atten = LIGHT_ATTENUATION (i); half3 base_col = tex2D(_MainTex, i.uv).xyz; half3 normal_world= normalize(i.normalDir); half3 tangent_world= normalize(i.tangentDir); half3 binormal_world= normalize(i.binormalDir); half3 pos_world= normalize(i.pos_world); half3 normal_data = UnpackNormal(tex2D(_Normal,i.uv)); half3x3 TBN = half3x3 (tangent_world,binormal_world,normal_world); normal_world = mul(normal_data,TBN); half3 ViewDir = normalize(_WorldSpaceCameraPos.xyz-pos_world); half3 lightDir = normalize(_WorldSpaceLightPos0.xyz); //漫反射 half NdotL = max(0,dot(normal_world,lightDir)); half half_lambert = (NdotL+1.0)*0.5; //half half_lambert = half_lambert*ao //本来要乘上AO因为素材没有算了 half3 tint_Base_color1 = base_col; //第一层ramp half2 uv_ramp1 = half2(half_lambert+_RampLayerOffset1,0.5); half toon_diffuse1 = tex2D(_DiffuseRamp,uv_ramp1).r; half3 tint_color1 = lerp(half3(1,1,1),__TintLayer1,toon_diffuse1*__TintLayer1.a); //第二层ramp half2 uv_ramp2 = half2(half_lambert+_RampLayerOffset2,1-i.VertexColor.g+_RampLayerSoftness2);//1-i.VertexColor.g可以用_RampLayerSoftness2代替越大越柔和 half toon_diffuse2 = tex2D(_DiffuseRamp,uv_ramp2).g; half3 tint_color2 = lerp(half3(1,1,1),__TintLayer2,toon_diffuse2*__TintLayer2.a); //第三层ramp half2 uv_ramp3 = half2(half_lambert+_RampLayerOffset3,1-i.VertexColor.b+_RampLayerSoftness3);//1-i.VertexColor.b可以用_RampLayerSoftness3代替越大越柔和 half toon_diffuse3 = tex2D(_DiffuseRamp,uv_ramp3).b; half3 tint_color3 = lerp(half3(1,1,1),__TintLayer3,toon_diffuse3*__TintLayer3.a); half3 final_diffuse = tint_Base_color1 * tint_color1 *tint_color2 *tint_color3 ; //高光 //half3 half_R = normalize(lightDir+ViewDir); half3 R = normalize(reflect(-lightDir,normal_world)); half specular_term = max(pow(dot(R,ViewDir),_Shineness),0.0001);//本来要乘上AO因为素材没有算了 specular_term = smoothstep(0.5-_SpecularSmooth*0.5,0.5+_SpecularSmooth*0.5,specular_term);//风格化高光 half3 final_specular = base_col * specular_term *_SpecularColor *atten *_LightColor0.xyz *_SpecularIntensity ; half3 final_col = final_diffuse+final_specular ; 卖家秀 买家秀 边缘光，环境光 解释_MatCap是我自己加上去的，有点多余 实现1234567891011121314151617181920212223242526272829Properties : _MatCap (&quot;MatCap&quot;, 2D) = &quot;Black&quot; &#123;&#125; _Envmap (&quot;Envmap&quot;, Cube) = &quot;Black&quot; &#123;&#125; [Header(Rim)] _RimMin(&quot;RimMin&quot;, Range(-2,2)) = 0.5 _RimMax(&quot;RimMax&quot;, Range(-2,2)) = 0.5 _Roughness(&quot;Roughness&quot;, Float) = 0 _EnvIntensity(&quot;Env Intensity&quot;, Float) = 0pass : sampler2D _MatCap; samplerCUBE _Envmap; float _RimMax; float _RimMin; float _Roughness; float _EnvIntensity; float4 _Envmap_HDR;frag : //边缘光,环境光 half fresnel = 1- dot(ViewDir,normal_world); half rim = smoothstep(_RimMin,_RimMax,fresnel);//本来要乘上AO因为素材没有算了 half3 mc=tex2D(_MatCap,fresnel.xx); half3 r = reflect(-ViewDir,normal_world); half roughness = lerp(0,0.95,saturate(_Roughness)); roughness = roughness * (1.7-0.7*roughness ); half mip_level = roughness * 6.0; half4 color_cubemap = texCUBElod(_Envmap,half4(r,mip_level)); half3 color_env = DecodeHDR(color_cubemap,_Envmap_HDR); half3 final_env =color_env * rim * _EnvIntensity; 总体代码Character_Skin.shader 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243Shader &quot;Character/Skin&quot;&#123; Properties &#123; _MainTex (&quot;MainTex&quot;, 2D) = &quot;white&quot; &#123;&#125; _Normal(&quot;Normal&quot;,2D) = &quot;bump&quot; &#123;&#125; _DiffuseRamp (&quot;DiffuseRamp&quot;, 2D) = &quot;Black&quot; &#123;&#125; _Envmap (&quot;Envmap&quot;, Cube) = &quot;Black&quot; &#123;&#125; [Header(Tint Base)] _TintBase (&quot;Tint Base&quot;, COLOR) = (0,0,0,1) [Header(RampLayer1)] _RampLayerOffset1 (&quot;RampLayerOffset1&quot;, Range(-0.5,0.5)) = 0.5 _TintLayer1 (&quot;Tint_Layer1&quot;, COLOR) = (0,0,0,1) [Header(RampLayer2)] _RampLayerOffset2 (&quot;RampLayerOffset2&quot;, Range(-0.5,0.5)) = 0.5 _RampLayerSoftness2 (&quot;RampLayerSoftness2&quot;, Range(0,1)) = 0.5 __TintLayer2 (&quot;Tint Layer2&quot;, COLOR) = (0,0,0,1) [Header(RampLayer3)] _RampLayerOffset3 (&quot;RampLayerOffset3&quot;, Range(-0.5,0.5)) = 0.5 _RampLayerSoftness3 (&quot;RampLayerSoftness3&quot;, Range(0,1)) = 0.5 __TintLayer3 (&quot;Tint Layer3&quot;, COLOR) = (0,0,0,1) [Header(Specular)] _Shineness (&quot;Shineness&quot;, Float) = 0.5 _SpecularColor (&quot;Specular Color&quot;, COLOR) = (0,0,0,1) _SpecularIntensity (&quot;SpecularIntensity&quot;, Float) = 1 _SpecularSmooth (&quot;Specular Smooth&quot;, Float) = 1 [Header(Rim)] _RimMin(&quot;RimMin&quot;, Range(-2,2)) = 0.5 _RimMax(&quot;RimMax&quot;, Range(-2,2)) = 0.5 _Roughness(&quot;Roughness&quot;, Float) = 0 _EnvIntensity(&quot;Env Intensity&quot;, Float) = 0 [Header(Outline)] _Outline (&quot;Outline&quot;, Float) = 0.6 _OutlineColor (&quot;OutlineColor&quot;, COLOR) = (0,0,0,1) &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot;=&quot;Opaque&quot; &#125; LOD 100 Pass &#123; Name &quot;Skin&quot; Tags &#123; &quot;LightMode&quot; = &quot;ForwardBase&quot; &#125; CGPROGRAM #pragma vertex vert #pragma fragment frag #pragma multi_compile_fwdbase // make fog work #pragma multi_compile_fog #include &quot;AutoLight.cginc&quot; #include &quot;UnityCG.cginc&quot; struct appdata &#123; float4 vertex : POSITION; float2 texcoord0 : TEXCOORD0; float4 normal :NORMAL; float4 tangent:TANGENT; float4 VertexColor:COLOR; &#125;; struct v2f &#123; float4 pos : SV_POSITION; float2 uv : TEXCOORD0; float3 normalDir: TEXCOORD1; float3 tangentDir: TEXCOORD2; float3 binormalDir: TEXCOORD3; float4 VertexColor: TEXCOORD4; float3 pos_world: TEXCOORD5; LIGHTING_COORDS(6,7) &#125;; sampler2D _MainTex; sampler2D _Normal; sampler2D _DiffuseRamp; samplerCUBE _Envmap; float4 _LightColor0; float4 _MainTex_ST; float4 _TintBase; float4 __TintLayer1; float _RampLayerOffset1; float4 __TintLayer2; float _RampLayerOffset2; float _RampLayerSoftness2; float4 __TintLayer3; float _RampLayerOffset3; float _RampLayerSoftness3; float _Shineness; float _SpecularIntensity; float4 _SpecularColor; float _SpecularSmooth; float _RimMax; float _RimMin; float _Roughness; float _EnvIntensity; float4 _Envmap_HDR; v2f vert (appdata v) &#123; v2f o; o.pos = UnityObjectToClipPos(v.vertex); o.uv = v.texcoord0; o.normalDir=normalize( mul(unity_ObjectToWorld,v.normal).xyz); o.tangentDir=normalize( mul(unity_ObjectToWorld,v.tangent).xyz); o.pos_world=normalize( mul(unity_ObjectToWorld,v.vertex).xyz); o.binormalDir=normalize( cross(o.normalDir,o.tangentDir)*v.tangent.w); o.VertexColor = v.VertexColor; TRANSFER_VERTEX_TO_FRAGMENT(o); return o; &#125; half4 frag (v2f i) : SV_Target &#123; // sample the texture half atten = LIGHT_ATTENUATION (i); half3 base_col = tex2D(_MainTex, i.uv).xyz; half3 normal_world= normalize(i.normalDir); half3 tangent_world= normalize(i.tangentDir); half3 binormal_world= normalize(i.binormalDir); half3 pos_world= normalize(i.pos_world); half3 normal_data = UnpackNormal(tex2D(_Normal,i.uv)); half3x3 TBN = half3x3 (tangent_world,binormal_world,normal_world); normal_world = mul(normal_data,TBN); half3 ViewDir = normalize(_WorldSpaceCameraPos.xyz-pos_world); half3 lightDir = normalize(_WorldSpaceLightPos0.xyz); //漫反射 half NdotL = max(0,dot(normal_world,lightDir)); half half_lambert = (NdotL+1.0)*0.5; //half half_lambert = half_lambert*ao //本来要乘上AO因为素材没有算了 half3 tint_Base_color1 = base_col; //第一层ramp half2 uv_ramp1 = half2(half_lambert+_RampLayerOffset1,0.5); half toon_diffuse1 = tex2D(_DiffuseRamp,uv_ramp1).r; half3 tint_color1 = lerp(half3(1,1,1),__TintLayer1,toon_diffuse1*__TintLayer1.a); //第二层ramp half2 uv_ramp2 = half2(half_lambert+_RampLayerOffset2,1-i.VertexColor.g+_RampLayerSoftness2);//1-i.VertexColor.g可以用_RampLayerSoftness2代替越大越柔和 half toon_diffuse2 = tex2D(_DiffuseRamp,uv_ramp2).g; half3 tint_color2 = lerp(half3(1,1,1),__TintLayer2,toon_diffuse2*__TintLayer2.a); //第三层ramp half2 uv_ramp3 = half2(half_lambert+_RampLayerOffset3,1-i.VertexColor.b+_RampLayerSoftness3);//1-i.VertexColor.b可以用_RampLayerSoftness3代替越大越柔和 half toon_diffuse3 = tex2D(_DiffuseRamp,uv_ramp3).b; half3 tint_color3 = lerp(half3(1,1,1),__TintLayer3,toon_diffuse3*__TintLayer3.a); half3 final_diffuse = tint_Base_color1 * tint_color1 *tint_color2 *tint_color3 ; //高光 //half3 half_R = normalize(lightDir+ViewDir); half3 R = normalize(reflect(-lightDir,normal_world)); half specular_term = max(pow(dot(R,ViewDir),_Shineness),0.0001);//本来要乘上AO因为素材没有算了 specular_term = smoothstep(0.5-_SpecularSmooth*0.5,0.5+_SpecularSmooth*0.5,specular_term);//风格化高光 half3 final_specular = base_col * specular_term *_SpecularColor *atten *_LightColor0.xyz *_SpecularIntensity ; //边缘光,环境光 half NDL = NdotL&gt;0 ? 1:0; half fresnel = 1- dot(ViewDir,normal_world); half rim = smoothstep(_RimMin,_RimMax,fresnel);//本来要乘上AO因为素材没有算了 rim = rim * NDL; half3 r = reflect(-ViewDir,normal_world); half roughness = lerp(0,0.95,saturate(_Roughness)); roughness = roughness * (1.7-0.7*roughness ); half mip_level = roughness * 6.0; half4 color_cubemap = texCUBElod(_Envmap,half4(r,mip_level)); half3 color_env = DecodeHDR(color_cubemap,_Envmap_HDR); half3 final_env =color_env * rim * _EnvIntensity ; half3 final_col = final_diffuse+final_specular + final_env; return half4(final_col,1); &#125; ENDCG &#125; Pass &#123; Name &quot;OUTLINE&quot; Cull Front ZWrite On ColorMask RGB Blend SrcAlpha OneMinusSrcAlpha CGPROGRAM #pragma vertex vert #pragma fragment frag #include &quot;UnityCG.cginc&quot; struct appdata &#123; float4 vertex : POSITION; float3 normal : NORMAL; float4 texCoord : TEXCOORD0; float4 vertexColor : COLOR; &#125;; struct v2f &#123; float4 pos : POSITION; float4 color : COLOR; float4 tex : TEXCOORD0; &#125;; sampler2D _MainTex; float _Outline; float4 _OutlineColor; v2f vert(appdata v) &#123; // just make a copy of incoming vertex data but scaled according to normal direction v2f o; o.pos = UnityObjectToClipPos(v.vertex); float3 norm = mul((float3x3)UNITY_MATRIX_IT_MV, v.normal); float2 offset = TransformViewToProjection(norm.xy); // float2 offset = (norm.xy); o.pos.xy += offset * _Outline*0.0001; o.tex = v.texCoord; o.color = v.vertexColor; return o; &#125; fixed4 frag (v2f i) : SV_Target &#123; half4 base_col = tex2D(_MainTex,i.tex); return _OutlineColor*base_col; &#125; ENDCG &#125; &#125; FallBack &quot;Diffuse&quot;&#125; 眼睛眼睛折射效果，我的模型不需要进行眼球移动，也不适合做这个，所以没弄其中uworld和vworld是指UV线在世界空间下在方向。以下也没搞清除 关于头发遮挡眼睛，解决办法模板测试在进行眼睛渲染的Pass时，将模板值设置为某一固定值： 123456Stencil &#123; Ref 1 Comp Always Pass Replace Fail Replace&#125; 头发等遮挡部分 123456Stencil &#123; Ref 1 Comp NotEqual Pass Keep Fail Keep&#125; 将遮挡脸部透明部分写入顶点色A通道将头发渲染队列改为Transparent让最后输出的颜色的A等于顶点色A Eye.shader12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697Shader &quot;Character/Eye&quot;&#123; Properties &#123; _MainTex (&quot;MainTex&quot;, 2D) = &quot;white&quot; &#123;&#125; _Normal(&quot;Normal&quot;,2D) = &quot;bump&quot; &#123;&#125; &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot;=&quot;Opaque&quot; &#125; LOD 100 Pass &#123; Stencil &#123; Ref 1 Comp Always Pass Replace Fail Replace &#125; Name &quot;Eye&quot; Tags &#123; &quot;LightMode&quot; = &quot;ForwardBase&quot; &#125; CGPROGRAM #pragma vertex vert #pragma fragment frag #pragma multi_compile_fwdbase // make fog work #pragma multi_compile_fog #include &quot;AutoLight.cginc&quot; #include &quot;UnityCG.cginc&quot; struct appdata &#123; float4 vertex : POSITION; float2 texcoord0 : TEXCOORD0; float4 normal :NORMAL; float4 tangent:TANGENT; float4 VertexColor:COLOR; &#125;; struct v2f &#123; float4 pos : SV_POSITION; float2 uv : TEXCOORD0; float3 normalDir: TEXCOORD1; float3 tangentDir: TEXCOORD2; float3 binormalDir: TEXCOORD3; float4 VertexColor: TEXCOORD4; float3 pos_world: TEXCOORD5; LIGHTING_COORDS(6,7) &#125;; sampler2D _MainTex; sampler2D _Normal; float4 _MainTex_ST; v2f vert (appdata v) &#123; v2f o; o.pos = UnityObjectToClipPos(v.vertex); o.uv = v.texcoord0; o.normalDir=normalize( mul(unity_ObjectToWorld,v.normal).xyz); o.tangentDir=normalize( mul(unity_ObjectToWorld,v.tangent).xyz); o.pos_world=normalize( mul(unity_ObjectToWorld,v.vertex).xyz); o.binormalDir=normalize( cross(o.normalDir,o.tangentDir)*v.tangent.w); o.VertexColor = v.VertexColor; TRANSFER_VERTEX_TO_FRAGMENT(o); return o; &#125; fixed4 frag (v2f i) : SV_Target &#123; // sample the texture fixed4 base_col = tex2D(_MainTex, i.uv); half3 normal_world= normalize(i.normalDir); half3 tangent_world= normalize(i.tangentDir); half3 binormal_world= normalize(i.binormalDir); half3 normal_data = UnpackNormal(tex2D(_Normal,i.uv)); half3x3 TBN = half3x3 (tangent_world,binormal_world,normal_world); normal_world = mul(TBN,normal_world); half3 ViewDir = normalize(_WorldSpaceCameraPos.xyz-i.pos_world); half3 lightDir = normalize(_WorldSpaceLightPos0.xyz); half fresnel = 1- saturate(dot(normal_world ,ViewDir )); return base_col; // return half4(normal_world,1); &#125; ENDCG &#125; &#125; FallBack &quot;Diffuse&quot;&#125; 头发各项异性高光原理见移动人物渲染 使用shiftmap增强质感 123half2 uv_shift = i.uv * _ShiftRamp_ST.xy + _ShiftRamp_ST.zw;half3 shift_col = tex2D(_ShiftRamp,uv_shift);binormal_world = normalize( binormal_world + (shift_col+_ShiftOffset)* normal_world); _ShiftRamp_ST.x调节质感，_ShiftOffset调节头发的上下偏移 初版通过shininess调节柔和度调大shininess让过度变硬 123456789half StrandSpecular(half3 T, half3 V, half3 L, half exponent)&#123; half3 H = normalize(L + V); half dotTH = dot(T, H); half sinTH = sqrt(1 - dotTH * dotTH); half dirAtten = smoothstep(-1.0, 0.0, dotTH); return dirAtten * pow(sinTH, exponent);&#125;half3 final_specular = StrandSpecular(binormal_world,lightDir,ViewDir,_Shineness)*_SpecularColor; 改进把柔和度调整到0，1中通过shininess值 12345678910half NdotV = max(0.0 ,dot(normal_world , ViewDir));half3 H = normalize(lightDir+ViewDir);half NdotH = dot(normal_world ,H );half TdotH = dot(tangent_world ,H);half BdotH = dot(binormal_world ,H);BdotH /=_Shineness;half spec_term =exp(-(TdotH*TdotH+BdotH*BdotH)/(1.0+NdotH));half spec_atten = saturate(sqrt(max(0.0,half_lambert/NdotV)));half3 final_specular = spec_term*spec_atten*_SpecularColor; 在第二层高光叠加的时候再乘上一层shift_col当噪声 Hair.shader123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300// Upgrade NOTE: replaced &#x27;_Object2World&#x27; with &#x27;unity_ObjectToWorld&#x27;// Upgrade NOTE: replaced &#x27;mul(UNITY_MATRIX_MVP,*)&#x27; with &#x27;UnityObjectToClipPos(*)&#x27;Shader &quot;Character/Hair&quot;&#123; Properties &#123; _MainTex (&quot;MainTex&quot;, 2D) = &quot;white&quot; &#123;&#125; _Normal(&quot;Normal&quot;,2D) = &quot;bump&quot; &#123;&#125; _DiffuseRamp (&quot;DiffuseRamp&quot;, 2D) = &quot;Black&quot; &#123;&#125; _Envmap (&quot;Envmap&quot;, Cube) = &quot;Black&quot; &#123;&#125; _ShiftRamp(&quot;ShiftRamp&quot;,2D)=&quot;Black&quot;&#123;&#125; [Header(Tint Base)] _TintBase (&quot;Tint Base&quot;, COLOR) = (0,0,0,1) [Header(RampLayer1)] _RampLayerOffset1 (&quot;RampLayerOffset1&quot;, Range(-0.5,0.5)) = 0.5 _TintLayer1 (&quot;Tint_Layer1&quot;, COLOR) = (0,0,0,1) [Header(RampLayer2)] _RampLayerOffset2 (&quot;RampLayerOffset2&quot;, Range(-0.5,0.5)) = 0.5 _RampLayerSoftness2 (&quot;RampLayerSoftness2&quot;, Range(0,1)) = 0.5 __TintLayer2 (&quot;Tint Layer2&quot;, COLOR) = (0,0,0,1) [Header(RampLayer3)] _RampLayerOffset3 (&quot;RampLayerOffset3&quot;, Range(-0.5,0.5)) = 0.5 _RampLayerSoftness3 (&quot;RampLayerSoftness3&quot;, Range(0,1)) = 0.5 __TintLayer3 (&quot;Tint Layer3&quot;, COLOR) = (0,0,0,1) [Header(Specular1)] _SpecularColor1 (&quot;Specular Color1&quot;, COLOR) = (0,0,0,1) _SpecularIntensity1 (&quot;SpecularIntensity1&quot;, Float) = 1 _SpecularSmooth1 (&quot;Specular Smooth1&quot;, Range(0,1)) = 1 _ShiftOffset1 (&quot;Shift Offset1&quot;, Float) = 0 [Header(Specular2)] _SpecularColor2 (&quot;Specular Color2&quot;, COLOR) = (0,0,0,1) _SpecularIntensity2 (&quot;SpecularIntensity2&quot;, Float) = 1 _SpecularSmooth2 (&quot;Specular Smooth2&quot;, Range(0,1)) = 1 _ShiftOffset2 (&quot;Shift Offset2&quot;, Float) = 0 [Header(Rim)] _RimMin(&quot;RimMin&quot;, Range(-2,2)) = 0.5 _RimMax(&quot;RimMax&quot;, Range(-2,2)) = 0.5 _Roughness(&quot;Roughness&quot;, Float) = 0 _EnvIntensity(&quot;Env Intensity&quot;, Float) = 0 [Header(Outline)] _Outline (&quot;Outline&quot;, Float) = 0.6 _OutlineColor (&quot;OutlineColor&quot;, COLOR) = (0,0,0,1) &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot;=&quot;Opaque&quot; &#125; LOD 100 Pass &#123; Name &quot;Skin&quot; Tags &#123; &quot;LightMode&quot; = &quot;ForwardBase&quot; &#125; Stencil &#123; Ref 1 Comp NotEqual Pass Keep Fail Keep &#125; CGPROGRAM #pragma vertex vert #pragma fragment frag #pragma multi_compile_fwdbase // make fog work #pragma multi_compile_fog #include &quot;AutoLight.cginc&quot; #include &quot;UnityCG.cginc&quot; struct appdata &#123; float4 vertex : POSITION; float2 texcoord0 : TEXCOORD0; float4 normal :NORMAL; float4 tangent:TANGENT; float4 VertexColor:COLOR; &#125;; struct v2f &#123; float4 pos : SV_POSITION; float2 uv : TEXCOORD0; float3 normalDir: TEXCOORD1; float3 tangentDir: TEXCOORD2; float3 binormalDir: TEXCOORD3; float4 VertexColor: TEXCOORD4; float3 pos_world: TEXCOORD5; LIGHTING_COORDS(6,7) &#125;; sampler2D _MainTex; sampler2D _Normal; sampler2D _DiffuseRamp; samplerCUBE _Envmap; sampler2D _ShiftRamp; float4 _ShiftRamp_ST; float4 _LightColor0; float4 _MainTex_ST; float4 _TintBase; float4 __TintLayer1; float _RampLayerOffset1; float4 __TintLayer2; float _RampLayerOffset2; float _RampLayerSoftness2; float4 __TintLayer3; float _RampLayerOffset3; float _RampLayerSoftness3; float _ShiftOffset1; float _SpecularIntensity1; float4 _SpecularColor1; float _SpecularSmooth1; float _ShiftOffset2; float _SpecularIntensity2; float4 _SpecularColor2; float _SpecularSmooth2; float _RimMax; float _RimMin; float _Roughness; float _EnvIntensity; float4 _Envmap_HDR; v2f vert (appdata v) &#123; v2f o; o.pos = UnityObjectToClipPos(v.vertex); o.uv = v.texcoord0; o.normalDir=normalize( mul(unity_ObjectToWorld,v.normal).xyz); o.tangentDir=normalize( mul(unity_ObjectToWorld,v.tangent).xyz); o.pos_world=normalize( mul(unity_ObjectToWorld,v.vertex).xyz); o.binormalDir=normalize( cross(o.normalDir,o.tangentDir)*v.tangent.w); o.VertexColor = v.VertexColor; TRANSFER_VERTEX_TO_FRAGMENT(o); return o; &#125; half StrandSpecular(half3 T, half3 V, half3 L, half exponent) &#123; half3 H = normalize(L + V); half dotTH = dot(T, H); half sinTH = sqrt(1 - dotTH * dotTH); half dirAtten = smoothstep(-1.0, 0.0, dotTH); return dirAtten * pow(sinTH, exponent); &#125; half4 frag (v2f i) : SV_Target &#123; // sample the texture half atten = LIGHT_ATTENUATION (i); half3 base_col = tex2D(_MainTex, i.uv).xyz; half3 normal_world = normalize(i.normalDir); half3 tangent_world= normalize(i.tangentDir); half3 binormal_world= normalize(i.binormalDir); half3 normal_data = UnpackNormal(tex2D(_Normal,i.uv)); half3x3 TBN = half3x3 (tangent_world,binormal_world,normal_world); normal_world = mul(normal_data,TBN); half3 ViewDir = normalize(_WorldSpaceCameraPos.xyz-i.pos_world); half3 lightDir = normalize(_WorldSpaceLightPos0.xyz); //漫反射 half NdotL = max(0,dot(normal_world,lightDir)); half half_lambert = (NdotL+1.0)*0.5; //half half_lambert = half_lambert*ao //本来要乘上AO因为素材没有算了 half3 tint_Base_color1 = base_col; //第一层ramp half2 uv_ramp1 = half2(half_lambert+_RampLayerOffset1,0.5); half toon_diffuse1 = tex2D(_DiffuseRamp,uv_ramp1).r; half3 tint_color1 = lerp(half3(1,1,1),__TintLayer1,toon_diffuse1*__TintLayer1.a); //第二层ramp half2 uv_ramp2 = half2(half_lambert+_RampLayerOffset2,1-i.VertexColor.g+_RampLayerSoftness2);//1-i.VertexColor.g可以用_RampLayerSoftness2代替越大越柔和 half toon_diffuse2 = tex2D(_DiffuseRamp,uv_ramp2).g; half3 tint_color2 = lerp(half3(1,1,1),__TintLayer2,toon_diffuse2*__TintLayer2.a); //第三层ramp half2 uv_ramp3 = half2(half_lambert+_RampLayerOffset3,1-i.VertexColor.b+_RampLayerSoftness3);//1-i.VertexColor.b可以用_RampLayerSoftness3代替越大越柔和 half toon_diffuse3 = tex2D(_DiffuseRamp,uv_ramp3).b; half3 tint_color3 = lerp(half3(1,1,1),__TintLayer3,toon_diffuse3*__TintLayer3.a); half3 final_diffuse = tint_Base_color1 * tint_color1 *tint_color2 *tint_color3 ; //各向异性高光 half2 uv_shift = i.uv * _ShiftRamp_ST.xy + _ShiftRamp_ST.zw; half3 shift_col = tex2D(_ShiftRamp,uv_shift); half3 binormal_world1 = normalize( binormal_world + (shift_col+_ShiftOffset1)* normal_world); half3 binormal_world2 = normalize( binormal_world + (shift_col+_ShiftOffset2)* normal_world); half NdotV = max(0.00001 ,dot(normal_world , ViewDir)); half3 H = normalize(lightDir+ViewDir); half NdotH = dot(normal_world ,H ); half TdotH = dot(tangent_world ,H); half BdotH1 =dot(binormal_world1 ,H)/_SpecularSmooth1; half spec_term1 =exp(-(TdotH*TdotH+BdotH1*BdotH1)/(1.0+NdotH)); half spec_atten1 = saturate(sqrt(max(0.0,half_lambert/NdotV))); half3 specular_col1 = spec_term1* spec_atten1 * _LightColor0.xyz * _SpecularIntensity1 * atten * _SpecularColor1.xyz; half BdotH2 =dot(binormal_world2 ,H)/_SpecularSmooth2; half spec_term2 =exp(-(TdotH*TdotH+BdotH2*BdotH2)/(1.0+NdotH)); half spec_atten2 = saturate(sqrt(max(0.0,half_lambert/NdotV))); half3 specular_col2 = spec_term2* spec_atten2 * _LightColor0.xyz * _SpecularIntensity2 * atten *_SpecularColor1.xyz*shift_col; half3 final_specular = specular_col1 + specular_col2 ; //half3 half_R = normalize(lightDir+ViewDir); //half3 R = normalize(reflect(-lightDir,normal_world)); //half specular_term = max(pow(dot(R,ViewDir),_Shineness),0.0001);//本来要乘上AO因为素材没有算了 //specular_term = smoothstep(0.5-_SpecularSmooth*0.5,0.5+_SpecularSmooth*0.5,specular_term);//风格化高光 //half3 final_specular = base_col * specular_term *_SpecularColor *atten *_LightColor0.xyz *_SpecularIntensity ; //边缘光,环境光 half NDL = NdotL&gt;0 ? 1:0; half fresnel = 1- dot(ViewDir,normal_world); half rim = smoothstep(_RimMin,_RimMax,fresnel);//本来要乘上AO因为素材没有算了 rim = rim * NDL; half3 r = reflect(-ViewDir,normal_world); half roughness = lerp(0,0.95,saturate(_Roughness)); roughness = roughness * (1.7-0.7*roughness ); half mip_level = roughness * 6.0; half4 color_cubemap = texCUBElod(_Envmap,half4(r,mip_level)); half3 color_env = DecodeHDR(color_cubemap,_Envmap_HDR); half3 final_env =color_env * rim * _EnvIntensity ; half3 final_col = final_diffuse +final_specular +final_env; return half4(final_col,1); &#125; ENDCG &#125; Pass &#123; Name &quot;OUTLINE&quot; Cull Front ZWrite On ColorMask RGB Blend SrcAlpha OneMinusSrcAlpha CGPROGRAM #pragma vertex vert #pragma fragment frag #include &quot;UnityCG.cginc&quot; struct appdata &#123; float4 vertex : POSITION; float3 normal : NORMAL; float4 texCoord : TEXCOORD0; float4 vertexColor : COLOR; &#125;; struct v2f &#123; float4 pos : POSITION; float4 color : COLOR; float4 tex : TEXCOORD0; &#125;; sampler2D _MainTex; float _Outline; float4 _OutlineColor; v2f vert(appdata v) &#123; // just make a copy of incoming vertex data but scaled according to normal direction v2f o; o.pos = UnityObjectToClipPos(v.vertex); float3 norm = mul((float3x3)UNITY_MATRIX_IT_MV, v.normal); float2 offset = TransformViewToProjection(norm.xy); // float2 offset = (norm.xy); o.pos.xy += offset * _Outline*0.0001; o.tex = v.texCoord; o.color = v.vertexColor; return o; &#125; fixed4 frag (v2f i) : SV_Target &#123; half4 base_col = tex2D(_MainTex,i.tex); return _OutlineColor*base_col; &#125; ENDCG &#125; &#125; FallBack &quot;Diffuse&quot;&#125; 脸部在皮肤的基础上提亮一点。","categories":[{"name":"游戏","slug":"游戏","permalink":"https://mrchenlearnspace.github.io/categories/%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"Shader","slug":"Shader","permalink":"https://mrchenlearnspace.github.io/tags/Shader/"}]},{"title":"houdini导入渲染顶点动画流动图片","slug":"houdini导入渲染顶点动画流动图片","date":"2022-04-30T08:38:45.000Z","updated":"2022-11-14T14:24:21.678Z","comments":true,"path":"2022/04/30/houdini导入渲染顶点动画流动图片/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/04/30/houdini%E5%AF%BC%E5%85%A5%E6%B8%B2%E6%9F%93%E9%A1%B6%E7%82%B9%E5%8A%A8%E7%94%BB%E6%B5%81%E5%8A%A8%E5%9B%BE%E7%89%87/","excerpt":"","text":"VAT动画材料行代表顶点，列代表帧需要每个顶点从左到右循环偏移顶点即可 时间推移 合成流动的UV 核心 扩展：约数函数floor取小的那个数，floor(1.5)&#x3D;1 roundround是四舍五入 ceil取大的那个数，ceil(1.1)&#x3D;2 FlowPicture扰动渐变参数&#x3D;abs(frac(x)*2-1) 简略版","categories":[{"name":"游戏","slug":"游戏","permalink":"https://mrchenlearnspace.github.io/categories/%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"Shader","slug":"Shader","permalink":"https://mrchenlearnspace.github.io/tags/Shader/"}]},{"title":"特效篇溶解算法","slug":"特效篇溶解算法","date":"2022-04-25T08:38:45.000Z","updated":"2022-11-14T14:22:25.834Z","comments":true,"path":"2022/04/25/特效篇溶解算法/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/04/25/%E7%89%B9%E6%95%88%E7%AF%87%E6%BA%B6%E8%A7%A3%E7%AE%97%E6%B3%95/","excerpt":"","text":"简单的溶解渐变 溶解边缘 合成效果 改进1溶解边缘柔和 改进2加一定方向的溶解 加入炭化的效果加入Remap的图片，能够将燃烧的黑烟搞出来","categories":[{"name":"游戏","slug":"游戏","permalink":"https://mrchenlearnspace.github.io/categories/%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"Shader","slug":"Shader","permalink":"https://mrchenlearnspace.github.io/tags/Shader/"}]},{"title":"大话设计模式观后感之创建型模式","slug":"大话设计模式观后感之创建型模式","date":"2022-04-22T14:38:45.000Z","updated":"2022-11-14T14:20:41.314Z","comments":true,"path":"2022/04/22/大话设计模式观后感之创建型模式/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/04/22/%E5%A4%A7%E8%AF%9D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E8%A7%82%E5%90%8E%E6%84%9F%E4%B9%8B%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"创建型模式为什么我们需要创建型模式?创建型模式隐藏了这些类的实例是如何被创建和放在一起，整个系统关于这些对象所知道的是由抽象类所定义的接口。这样，创建型模式在创建了什么、谁创建它、它是怎么被创建的，以及何时创建这些方面提供了很大的灵活性。 当一个系统应该独立于它的产品创建、构成和表示时，应该考虑用创建性模式。建立相应数目的原型并克隆它们通常比每次用合适的状态手工实例化该类更方便一些 松耦合的理解这个问题首先要谈谈内聚性与耦合性内聚性描述的是一个例程内部组成部分之间相互联系的紧密程度。耦合性描述的是一个例程与其他例程之间联系的紧密程度。软件开发的目标应该是创建这样的例程:内部完整，也就是高内聚，而与其他例程之间的联系则是小巧、直接、可见、灵活的，这就是松耦合。 如何理解创建型模式存在的意义?创建型模式抽象了实例化的过程。它们帮助一个系统独立于如何创建、组合和表示它的那些对象。创建型模式都会将关于该系统使用哪些具体的类的信息封装起来。允许客户用结构和功能差别很大的‘产品’对象配置一个系统。配置可以是静态的，即在编译时指定，也可以是动态的,就是运行时再指定。 工厂方法的优势我觉得她们几位都可能设计出比我更加灵活的代码，但她们的实现也相对就更加复杂。通常设计应该是从工厂方法开始，当设计者发现需要更大的灵活性时，设计便会向其他创建型模式演化。当设计者在设计标准之间进行权衡的时候,了解多个创建型模式可以给设计者更多的选择余地. 简单工厂模式简单工厂模式是由一个工厂对象决定创建出哪一种产品类的实例。解决如何实例化对象的问题不属于23种GOF设计模式之一，不符合开放封闭原则每一次都要修改类。 工厂方法模式工厂方法模式，定义一个用于创建对象的接口，让子类决定实例化哪一个类。工厂方法使一个类的实例化延迟到其子类。将实例化方法写在concreteCreator类里面工厂方法模式和简单工厂的区别：简单工厂模式的最大优点在于工厂类中包含了必要的逻辑判断，根据客户端的选择条件动态实例化相关的类，对于客户端来说，去除了与具体产品的依赖。 缺点：由于每加一个产品，就需要加一个产品工厂的类，增加了额外的开发量。”通过加分工厂实例化加法运算类 12345678interface IFactory&#123; Operation CreateOperation ();&#125;class AddFactory : IFactory&#123; public Operation Create0peration ()&#123; return new OperationAdd (); &#125;&#125; 抽象工厂模式原版抽象工厂模式是提供一个创建一系列相关或相互依赖对象的接口，而无需指定它们具体的类。多个产品有一个或多个实现方式，就把同产品系列的抽象。工厂和产品都进行抽象 优点 最大的好处便是易于交换产品系列，由于具体工厂类，例如IFactory factory &#x3D;new AccessFactory().在一个应用中只需要在初始化的时候出现一次，这就使得改变一个应用的具体工厂变得非常容易，它只需要改变具体工厂即可使用不同的产品配置。 它让具体的创建实例过程与客户端分离，客户端是通过它们的抽象接口操纵实例，产品的具体类名也被具体工厂的实现分离，不会出现在客户代码中。 缺点修改时需要添加三个类，并需要修改抽象工厂类及抽象工厂子类。 简单工厂来改进与其用那么多工厂类，不如直接用一个简单工厂来实现，抛弃了IFactory、SqlserverFactory和 AccessFactory三个工厂类，取而代之的是DataAccess类，由于事先设置了db的值(Sqlserver或Access)，所以简单工厂的方法都不需要输入参数，这样在客户端就只需要 DataAccess.CreateUser()和 DataAccess.CreateDepartment()来生成具体的数据库访问类实例，客户端没有出现任何一个SOL Server或 Access的字样，达到了解耦的目的。这样就需要在 DataAccess类中每个方法的swicth 中加 case了。 男人的浪漫–反射Assembly.Load(“程序集名称”).CreateInstance(“命名空间.类名称”)所有在用简单工厂的地方，都可以考虑用反射技术来去除switch或 if，解除分支判断带来的耦合。 12345678910111213141516using Syetem.Reflection//引入反射，必须要写class DataAccess&#123; private static readonly string AssemblyName = &quot;抽象工厂模式&quot;;//程序集名称 private static readonly string db = &quot;Sqlserver&quot;;//数据库名称，可替换成Access public static IUser CreateUser() &#123; string className = AssemblyName + &quot;.&quot; +db +&quot;User&quot;; return (IUser)Assembly.Load (AssemblyName).CreateInstance (className); &#125; public static IDepartment CreateDepartment() &#123; string className = AssemblyName + &quot;.&quot; +db+ &quot;Department&quot;; return (IDepartment)Assembly.Load (AssemblyName).CreateInstance (className) ; &#125;&#125; 单例模式单例模式（Singleton)，保证一个类仅有一个实例，并提供一个访问它的全局访问点。通常我们可以让一个全局变量使得一个对象被访问，但它不能防止你实例化多个对象。一个最好的办法就是，让类自身负责保存它的唯一实例。这个类可以保证没有其他实例可以被创建，并且它可以提供一个访问该实例的方法。 单线程的实现Singleton类,定义一个GetInstance操作，允许客户访问它的唯一实例。GetInstance是一个静态方法，主要负责创建自己的唯一实例。 123456789101112131415class Singleton&#123; private static singleton instance; private Singleton ()&#123;//构造方法让其private，这就堵死了外界利用 //new创建此类实例的可能 ) public static singleton GetInstance ()&#123; //此方法是获得本类实例的唯一全局访问点 if (instance == null)&#123; //若实例不存在，则new一个新实例， //否则返回已有的实例 instance =new Singleton (); &#125; return instance; &#125;&#125; 客户端代码 1234567static void Main (string[] args)Singleton s1 = Singleton.GetInstance();Singleton s2 -Singleton.GetInstance ();if (s1 ==s2)&#123;Console.writeLine(&quot;两个对象是相同的实例。&quot;);)Console.Read() ; 多线程单例lock 是确保当一个线程位于代码的临界区时，另一个线程不进入临界区。如果其他线程试图进入锁定的代码，则它将一直等待(即被阻止)，直到该对象被释放。双重锁定 12345678910111213141516class singleton&#123; private static singleton instance; private static readonly object syncRoot= new object(); private singleton ()&#123; &#125; public static singleton GetInstance()&#123; if (instance == null)&#123;//先判断实例是否存在，不存在再加锁处理 lock (syncRoot)&#123; if (instance == null)&#123; instance = new singleton (); &#125; &#125; &#125; return instance; &#125;&#125; 建造者模式建造者模式（Builder)，将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。如果我们用了建造者模式，那么用户就只需指定需要建造的类型就可以得到它们，而具体建造的过程和细节就不需知道了。用处创建一些复杂的对象，这些对象内部构建间的建造顺序通常是稳定的，但对象内部的构建通常面临着复杂的变化。建造者模式是在当创建复杂对象的算法应该独立于该对象的组成部分以及它们的装配方式时适用的模式。好处就是使得建造代码与表示代码分离，由于建造者隐藏了该产品是如何组装的，所以若需要改变一个产品的内部表示，只需要再定义一个具体的建造者就可以了。Product类——产品类，由多个部件组成。 123456789101112class Product&#123; IList&lt;string&gt; parts =new List&lt;string&gt;(); public void Add (string part)//添加产品部件&#123; parts. Add (part); &#125; public void Show ()&#123; console.writeLine(&quot;\\n产品创建―-—-&quot;);//列举所有的产品部件 foreach (string part in parts)&#123; Console.writeLine (part); &#125; &#125;&#125; Builder类——抽象建造者类，确定产品由两个部件 PartA和PartB组成，并声明一个得到产品建造后结果的方法GetResult。 12345abstract class Builder&#123; public abstract void BuildPartA (); public abstract void BuildPartB (); public abstract Product GetResult();&#125; ConcreteBuilder1类——具体建造者类。 12345678910111213class ConcreteBuilder1 : Builder&#123; private Product product = new Product (); //建造具体的两个部件是部件A和部件B public override void BuildPartA ()&#123; product.Add(&quot;部件A&quot;); &#125; public override void BuildPartB()&#123; product. Add(&quot;部件B&quot;); &#125; public override Product GetResult(o)&#123; return product; &#125;&#125; ConcreteBuilder2类——具体建造者类。 12345678910111213class ConcreteBuilder2 :Builder&#123; private Product product = new Product (); //建造具体的两个部件是部件X和部件Y public override void BuildPartA()&#123; product. Add(&quot;部件x&quot;); &#125; public override void BuildPartB()&#123; product.Add(&quot;部件Y&quot;); &#125; public override Product GetResult()&#123; return product; &#125;&#125; Director类——指挥者类。 123456class Director&#123; public void Construct(Builder builder)&#123;//用来指挥建造过程 builder .BuildPartA (); builder. BuildPartB(); &#125;&#125; 例子 原型模式原型模式（Prototype)，用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。“原型模式其实就是从一个对象再创建另外一个可定制的对象，而且不需知道任何创建的细节。 原版原型类 12345678910abstract class Prototype&#123; private string id; public Prototype (string id)&#123; this.id = id; &#125; public string Id&#123; get &#123; return id; ) &#125; public abstract Prototype Clone (); //抽象类关键就是有这样一个Clone方法&#125; 具体原型类 1234567891011class ConcretePrototypel : Prototype&#123; public ConcretePrototype1 (string id): base (id)&#123; &#125; public override Prototype Clone ()&#123; return (Prototype)this.MemberwiseClone() ; //创建当前对象的浅表副本。方法是创建一个新对象，然后将当前对象 //的非静态字段复制到该新对象。如果字段是值类型的，则对该字段执 //行逐位复制。如果字段是引用类型,则复制引用但不复制引用的对象; //因此,原始对象及其副本引用同对象[MSDN] &#125;&#125; 客户端代码 123456static void Main (string[]args)&#123;ConcretePrototypel p1 = new ConcretePrototype1(&quot;I&quot;);ConcretePrototypel cl =(ConcretePrototype1)p1.clone() ;Console.writeLine ( &quot;cloned: &#123;0&#125;&quot;, c1.Id);Console.Read() ;//克隆类ConcretePrototype1的对象pl就能得到新的实例cl&#125; 浅复制和深复制浅复制，被复制对象的所有变量都含有与原来的对象相同的值，而所有的对其他对象的引用都仍然指向原来的对象。深复制，深复制把引用对象的变量指向复制过的新对象，而不是原有的被引用的对象。 Csharp更新.NET在System命名空间中提供了ICloneable接口,其中就是唯一的一个方法Clone()，这样你就只需要实现这个接口就可以完成原型模式了。","categories":[{"name":"编程","slug":"编程","permalink":"https://mrchenlearnspace.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://mrchenlearnspace.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"Games104第6节记录","slug":"Games104第6节记录","date":"2022-04-18T12:38:45.000Z","updated":"2022-11-14T14:23:48.783Z","comments":true,"path":"2022/04/18/Games104第6节记录/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/04/18/Games104%E7%AC%AC6%E8%8A%82%E8%AE%B0%E5%BD%95/","excerpt":"","text":"地形渲染height field 高层图 渲染地形高层图，地形分成不同的网格，通过高层图修改相关顶点。不适用于开饭大世界 地形渲染的方法 三角形剖分通过二叉树的结构 通过四叉树的结构 求解四边形网格中的t节点 多出来的点吸附连接到相邻的点，形成没面积的三角形。 GPU表面细化 网格着色管线 实时变化的地形 静态地形 私货 切片合成 地表材质极大数量的材质处理 通过高度的权重进行插值。 视差贴图 虚拟纹理 浮点数的精度溢出 解决方案 树渲染 装饰渲染 道路系统和贴片系统 天空之神 大气 进入物体进行光源散射 h海拔高度，1+cos的平方是腰果状 米氏散射气溶胶是米氏散射 能力的吸收 单次散射和多次散射 对比 解决方案 空气通透度 预计算大气散射的挑战 预先计算成本 ​ ．多次散射迭代是非常昂贵的 难在低端设备上生成大气LUT移动)环境的创作和动态调整艺术家不能随意改变散射系数很难渲染像天气从阳光到雨雾，行星之间的太空旅行运行时渲染成本昂贵的逐像素多维高维纹理采样用于透光性LUT和多散射LUT(总是需要向下采样以提高效率) 画云 用网格形成云 贴图 体积云 优点．真实的云的形状可能出现大规模云支持动态天气动态体积照明和阴影 缺点必须考虑效率 原理","categories":[{"name":"计算机图形学","slug":"计算机图形学","permalink":"https://mrchenlearnspace.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}],"tags":[{"name":"引擎制作","slug":"引擎制作","permalink":"https://mrchenlearnspace.github.io/tags/%E5%BC%95%E6%93%8E%E5%88%B6%E4%BD%9C/"}]},{"title":"Games104第7节记录","slug":"Games104第7节记录","date":"2022-04-18T12:38:45.000Z","updated":"2022-11-14T14:23:54.420Z","comments":true,"path":"2022/04/18/Games104第7节记录/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/04/18/Games104%E7%AC%AC7%E8%8A%82%E8%AE%B0%E5%BD%95/","excerpt":"","text":"环境光遮蔽(Ambient Occasion) 预计算AO采用光线追踪离线计算AO，并将结果存储到纹理中，这种方法广泛应用于物体建模过程中： 额外的仓储成本 仅适用于静态对象屏幕空间环境遮挡 在视空间中每个像素p周围的球体中生成N个随机样本 通过比较深度与深度缓冲来测试样本闭塞 样本点的平均可见性来近似AOSSAO+回想一下AO方程实际上是在法向半球上做的HBAO Horizon-based Ambient Occlusion使用深度缓冲作为高度场在水平角以下的2D表面射线被遮挡 使用深度缓冲区作为2D表面上的高度场 从水平角直接在2D和近似AO中跟踪射线GTAO Ground Truth-based Ambient OcclusionGTAO引入了缺失余弦因子，消除了衰减函数，并增加了多跳的快速逼近Ray-Tracing Ambient Occlusion使用RTT硬件从每个屏幕像素投射光线1 spp(每像素样本)对远场遮挡效果很好用2-4 spp，可以恢复接触区域的详细闭塞foghigh fogVoxel-based Volumetric Fog基于体素化的雾反走样 Anti-aliasing反走样的原因混叠是由高频信号与高频信号产生的一系列图像伪影。有限的渲染分辨率的采样不足解决方案基于屏幕的抗锯齿方案的一般策略是使用抽样模式获得更多的样本，然后加权和样本相加产生像素颜色Super-sample AA (SSAA) and Multi-sample AA (MSAA)FXAA (Fast Approximate Anti-aliasing)基于1x渲染图像的抗锯齿．根据亮度找到边缘像素计算每个边缘像素的偏移量．重新采样边缘像素的偏移量与邻居混合Blend Nearby PixelsTAA (Temporal Anti-aliasing)利用时空滤波方法提高机管局运动稳定性Post-process在3D图形中，后处理是指将应用于最终图像的任何算法。这可以是出于风格上的原因(色彩校正、对比等)，也可以是出于现实原因(色调映射、景深等)。BloomDetect Bright Area by Threshold Tone Mapping 没有办法在SDR设备中直接显示HDR图像 色调映射功能的目的是将宽范围的高动态范围(HDR)颜色映射到显示器可以输出的标准动态范围(SDR)Tone Mapping CurveACES 学院色彩编码系统 主要用于电影和动画 有趣的范例和转换 有用的部分 在HDR中应用颜色分级是好的 将一个固定的管道连接到最终的OTD转换阶段的想法是好的 将艺术意图与支持不同设备的机制分离开来HDR and SDR PipelineHDR &#x2F; SDR之间的视觉一致性之前的SDR颜色管道相似的SDR结果高质量高性能对美术团队的干扰最小从当前的颜色管道简单过渡掌握HDR和SDR所需的额外开销最小 Color GradingLookup Table (LUT) LUT用于根据LUT中包含的数据将源像素的输入颜色值重新映射为新的输出值 LUT可以被认为是一种可以应用于图像或镜头的颜色预设渲染管线渲染管道是所有渲染操作执行和资源分配的管理顺序Forward RenderingDeferred Rendering优点光照只计算可见的片段G-Buffer的数据可以用于后处理缺点高内存和带宽成本不支持透明对象对MSAA不友好 前进+(基于贴图的前进)渲染深度预压(防止透支&#x2F;提供瓷砖深度范围)平铺光照剔除(输出:每个平铺的光照列表)每个物体的阴影(PS:通过光剔除计算的光列表迭代) 挑战复杂的并行工作需要与复杂的资源依赖性同步大量生命周期小于一帧的瞬态资源复杂资源状态管理不需要大量的用户低级知识，就可以利用新暴露的GPU特性 屏幕撕裂 原因在大多数游戏中，你的GPU帧率是非常不稳定的当新的GPU帧在最后一帧的中间更新时，屏幕撕裂发生 解决方法v-Sync Technology用垂直刷新同步缓冲区交换称为V-syncV-Sync可以用来防止撕裂，但帧率降低，鼠标延迟和口吃破坏游戏","categories":[{"name":"计算机图形学","slug":"计算机图形学","permalink":"https://mrchenlearnspace.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}],"tags":[{"name":"引擎制作","slug":"引擎制作","permalink":"https://mrchenlearnspace.github.io/tags/%E5%BC%95%E6%93%8E%E5%88%B6%E4%BD%9C/"}]},{"title":"大话设计模式观后感之设计原则","slug":"大话设计模式观后感之设计原则","date":"2022-04-17T16:38:45.000Z","updated":"2022-11-14T14:21:02.648Z","comments":true,"path":"2022/04/18/大话设计模式观后感之设计原则/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/04/18/%E5%A4%A7%E8%AF%9D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E8%A7%82%E5%90%8E%E6%84%9F%E4%B9%8B%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/","excerpt":"","text":"单一职责原则就一个类而言，应该仅有一个引起它变化的原因 一个类不应该搞得很复杂，当傅老师黑魂教程中处理玩家数据时新建一个ActorData来装载玩家数据，ActorController来改变数据。一个类承担某种职责。 里氏替换原则子类型必须能够代替掉它们的父类型 可以理解为多态，只有子类可以替换掉父类，软件单位的功能不受到影响时，父类才能真正的被复用，而子类也能够在父类的基础上增加新行为。如果鸟类里面加入了飞的功能，那么企鹅类是不会飞的，所以不能继承。由于子类型的可替换性才使得使用父类类型的模块无需修改的情况下可以扩展 开放封闭原则软件实体（类、模块、函数等）应该可以扩展，但是不可修改 原来的代码能跑就不要去动它，要修改可以将其组合或者继承变成新的类进行扩展，书上有一点说的很好，在最开始的时候假设程序不会发生变化，当变化发生时再去创建抽象隔离，以此简化发生的同类变化，emm，虽然重构麻烦，如果项目不是很大可以考虑，毕竟为了后面长期变化做准备，刚看完的时候就是想太多，设计来设计去根本没动手，不如先动手做一个原型以后再改 依赖倒置原则 高层模块不应该依赖低层模块，应该都依赖于抽象 抽象不应该依赖于细节，细节应该依赖于抽象 高层模块通过调用低层模块中的函数进行数据处理。 高层模块关联抽象，高层模块可以调用抽象类中的函数，而不同低层模块可以复用函数，只需要实例化不同的低层模块便能达到灵活切换不同的低层模块函数。 也叫依赖倒转原则，依赖倒转是面向对象设计的标志，整个程序所有的依赖关系都应该是终止于抽象类或接口。 迪米特法则如果两个类不必彼此直接通信，那么这两个类就不应当发生直接的相互作用，如果一个类需要调用另一个类的某一个方法的话，可以通过第三者转发这个调用。 也叫最少知识原则，就像mvc架构升级到mvp架构一样，取消了m到v的直接联系。在类的结构设计上，每一个类都应当尽量降低成员的访问权限。 迪米特法则其根本思想，是强调了类之间的松耦合。我们在程序设计时，类之间的耦合越弱，越有利于复用，一个处在弱耦合的类被修改，不会对有关系的类造成波及。也就是说,信息的隐藏促进了软件的复用。” 合成&#x2F;聚合复用原则尽量使用合成&#x2F;聚合，尽量不要使用类继承 合成(Composition，也有翻译成组合）和聚合(Aggregation)都是关联的特殊种类。聚合表示一种弱的‘拥有’关系，体现的是A对象可以包含B对象，但B对象不是A对象的一部分;合成则是一种强的‘拥有’关系，体现了严格的部分和整体的关系，部分和整体的生命周期一样。优先使用对象的合成&#x2F;聚合将有助你保持每个类被封装，并集中在单个任务上。这样类和类继承层次会保持较小规模，并且不太可能增长为不可控制的庞然大物。 大雁有两个翅膀，翅膀与大雁是部分和整体的关系，并且它们的生命周期是相同的，于是大雁和翅膀就是合成关系。而大雁是群居动物，所以每只大雁都是属于一个雁群，一个雁群可以有多只大雁，所以大雁和雁群是聚合关系。” 接口隔离原则大话设计模式没讲此原则，个人猜测作者应该是认为和单一职责原则差不多吧 客户端不应该依赖它不需要的接口，即一个类对另一个类的依赖应该建立在最小的接口上。 将一个复杂且大的接口拆分成小的几个接口，是每一个接口的功能更单一。更灵活。 拓展MVC -Model(数据层):负责管理业务逻辑和处理网络或数据库API。-View(视图层):让数据层的数据可视化。在Android中对应用户交互、UI绘制等。-Controller (逻辑层)∶获得用户行为的通知，并根据需要更新Model。 优点Model类没有对Android类的任何引用，因此可以直接进行单元测试。Controller不会扩展或实现任何Android类，并且应该引用View的接口类。通过这种方式，也可以对控制器进行单元测试。如果View遵循单一责任原则，那么它们的角色就是为每个用户事件更新Controller，只显示Model中的数据，而不实现任何业务逻辑。在这种理想的作用下，UI测试应该足以覆盖所有的View的功能。总结以上介绍我们发现，MVC模式高度支持职责的分离。这种优势不仅增加了代码的可测试性，而且使其更容易扩展，从而可以相当容易地实现新功能。 缺点代码相对冗余。我们知道，MVC模式中View对Model是有着强依赖的。当View非常复杂的时候，为了最小化View中的逻辑，Model应该能够为要显示的每个视图提供可测试的方法——这将增加大量的类和方法。灵活性较低。由于View依赖于Controller和TModel，Ul逻辑中的一个更改可能导致需要修改很多类，这降低了灵活性，并且导致UI难以测试。可维护性低。Android的视图组件中，有着非常明显的生命周期，如Activity、Fragment等。对于MVC模式，我们有时不得不将处理视图逻辑的代码都写在这些组件中，造成它们十分臃肿。所以,Android中最初的MVC架构问题显而易见:过于臃肿的Controller层大大降低了工程的可维护性及可测试性。 MVP Model(数据层)。负责管理业务逻辑和处理网络或数据库API。 View(视图层)。显示数据并将用户操作的信息通知给Presenter。 Presenter(逻辑层)。从Model中检索数据，应用UI逻辑并管理View的状态，决定显示什么，以及对View的事件做出响应。 优点相对于MVC，MVP模式设计思路的核心是提出了Presenter层，它是View层与Model层沟通的桥梁，对业务逻辑进行处理。这更符合了我们理想中的单一职责原则。 缺点 接口粒度难以掌控。MVP模式将模块职责进行了良好的分离。但在开发小规模App或原型时，这似乎增加了开销——对于每个业务场景，我们都要写Activity-View-Presenter-Contract这4个类。为了缓解这种情况，一些开发者删除了Contract接口类和Presenter的接口。另外，Presenter 与View的交互是通过接口实现的,如果接口粒度过大，解耦程度就不高，反之会造成接口数量暴增的情况。从工程的严谨角度来说，这或许并不是缺点，只是创造一个良好工程架构带来的额外工作量。 Presenter逻辑容易过重。当我们将UI的逻辑移动到Presenter中时，Presenter变成了有数千行代码的类，或许会难以维护。要解决这个问题，我们只可能更多地拆分代码，创建便于单元测试的单一职责的类。 Presenter和View相互引用。我们在Presenter和View中都会保持一份对方的引用，所以需要用subscribe和unsubscribe来绑定和解除绑定。在操作UI的时候，我们需要判断UI生命周期，否则容易造成内存泄漏。 MVVM Model(数据模型):与ViewModel配合，可以获取和保存数据。 View(视图):即将用户的动作通知给ViewModel(视图模型)。 ViewModel(视图模型):暴露公共属性与View相关的数据流，通常为Model和View的绑定关系。 优点如果MVP模式意味着Presenter直接告诉View要显示的内容，那么在MVVM中, ViewModel会公开Views可以绑定的事件流。这样ViewModel不再需要保持对View的引用，但发挥了Presenter一样的作用。这也意味着MVP模式所需的所有接口现在都被删除了。这对介意接口数量过多的开发者来说是个福音。View还会通知ViewModel进行不同的操作。因此，MVM模式支持View和ViewModel之间的双向数据绑定，并且View和ViewModel之间存在多对一关系。View具有对ViewModel的引用，但ViewModel没有关于View的信息。因为数据的使用者应该知道生产者，但生产者ViewModel不需要知道，也不关心谁使用数据。 缺点1）需要更多精力定位Bug。由于双向绑定，视图中的异常排查起来会比较麻烦，你需要检查View中的代码，还需要检查Model中的代码。另外你可能多处复用了Model，一个地方导致的异常可能会扩散到其他地方，定位错误源可能并不会太简单。2）通用的View需要更好的设计。当一个View要变成通用组件时，该View对应的Model通常不能复用。在整体架构设计不够完善时，我们很容易创建一些冗余的Model。","categories":[{"name":"编程","slug":"编程","permalink":"https://mrchenlearnspace.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://mrchenlearnspace.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"移动端人物渲染","slug":"移动端人物渲染","date":"2022-04-14T12:38:45.000Z","updated":"2022-11-14T14:23:00.976Z","comments":true,"path":"2022/04/14/移动端人物渲染/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/04/14/%E7%A7%BB%E5%8A%A8%E7%AB%AF%E4%BA%BA%E7%89%A9%E6%B8%B2%E6%9F%93/","excerpt":"","text":"模型与贴图分析模型导入武器时属于泛型。 psk导入模型时3dmax效果比blender好，blender的模型不会平滑，选用3dmax加载模型。 贴图分析Albedo 贴图包含金属非金属部分的基本颜色 combmap 贴图R通道是roughness 粗糙度 G通道是金属度 B，如果皮肤通道为红色部分地方为蓝色就是皮肤部分 法线贴图见之前文章 光照框架直接光照反射lambert1half half_lambert = (diffuse_term+1.0)*0.5; SSS 散光 12345half skin_area = 1- comb_map.b;//获取颜色部分half2 uv_lut = float2(min(1, diffuse_term*atten +_LUTOffset),_CurveOffset);//将颜色分布在光照边缘half3 lut_color = tex2D(_SSSTrick,uv_lut);half3 sss_diffuse = lut_color *base_col*_LightColor0.xyz* half_lambert;//散射部分光照half3 diffuse = lerp(comm_diffuse,sss_diffuse,skin_area);//区分皮肤和非皮肤部分 直接光镜面反射Blin-Phong利用V+L代替reflect(-L,N) KK各项异性 光照射头发、不锈钢锅底，光碟会出现这样的现象。头发可以去除间接光的漫反射。 简单原理版 1234567891011half3 half_dir =normalize( light_dir+view_dir);//得到半角向量 half2 uv_shift = i.texcoord * _ShiftNoise_ST.xy+_ShiftNoise_ST.zw;//控制发丝密度 half shiftnoise = tex2D(_ShiftNoise,uv_shift).r; shiftnoise =(shiftnoise*2.0-1.0)*_NoiseIntensity;//从-1 - 1 映射到 0 - 1 half3 b_offset = normal_dir*(_Shiftoffset+shiftnoise);//法线方向偏移（上下移动） binormal_dir = normalize(binormal_dir+ b_offset); half TdotN=dot(binormal_dir,half_dir); half sinTH = sqrt(1-TdotN*TdotN); fixed3 specular_color = pow(max(0,sinTH),_Shininess)//将公式 *_LightColor0.xyz; ​ _ShiftNoise 头发部分体现,调了半天没调好，开摆。 1234567891011121314151617181920212223242526half roughness = 0.2; half3 half_dir =normalize( light_dir+view_dir); half2 uv_Anoise = i.texcoord*_AnoiseMap_ST.xy+_AnoiseMap_ST.zw; half3 aniso_noise = tex2D(_AnoiseMap,uv_Anoise); half NdotH = dot(normal_dir,half_dir); half TdotH = dot(tangent_dir,half_dir); half NdotV = max(0, dot(normal_dir,view_dir)); half aniso_atten = saturate(sqrt(max(0,half_lambert/NdotV)))*atten; //spec1 half3 specular_color1 = _SpecularColor1 + base_col; half3 aniso_offset1 = normal_dir *(aniso_noise*_SpecNoise1+_Shiftoffset1); half3 binormal_dir1 = normalize(binormal_dir + aniso_offset1); half BdotH1 = dot(binormal_dir1,half_dir)/ _SpecShininess1; half3 specular_term1 = exp(-(TdotH*TdotH+BdotH1*BdotH1)/(1.0+NdotH)); half3 specular1 = specular_term1*aniso_atten*specular_color1*_LightColor0.xyz; half3 specular_color2 = _SpecularColor2 + base_col; half3 aniso_offset2 = normal_dir *(aniso_noise*_SpecNoise2+_Shiftoffset2); half3 binormal_dir2 = normalize(binormal_dir + aniso_offset2); half BdotH2 = dot(binormal_dir2,half_dir)/ _SpecShininess2; half3 specular_term2 = exp(-(TdotH*TdotH+BdotH2*BdotH2)/(1.0+NdotH)); half3 specular2 = specular_term2*aniso_atten*specular_color2*_LightColor0.xyz; half3 specular = specular1+specular2; col.xyz+=specular; ACES_Tonemapping12345678910float3 ACES_Tonemapping(float3 x)&#123; float a = 2.51f; float b = 0.03f; float c = 2.43f; float d = 0.59f; float e = 0.14f; float3 encode_color = saturate((x*(a*x + b)) / (x*(c*x + d) + e)); return encode_color;&#125;; 宏开关1234567891011121314//Properties[Toggle(_D_ok)] _DiffuseCheck(&quot;_DiffuseCheck&quot;,Float) = 1.0 //Pass#pragma shader_feature _D_ok; #ifdef _D_ok one#else two#endif 或者把 1#pragma shader_feature _D_ok; 换成 1#pragma multi_compile _D_ok; 人物代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177Shader &quot;Human&quot;&#123; Properties &#123; _Diffuse(&quot;Diffuse&quot;, 2D) = &quot;white&quot; &#123;&#125; _Normal(&quot;Normal&quot;, 2D) = &quot;bump&quot; &#123;&#125; _NormalIntensity(&quot;Normal Intensity&quot;, Float) = 1.0 _Combmap(&quot;Combmap&quot;, 2D) = &quot;black&quot; &#123;&#125; _SSSTrick(&quot;SSSTrick&quot;, 2D) = &quot;black&quot; &#123;&#125; _CurveOffset(&quot;Curve Offset&quot;, Range(-1,1)) = 1.0 _LUTOffset(&quot;LUT Offset&quot;, Range(-1,1)) = 1.0 _SpecShininess(&quot;Spec Shininess&quot;, Float) = 1.0 _EnvMap(&quot;EnvMap&quot;, Cube) = &quot;black&quot; &#123;&#125; _Expose(&quot;Expose&quot;, Float) = 1.0 [HideInInspector]custom_SHAr(&quot;Custom SHAr&quot;, Vector) = (0, 0, 0, 0) [HideInInspector]custom_SHAg(&quot;Custom SHAg&quot;, Vector) = (0, 0, 0, 0) [HideInInspector]custom_SHAb(&quot;Custom SHAb&quot;, Vector) = (0, 0, 0, 0) [HideInInspector]custom_SHBr(&quot;Custom SHBr&quot;, Vector) = (0, 0, 0, 0) [HideInInspector]custom_SHBg(&quot;Custom SHBg&quot;, Vector) = (0, 0, 0, 0) [HideInInspector]custom_SHBb(&quot;Custom SHBb&quot;, Vector) = (0, 0, 0, 0) [HideInInspector]custom_SHC(&quot;Custom SHC&quot;, Vector) = (0, 0, 0, 1) &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot;=&quot;Opaque&quot; &#125; LOD 100 Pass &#123; Tags &#123; &quot;LightMode&quot; = &quot;ForwardBase&quot; &#125; CGPROGRAM #pragma vertex vert #pragma fragment frag #pragma multi_compile_fwdbase #include &quot;AutoLight.cginc&quot; #include &quot;UnityCG.cginc&quot; struct appdata &#123; float4 vertex : POSITION; float2 uv : TEXCOORD0; float3 normal:NORMAL; float4 tangent:TANGENT; &#125;; struct v2f &#123; float2 texcoord : TEXCOORD0; float4 pos : SV_POSITION; float3 normal_world:TEXCOORD1; float3 binormal_world:TEXCOORD2; float3 tangent_world:TEXCOORD3; float3 pos_world:TEXCOORD4; LIGHTING_COORDS(5,6) &#125;; sampler2D _Diffuse; float4 _Diffuse_ST; sampler2D _Normal; float _NormalIntensity; float _SpecShininess; float _Expose; float4 _LightColor0; sampler2D _Combmap; sampler2D _SSSTrick; samplerCUBE _EnvMap; float4 _EnvMap_HDR; float _CurveOffset; float _LUTOffset; float4 custom_SHAr; float4 custom_SHAg; float4 custom_SHAb; float4 custom_SHBr; float4 custom_SHBg; float4 custom_SHBb; float4 custom_SHC; float3 SH(half3 normal_dir) &#123; float4 normalForSH = float4(normal_dir, 1.0); //SHEvalLinearL0L1 half3 x; x.r = dot(custom_SHAr, normalForSH); x.g = dot(custom_SHAg, normalForSH); x.b = dot(custom_SHAb, normalForSH); //SHEvalLinearL2 half3 x1, x2; // 4 of the quadratic (L2) polynomials half4 vB = normalForSH.xyzz * normalForSH.yzzx; x1.r = dot(custom_SHBr, vB); x1.g = dot(custom_SHBg, vB); x1.b = dot(custom_SHBb, vB); // Final (5th) quadratic (L2) polynomial half vC = normalForSH.x*normalForSH.x - normalForSH.y*normalForSH.y; x2 = custom_SHC.rgb * vC; float3 sh = max(float3(0.0, 0.0, 0.0), (x + x1 + x2)); sh = pow(sh, 1.0 / 2.2); return sh; &#125; v2f vert (appdata v) &#123; v2f o; o.pos = UnityObjectToClipPos(v.vertex); o.texcoord =v.uv; o.normal_world = normalize(mul(float4(v.normal,0.0),unity_WorldToObject)).xyz; o.tangent_world = normalize(mul(unity_ObjectToWorld,float4(v.tangent.xyz,0.0))); o.pos_world = normalize(mul(unity_ObjectToWorld,float4(v.vertex.xyz,0.0))); o.binormal_world =normalize(cross(o.normal_world,o.tangent_world)*v.tangent.w); TRANSFER_VERTEX_TO_FRAGMENT(o); return o; &#125; fixed4 frag (v2f i) : SV_Target &#123; half atten = LIGHT_ATTENUATION (i); fixed4 col = fixed4(0,0,0,1); fixed3 albedo = tex2D(_Diffuse, i.texcoord).xyz; fixed3 comb_map = tex2D(_Combmap, i.texcoord).xyz; half metal = comb_map.g; fixed3 base_col =albedo * (1-metal); fixed3 spec_color = lerp(0.04,albedo,metal); half3 normal_dir = normalize(i.normal_world); half3 pos_world = normalize(i.pos_world); half3 tangent_dir = normalize(i.tangent_world)*_NormalIntensity; half3 binormal_dir = normalize(i.binormal_world)*_NormalIntensity; half4 normalmap= tex2D(_Normal,i.texcoord); half3 normal_data = UnpackNormal( normalmap); float3x3 TBN = float3x3(tangent_dir,binormal_dir,normal_dir); normal_dir = normalize(mul(normal_data,TBN)); half3 view_dir = normalize(_WorldSpaceCameraPos.xyz-pos_world); half3 light_dir = normalize(_WorldSpaceLightPos0.xyz); //直接光漫反射 half diffuse_term = max(dot(normal_dir,light_dir),0); half3 comm_diffuse = diffuse_term*base_col*atten*_LightColor0.xyz; half half_lambert = (diffuse_term+1.0)*0.5; half skin_area = 1- comb_map.b; half2 uv_lut = float2(min(1, diffuse_term*atten +_LUTOffset),_CurveOffset); half3 lut_color = tex2D(_SSSTrick,uv_lut); half3 sss_diffuse = lut_color *base_col*_LightColor0.xyz* half_lambert; half3 diffuse = lerp(comm_diffuse,sss_diffuse,skin_area); col.xyz+=diffuse; //直接光镜面反射 half3 half_dir =normalize( light_dir+view_dir); half roughness = comb_map.r; half smoothness = 1.0-roughness; half shininess = lerp(1.0,_SpecShininess,smoothness); half reflect_term = pow(max(0,dot(normal_dir,half_dir)),shininess); half3 specular = reflect_term * spec_color*atten*_LightColor0.xyz; col.xyz+=specular; //间接光照 half3 env_diffuse = SH(normal_dir)*base_col*half_lambert; // sample the texture col.xyz+=env_diffuse; //间接镜面反射 roughness=roughness*(1.7-0.7*roughness); half mip_level = roughness*6.0; half4 Cube_col=texCUBElod(_EnvMap,float4(half_dir,mip_level)); half3 EnvHDR_col=DecodeHDR(Cube_col,_EnvMap_HDR); half3 env_specular = EnvHDR_col *spec_color*half_lambert*_Expose; col.xyz+=env_specular; col.xyz*=0.8; return col; // return fixed4(diffuse,1.0); &#125; ENDCG &#125; &#125; FallBack &quot;Diffuse&quot;&#125; 头发代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175Shader &quot;Hair&quot;&#123; Properties &#123; _Diffuse(&quot;Diffuse&quot;, 2D) = &quot;white&quot; &#123;&#125; _DiffuseColor(&quot;Diffuse Color&quot;, Color) = (0,0,0,1) _Normal(&quot;Normal&quot;, 2D) = &quot;bump&quot; &#123;&#125; _NormalIntensity(&quot;Normal Intensity&quot;, Float) = 1.0 _AnoiseMap(&quot;AnoiseMap&quot;, 2D) = &quot;gray&quot; &#123;&#125; _SpecularColor1(&quot;Specular Color1&quot;, Color) = (0,0,0,1) _SpecShininess1(&quot;Spec Shininess1&quot;, Float) = 1.0 _Shiftoffset1 (&quot;Shift offset1&quot;, Range(-10,10)) = 1.0 _SpecNoise1 (&quot;Spec Noise1&quot;, Float) = 1.0 _SpecularColor2(&quot;Specular Color2&quot;, Color) = (0,0,0,1) _SpecShininess2(&quot;Spec Shininess2&quot;, Float) = 1.0 _Shiftoffset2 (&quot;Shift offset2&quot;, Range(-10,10)) = 1.0 _SpecNoise2 (&quot;Spec Noise2&quot;, Float) = 1.0 _EnvMap(&quot;EnvMap&quot;, Cube) = &quot;black&quot; &#123;&#125; _Expose(&quot;Expose&quot;, Float) = 1.0 &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot;=&quot;Opaque&quot; &#125; LOD 100 Pass &#123; Tags &#123; &quot;LightMode&quot; = &quot;ForwardBase&quot; &#125; CGPROGRAM #pragma vertex vert #pragma fragment frag #pragma multi_compile_fwdbase #include &quot;AutoLight.cginc&quot; #include &quot;UnityCG.cginc&quot; struct appdata &#123; float4 vertex : POSITION; float2 uv : TEXCOORD0; float3 normal:NORMAL; float4 tangent:TANGENT; &#125;; struct v2f &#123; float2 texcoord : TEXCOORD0; float4 pos : SV_POSITION; float3 normal_world:TEXCOORD1; float3 binormal_world:TEXCOORD2; float3 tangent_world:TEXCOORD3; float3 pos_world:TEXCOORD4; LIGHTING_COORDS(5,6) &#125;; sampler2D _Diffuse; float4 _Diffuse_ST; sampler2D _Normal; float _NormalIntensity; float _SpecShininess; float _Expose; float4 _LightColor0; float4 _DiffuseColor; samplerCUBE _EnvMap; float4 _EnvMap_HDR; float _CurveOffset; float _LUTOffset; sampler2D _AnoiseMap; float4 _AnoiseMap_ST; float4 _SpecularColor1; float _SpecShininess1; float _Shiftoffset1 ; float _SpecNoise1 ; float4 _SpecularColor2; float _SpecShininess2; float _Shiftoffset2 ; float _SpecNoise2 ; v2f vert (appdata v) &#123; v2f o; o.pos = UnityObjectToClipPos(v.vertex); o.texcoord =v.uv; o.normal_world = normalize(mul(float4(v.normal,0.0),unity_WorldToObject)).xyz; o.tangent_world = normalize(mul(unity_ObjectToWorld,float4(v.tangent.xyz,0.0))); o.pos_world = normalize(mul(unity_ObjectToWorld,float4(v.vertex.xyz,0.0))); o.binormal_world =normalize(cross(o.normal_world,o.tangent_world)*v.tangent.w); //o.texcoord = TRANSFORM_TEX(v.uv, _MainTex); TRANSFER_VERTEX_TO_FRAGMENT(o); return o; &#125; fixed4 frag (v2f i) : SV_Target &#123; half atten = LIGHT_ATTENUATION (i); fixed4 col = fixed4(0,0,0,1); fixed3 albedo = tex2D(_Diffuse, i.texcoord).xyz*_DiffuseColor; fixed3 base_col =albedo ; fixed3 spec_color =albedo ; half3 normal_dir = normalize(i.normal_world); half3 pos_world = normalize(i.pos_world); half3 tangent_dir = normalize(i.tangent_world)*_NormalIntensity; half3 binormal_dir = normalize(i.binormal_world)*_NormalIntensity; half4 normalmap= tex2D(_Normal,i.texcoord); half3 normal_data = UnpackNormal( normalmap); float3x3 TBN = float3x3(tangent_dir,binormal_dir,normal_dir); normal_dir = normalize(mul(normal_data,TBN)); half3 view_dir = normalize(_WorldSpaceCameraPos.xyz-pos_world); half3 light_dir = normalize(_WorldSpaceLightPos0.xyz); //直接光漫反射 half diffuse_term = max(dot(normal_dir,light_dir),0); half half_lambert = (diffuse_term+1.0)*0.5; half3 comm_diffuse = diffuse_term*base_col*atten*_LightColor0.xyz; half3 diffuse = comm_diffuse; col.xyz+=diffuse; //直接光镜面反射 half roughness = 0.2; half3 half_dir =normalize( light_dir+view_dir); half2 uv_Anoise = i.texcoord*_AnoiseMap_ST.xy+_AnoiseMap_ST.zw; half3 aniso_noise = tex2D(_AnoiseMap,uv_Anoise); half NdotH = dot(normal_dir,half_dir); half TdotH = dot(tangent_dir,half_dir); half NdotV = max(0, dot(normal_dir,view_dir)); half aniso_atten = saturate(sqrt(max(0,half_lambert/NdotV)))*atten; //spec1 half3 specular_color1 = _SpecularColor1 + base_col; half3 aniso_offset1 = normal_dir *(aniso_noise*_SpecNoise1+_Shiftoffset1); half3 binormal_dir1 = normalize(binormal_dir + aniso_offset1); half BdotH1 = dot(binormal_dir1,half_dir)/ _SpecShininess1; half3 specular_term1 = exp(-(TdotH*TdotH+BdotH1*BdotH1)/(1.0+NdotH)); half3 specular1 = specular_term1*aniso_atten*specular_color1*_LightColor0.xyz; half3 specular_color2 = _SpecularColor2 + base_col; half3 aniso_offset2 = normal_dir *(aniso_noise*_SpecNoise2+_Shiftoffset2); half3 binormal_dir2 = normalize(binormal_dir + aniso_offset2); half BdotH2 = dot(binormal_dir2,half_dir)/ _SpecShininess2; half3 specular_term2 = exp(-(TdotH*TdotH+BdotH2*BdotH2)/(1.0+NdotH)); half3 specular2 = specular_term2*aniso_atten*specular_color2*_LightColor0.xyz; half3 specular = specular1+specular2; col.xyz+=specular; //间接镜面反射 roughness=roughness*(1.7-0.7*roughness); half mip_level = roughness*6.0; half4 Cube_col=texCUBElod(_EnvMap,float4(half_dir,mip_level)); half3 EnvHDR_col=DecodeHDR(Cube_col,_EnvMap_HDR); half3 env_specular = EnvHDR_col *spec_color*half_lambert*_Expose; col.xyz+=env_specular; //return col; return fixed4(specular,1.0); &#125; ENDCG &#125; &#125; FallBack &quot;Diffuse&quot;&#125;","categories":[{"name":"游戏","slug":"游戏","permalink":"https://mrchenlearnspace.github.io/categories/%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"Shader","slug":"Shader","permalink":"https://mrchenlearnspace.github.io/tags/Shader/"}]},{"title":"Imgui学习","slug":"Imgui学习","date":"2022-04-12T13:38:45.000Z","updated":"2022-11-14T14:24:26.480Z","comments":true,"path":"2022/04/12/Imgui学习/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/04/12/Imgui%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"让控制台消失GetConsoleWindow()&#x2F;&#x2F;获取控制台窗口句柄 SW_HIDE 0SW_SHOWNORMAL 1SW_NORMAL 1SW_SHOWMINIMIZED 2SW_SHOWMAXIMIZED 3SW_MAXIMIZE 3SW_SHOWNOACTIVATE 4SW_SHOW 5SW_MINIMIZE 6SW_SHOWMINNOACTIVE 7SW_SHOWNA 8SW_RESTORE 9SW_SHOWDEFAULT 10SW_FORCEMINIMIZE 11SW_MAX 11 12345#include &lt;Windows.h&gt;int main(int, char**)&#123; ShowWindow(GetConsoleWindow(), SW_HIDE); &#125; 导入Imgui下载docking的版本有停靠窗口和拿出原窗口的功能 将初始目录下的文件放在解决方案下，将backends和glfw文件夹复制到相应文件夹下。 并将初始目录下的文件放入解决方案的imgui文件夹中 关于平台的backends中的头文件放入头文件夹中 在项目新建main.cpp文件，修改配置 C&#x2F;C++的常规里的附加包含目录 1234.\\..\\glfw\\include.\\backends%(AdditionalIncludeDirectories)//可不写系统自带 链接器常规 12345664架构.\\glfw\\lib-vc2010-64%(AdditionalLibraryDirectories)32架构.\\glfw\\lib-vc2010-32%(AdditionalLibraryDirectories) 链接器输入 123opengl32.libglfw3.lib%(AdditionalDependencies) 导入样例中代码是否报错能跑就说明装好了 Global.h123456789101112#pragma once#include &lt;string&gt;#include &quot;imgui.h&quot;#include &quot;imgui_internal.h&quot;#include &quot;imstb_rectpack.h&quot;#include &quot;imstb_textedit.h&quot;#include &quot;imstb_truetype.h&quot;#include &quot;imgui_impl_glfw.h&quot;#include &quot;imgui_impl_opengl3.h&quot;#include &lt;stdio.h&gt; main.cpp123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186#include&quot;Global.h&quot;// Dear ImGui: standalone example application for GLFW + OpenGL 3, using programmable pipeline// (GLFW is a cross-platform general purpose library for handling windows, inputs, OpenGL/Vulkan/Metal graphics context creation, etc.)// If you are new to Dear ImGui, read documentation from the docs/ folder + read the top of imgui.cpp.// Read online: https://github.com/ocornut/imgui/tree/master/docs#if defined(IMGUI_IMPL_OPENGL_ES2)#include &lt;GLES2/gl2.h&gt;#endif#include &lt;GLFW/glfw3.h&gt; // Will drag system OpenGL headers// [Win32] Our example includes a copy of glfw3.lib pre-compiled with VS2010 to maximize ease of testing and compatibility with old VS compilers.// To link with VS2010-era libraries, VS2015+ requires linking with legacy_stdio_definitions.lib, which we do using this pragma.// Your own project should not be affected, as you are likely to link with a newer binary of GLFW that is adequate for your version of Visual Studio.#if defined(_MSC_VER) &amp;&amp; (_MSC_VER &gt;= 1900) &amp;&amp; !defined(IMGUI_DISABLE_WIN32_FUNCTIONS)#pragma comment(lib, &quot;legacy_stdio_definitions&quot;)#endifstatic void glfw_error_callback(int error, const char* description) &#123; fprintf(stderr, &quot;Glfw Error %d: %s\\n&quot;, error, description);&#125;int main(int, char**) &#123; // Setup window glfwSetErrorCallback(glfw_error_callback); if (!glfwInit()) return 1; // Decide GL+GLSL versions#if defined(IMGUI_IMPL_OPENGL_ES2) // GL ES 2.0 + GLSL 100 const char* glsl_version = &quot;#version 100&quot;; glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 2); glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 0); glfwWindowHint(GLFW_CLIENT_API, GLFW_OPENGL_ES_API);#elif defined(__APPLE__) // GL 3.2 + GLSL 150 const char* glsl_version = &quot;#version 150&quot;; glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 3); glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 2); glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE); // 3.2+ only glfwWindowHint(GLFW_OPENGL_FORWARD_COMPAT, GL_TRUE); // Required on Mac#else // GL 3.0 + GLSL 130 const char* glsl_version = &quot;#version 130&quot;; glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 3); glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 0); //glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE); // 3.2+ only //glfwWindowHint(GLFW_OPENGL_FORWARD_COMPAT, GL_TRUE); // 3.0+ only#endif // Create window with graphics context GLFWwindow* window = glfwCreateWindow(1280, 720, &quot;Dear ImGui GLFW+OpenGL3 example&quot;, NULL, NULL); if (window == NULL) return 1; glfwMakeContextCurrent(window); glfwSwapInterval(1); // Enable vsync // Setup Dear ImGui context IMGUI_CHECKVERSION(); ImGui::CreateContext(); ImGuiIO&amp; io = ImGui::GetIO(); (void)io; io.ConfigFlags |= ImGuiConfigFlags_NavEnableKeyboard; // Enable Keyboard Controls //io.ConfigFlags |= ImGuiConfigFlags_NavEnableGamepad; // Enable Gamepad Controls io.ConfigFlags |= ImGuiConfigFlags_DockingEnable; // Enable Docking io.ConfigFlags |= ImGuiConfigFlags_ViewportsEnable; // Enable Multi-Viewport / Platform Windows //io.ConfigViewportsNoAutoMerge = true; //io.ConfigViewportsNoTaskBarIcon = true; // Setup Dear ImGui style ImGui::StyleColorsDark(); //ImGui::StyleColorsClassic(); // When viewports are enabled we tweak WindowRounding/WindowBg so platform windows can look identical to regular ones. ImGuiStyle&amp; style = ImGui::GetStyle(); if (io.ConfigFlags &amp; ImGuiConfigFlags_ViewportsEnable) &#123; style.WindowRounding = 0.0f; style.Colors[ImGuiCol_WindowBg].w = 1.0f; &#125; // Setup Platform/Renderer backends ImGui_ImplGlfw_InitForOpenGL(window, true); ImGui_ImplOpenGL3_Init(glsl_version); // Load Fonts // - If no fonts are loaded, dear imgui will use the default font. You can also load multiple fonts and use ImGui::PushFont()/PopFont() to select them. // - AddFontFromFileTTF() will return the ImFont* so you can store it if you need to select the font among multiple. // - If the file cannot be loaded, the function will return NULL. Please handle those errors in your application (e.g. use an assertion, or display an error and quit). // - The fonts will be rasterized at a given size (w/ oversampling) and stored into a texture when calling ImFontAtlas::Build()/GetTexDataAsXXXX(), which ImGui_ImplXXXX_NewFrame below will call. // - Read &#x27;docs/FONTS.md&#x27; for more instructions and details. // - Remember that in C/C++ if you want to include a backslash \\ in a string literal you need to write a double backslash \\\\ ! //io.Fonts-&gt;AddFontDefault(); //io.Fonts-&gt;AddFontFromFileTTF(&quot;../../misc/fonts/Roboto-Medium.ttf&quot;, 16.0f); //io.Fonts-&gt;AddFontFromFileTTF(&quot;../../misc/fonts/Cousine-Regular.ttf&quot;, 15.0f); //io.Fonts-&gt;AddFontFromFileTTF(&quot;../../misc/fonts/DroidSans.ttf&quot;, 16.0f); //io.Fonts-&gt;AddFontFromFileTTF(&quot;../../misc/fonts/ProggyTiny.ttf&quot;, 10.0f); //ImFont* font = io.Fonts-&gt;AddFontFromFileTTF(&quot;c:\\\\Windows\\\\Fonts\\\\ArialUni.ttf&quot;, 18.0f, NULL, io.Fonts-&gt;GetGlyphRangesJapanese()); //IM_ASSERT(font != NULL); // Our state bool show_demo_window = false; bool show_another_window = false; ImVec4 clear_color = ImVec4(0.45f, 0.55f, 0.60f, 1.00f); // Main loop while (!glfwWindowShouldClose(window)) &#123; // Poll and handle events (inputs, window resize, etc.) // You can read the io.WantCaptureMouse, io.WantCaptureKeyboard flags to tell if dear imgui wants to use your inputs. // - When io.WantCaptureMouse is true, do not dispatch mouse input data to your main application, or clear/overwrite your copy of the mouse data. // - When io.WantCaptureKeyboard is true, do not dispatch keyboard input data to your main application, or clear/overwrite your copy of the keyboard data. // Generally you may always pass all inputs to dear imgui, and hide them from your application based on those two flags. glfwPollEvents(); // Start the Dear ImGui frame ImGui_ImplOpenGL3_NewFrame(); ImGui_ImplGlfw_NewFrame(); ImGui::NewFrame(); // 1. Show the big demo window (Most of the sample code is in ImGui::ShowDemoWindow()! You can browse its code to learn more about Dear ImGui!). if (show_demo_window) // 2. Show a simple window that we create ourselves. We use a Begin/End pair to created a named window. ImGui::ShowDemoWindow(&amp;show_demo_window); &#123; static float f = 0.0f; static int counter = 0; ImGui::Begin(&quot;Hello, world!&quot;); // Create a window called &quot;Hello, world!&quot; and append into it. ImGui::Text(&quot;This is some useful text.&quot;); // Display some text (you can use a format strings too) ImGui::Checkbox(&quot;Demo Window&quot;, &amp;show_demo_window); // Edit bools storing our window open/close state ImGui::Checkbox(&quot;Another Window&quot;, &amp;show_another_window); ImGui::SliderFloat(&quot;float&quot;, &amp;f, 0.0f, 1.0f); // Edit 1 float using a slider from 0.0f to 1.0f ImGui::ColorEdit3(&quot;clear color&quot;, (float*)&amp;clear_color); // Edit 3 floats representing a color if (ImGui::Button(&quot;Button&quot;)) // Buttons return true when clicked (most widgets return true when edited/activated) counter++; ImGui::SameLine(); ImGui::Text(&quot;counter = %d&quot;, counter); ImGui::Text(&quot;Application average %.3f ms/frame (%.1f FPS)&quot;, 1000.0f / ImGui::GetIO().Framerate, ImGui::GetIO().Framerate); ImGui::End(); &#125; // 3. Show another simple window. if (show_another_window) &#123; ImGui::Begin(&quot;Another Window&quot;, &amp;show_another_window); // Pass a pointer to our bool variable (the window will have a closing button that will clear the bool when clicked) ImGui::Text(&quot;Hello from another window!&quot;); if (ImGui::Button(&quot;Close Me&quot;)) show_another_window = false; ImGui::End(); &#125; // Rendering ImGui::Render(); int display_w, display_h; glfwGetFramebufferSize(window, &amp;display_w, &amp;display_h); glViewport(0, 0, display_w, display_h); glClearColor(clear_color.x * clear_color.w, clear_color.y * clear_color.w, clear_color.z * clear_color.w, clear_color.w); glClear(GL_COLOR_BUFFER_BIT); ImGui_ImplOpenGL3_RenderDrawData(ImGui::GetDrawData()); // Update and Render additional Platform Windows // (Platform functions may change the current OpenGL context, so we save/restore it to make it easier to paste this code elsewhere. // For this specific demo app we could also call glfwMakeContextCurrent(window) directly) if (io.ConfigFlags &amp; ImGuiConfigFlags_ViewportsEnable) &#123; GLFWwindow* backup_current_context = glfwGetCurrentContext(); ImGui::UpdatePlatformWindows(); ImGui::RenderPlatformWindowsDefault(); glfwMakeContextCurrent(backup_current_context); &#125; glfwSwapBuffers(window); &#125; // Cleanup ImGui_ImplOpenGL3_Shutdown(); ImGui_ImplGlfw_Shutdown(); ImGui::DestroyContext(); glfwDestroyWindow(window); glfwTerminate(); return 0;&#125; 建立窗口ImGuiWindowFlags参数可直接用加法叠加效果 12345ImGuiWindowFlags_None = 0,ImGuiWindowFlags_NoTitleBar = 1 &lt;&lt; 0, // 禁用标题栏ImGuiWindowFlags_NoResize = 1 &lt;&lt; 1, // 使用右下角手柄禁用用户调整大小ImGuiWindowFlags_NoMove = 1 &lt;&lt; 2, // 禁止用户移动窗口ImGuiWindowFlags_NoCollapse = 1 &lt;&lt; 5, // 禁用用户折叠窗口双击它。也被称为窗口菜单按钮(例如在停靠节点内) 1234if (isOpen) &#123; ImGui::Begin(&quot;my&quot;, &amp;isOpen, ImGuiWindowFlags_None); ImGui::End(); &#125; 按钮放入begin和end中 1234567if (isOpen) &#123; ImGui::Begin(&quot;my&quot;, &amp;isOpen, ImGuiWindowFlags_None); if (ImGui::Button(&quot;asd1&quot;)) &#123; printf(&quot;dsads&quot;);//按下 &#125; ImGui::End(); &#125; 按钮不换行 123ImGui::Button(&quot;asd1&quot;); ImGui::SameLine(); ImGui::Button(&quot;asd1&quot;); 单选框和复选框单选框1234ImGui::RadioButton(&quot;01&quot;, &amp;num, 1);ImGui::RadioButton(&quot;02&quot;, &amp;num, 2);ImGui::RadioButton(&quot;03&quot;, &amp;num, 3);ImGui::RadioButton(&quot;04&quot;, &amp;inta, intb);//如果选到这一栏&amp;a=b 复选框12ImGui::Checkbox(&quot;03&quot;, &amp;isOpen);ImGui::Checkbox(&quot;03&quot;, &amp;bool); 折叠框123456if (ImGui::CollapsingHeader(&quot;CollapsingHeader1&quot; )) &#123; ImGui::RadioButton(&quot;01&quot;, &amp;num, 1); ImGui::RadioButton(&quot;02&quot;, &amp;num, 2); ImGui::RadioButton(&quot;03&quot;, &amp;num, 3); ImGui::Checkbox(&quot;03&quot;, &amp;isOpen);&#125; 文本框12ImGui::Text(&quot;dsadsa&quot;,&quot;tyt&quot;);//最简单的ImGui::BulletText(&quot;BulletText&quot;);//带点的 HelpMarker 123456789101112static void HelpMarker(const char* desc)&#123; ImGui::TextDisabled(&quot;(?)&quot;); if (ImGui::IsItemHovered()) &#123; ImGui::BeginTooltip(); ImGui::PushTextWrapPos(ImGui::GetFontSize() * 35.0f); ImGui::TextUnformatted(desc); ImGui::PopTextWrapPos(); ImGui::EndTooltip(); &#125;&#125; 滑块条name不能一样 1234ImGui::SliderFloat(&quot;float&quot;, &amp;f, 0.0f, 1.0f); ImGui::SliderInt(&quot;SliderInt&quot;, &amp;i, 0, 100); ImGui::SliderFloat(&quot;float&quot;, &amp;float, min, max); ImGui::SliderInt(&quot;SliderInt&quot;, &amp;int, min, max); 切换中文c:\\Windows\\Fonts\\选一款字体，GetGlyphRangesChineseFull（）换成这个。在字符前面加u8 123ImFont* font = io.Fonts-&gt;AddFontFromFileTTF(&quot;c:\\\\Windows\\\\Fonts\\\\simkai.ttf&quot;, 18.0f, NULL, io.Fonts-&gt;GetGlyphRangesChineseFull()); IM_ASSERT(font != NULL);ImGui::CollapsingHeader(u8&quot;集合 CollapsingHeader1&quot; ); 方法二 通过binary_to_compressed_c.cpp转化为数组然后建立一个头文件复制进去 12ImFont* font = io.Fonts-&gt;AddFontFromMemoryTTF((void*)font_h_data,font_h_size, 18.0f,NULL, io.Fonts-&gt;GetGlyphRangesChineseFull());ImGui::CollapsingHeader(u8&quot;集合 CollapsingHeader1&quot; ); 切换控件颜色12style.Colors[ImGuiCol_TitleBgCollapsed] = ImColor(180, 180, 180);style.Colors[ImGuiCol_枚举类型] = ImColor(180, 180, 180);","categories":[{"name":"计算机图形学","slug":"计算机图形学","permalink":"https://mrchenlearnspace.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://mrchenlearnspace.github.io/tags/C/"},{"name":"Imgui","slug":"Imgui","permalink":"https://mrchenlearnspace.github.io/tags/Imgui/"}]},{"title":"Games104第5节记录","slug":"Games104第5节记录","date":"2022-04-11T13:38:45.000Z","updated":"2022-11-14T14:23:43.745Z","comments":true,"path":"2022/04/11/Games104第5节记录/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/04/11/Games104%E7%AC%AC5%E8%8A%82%E8%AE%B0%E5%BD%95/","excerpt":"","text":"光照，材质，着色 光照第一个挑战多样的光 复杂的光照信息 第二个挑战半球光照和散射信息收集的困难 第三个挑战任何物体会变成光源 从简单开始简单的光照解决方案结果 &#x3D; 环境光 + 单一光照 环境反射贴图结果 &#x3D; 主要光 + 环境光 +环境贴图 Phong光照模型缺陷 能量不守恒 Phone光照模型会有点像塑料 Shadow shadow map问题 基础着色解决方案 3A质量预先计算全局照明直接光照加间接光照 傅里叶变化能够提高卷积的效率 SH（球面谐波）球面谐函数，一个数学系统，类似于傅里叶变换，但定义在球面上。SH函数通常是在虚数上定义的 将低频表示出来，一阶就够了 光照贴图优化UV Atlas Lighting Lightmap优点运行时非常高效在环境上烘烤Gl的很多细节 缺点长时间和昂贵的预计算(灯光地图农场)只能处理静态场景和静态灯光封装和GPU的存储成本 光照探针 光照点生成尽量自动生成 反射探针高质量立体贴图 光探头+反射探头混合优点 运行时非常高效可以应用于静态和动态对象吗处理漫反射和镜面阴影 缺点 一堆SH光探测器需要预先计算不能处理gl的细节，比如重叠结构上的软阴影 PBR微平面理论 BRDF DFGD G F 迪士尼 Dinesy原则 BRDF执行模型时应遵循的原则: •应使用直观而非物理参数 •参数越少越好 •参数应该在合理范围内为0到1 •应该允许参数超出其合理范围 •所有参数的组合应该尽可能地稳健和合理 迪士尼材质参数 PBR镜面光泽 非金属尽量不使用菲涅尔，金属用菲涅尔 MR会有白边 《大世界》和《阶梯阴影》 将截锥分割成多个截锥 为每个子截锥渲染阴影地图 然后像素着色器从最接近所需分辨率的地图中采样 级联层之间的混合1. 在级联重叠的地方可以看到可见的接缝2. 级联层之间，因为分辨率不匹配。3.然后着色器根据像素在混合带中的位置在这两个值之间线性插值。 Cascade Shadow的利弊 优点 最好的方法与普遍的阴影错误 :透视混叠快速生成深度图，3倍时，深度写入只能提供相当好的结果 缺点 几乎不可能产生高质量的区域阴影没有颜色的阴影。半透明的表面投射不透明的阴影 GPU的快速发展． 更灵活的新着色器模型计算着色器网状材质．Ray-tracying材质 高性能并行架构翘曲或波浪结构 完全开放的图形API．DirectX 12和Vulkan 实时光追 实时全局光照 更复杂的材质模型 虚拟阴影图 shader管理优步着色器和变体","categories":[{"name":"计算机图形学","slug":"计算机图形学","permalink":"https://mrchenlearnspace.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}],"tags":[{"name":"引擎制作","slug":"引擎制作","permalink":"https://mrchenlearnspace.github.io/tags/%E5%BC%95%E6%93%8E%E5%88%B6%E4%BD%9C/"}]},{"title":"Ubuntu系统和Docker的奇妙故事","slug":"Ubuntu系统和Docker的奇妙故事","date":"2022-04-07T12:38:45.000Z","updated":"2022-11-14T14:25:02.824Z","comments":true,"path":"2022/04/07/Ubuntu系统和Docker的奇妙故事/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/04/07/Ubuntu%E7%B3%BB%E7%BB%9F%E5%92%8CDocker%E7%9A%84%E5%A5%87%E5%A6%99%E6%95%85%E4%BA%8B/","excerpt":"","text":"装系统下载镜像，制作 跳过更新过程 找到软件和更新 寻找最佳镜像源 设置好再更新镜像 内网穿透用frp进行穿透 公网服务器frps.ini 123[common]bind_port = 7000token =sss 密钥和客户端一样就行 私有服务器frpc.ini 1234567891011[common]server_addr = 公网服务器ipserver_port = 7000token =sss[pve-web]type = tcplocal_ip = 192.168.50.200 local_port = 8888 remote_port = 8888 12345local_ip //私有服务器地址local_port //本地的应用端口remote_port //映射到服务器的端口 linux下载一定要下_linux_amd64.tar.gz的，架构可以选，其他的darwin_amd64.tar.gzUbuntu运行不了 到相关文件夹下 1sudo ./frps -c frps.ini 如果在其他用户群 1su -l [user] 不加的话默认root权限管理员 1sudo ./frpc -c frpc.ini wincmd指令相关文件夹下 12frps.exe -c frps.inifrpc.exe -c frpc.ini 可以将此命令写出bat放进开始文件夹，变成开机启动项。 虚拟组网zerotier 虚拟组网 原理就是先通过zerotier中继器进行联网，然后尝试让两者进行p2p连接。 Linux麻烦一点 12zerotier-cli join id//加入并连接zerotier-cli leave id//断开连接 转载自别人视频的东西docker镜像加速请把 docker 更换源工具解压至用户主目录 打开终端运行 ds.sh 123456789101112#! /bin/bashdate &quot;+%Y年%m月%d日 周%w %H:%M:%S&quot;echo &#x27;为 Docker 更换官方国内源加速下载&#x27;cat &gt; /etc/docker/daemon.json &lt;&lt; EOF&#123; &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;]&#125;EOFservice docker restartdocker info|grep &quot;Registry Mirrors&quot; -A 1echo &#x27;显示 registry.docker-cn.com 即换源成功&#x27; 更换 Docker 国内官方源sudo sh ds.sh 修复 Docker 无管理员权限运行失败的问题sudo gpasswd -a $USER docker newgrp docker service docker restart 来自科技宅小明的视频 一定要切换镜像源！！！一定要切换镜像源！！！一定要切换镜像源！！！一定要切换镜像源！！！一定要切换镜像源！！！一定要切换镜像源！！！一定要切换镜像源！！！一定要切换镜像源！！！一定要切换镜像源！！！一定要切换镜像源！！！ 装Docker也可以看菜鸟教程装Docker 更新 apt 工具及索引，以支持 https 存储库 1234567sudo apt-get updatesudo apt-get install \\ ca-certificates \\ curl \\ gnupg \\ lsb-release 添加 Docker 官方 GPG 密钥（用于签名&#x2F;验证、加密&#x2F;解密） 1curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg 设置 stable 版稳定存储库（区别于夜间版&#x2F;测试版 nightly &#x2F; test ） 123echo \\ &quot;deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) stable&quot; | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null 更新 apt 工具及索引，并安装 Docker 123sudo apt-get updatesudo apt-get install docker-ce docker-ce-cli containerd.io 验证 Docker Engine 是否正确安装（显示 “Hello from Docker!” 即为成功安装） 1sudo docker run hello-world 为 Docker 安装图形化操作界面 Portainer创建 Portainer Server 存储数据库的卷 1sudo docker volume create portainer_data 下载并安装 Portainer Server 容器 12345sudo docker run -d -p 8000:8000 -p 9443:9443 --name portainer \\ --restart=always \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -v portainer_data:/data \\ portainer/portainer-ce:latest 查看 Docker 容器状态（NAMES 标签出现 portainer&#x2F;portainer-ce 则成功运行） 1sudo docker ps 使用 Ubuntu 自带的火狐浏览器访问（https://127.0.0.1:9443/）或使用局域网内另一台计算机&#x2F;手机的浏览器访问（https:&#x2F;&#x2F;服务器的IP:9443&#x2F;） 对 Portainer 初始设置设置用户名及密码（8位字符或数字），点击 Get Started，载入后点击 local 即可 启用 Web 个人导航页将 nginx 文件夹解压至 &#x2F;home&#x2F;你自己的用户名&#x2F; 之下 下载 Nginx 镜像 Portainer 点击 Images 镜像，docker.io 右侧填入 nginx，点击 Pull the image 下载镜像 部署并运行 Nginx 容器（可以理解为把 Nginx 镜像作为小型虚拟机启动） 点击 Containers 标签，点击 Add Container 启动容器，名称填入Nginx，docker.io 右侧填入 nginx:latest（Images 标签页 Tags 标签选项）。 Manual network port publishing 手动发布网口设置项，把本地80端口映射到容器80端口。 在Advanced container settings高级容器设置中，点击map additional volume 映射附加卷，点击绑定文件夹及可读写，本地文件夹填入 &#x2F;home&#x2F;你自己的用户名&#x2F;nginx&#x2F; 容器文件夹填入 &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html Restart policy 重启策略调整为 Always 永远自动启动。 最后点击 Deploy the container 部署容器 使用 Ubuntu 自带的火狐浏览器访问（http://127.0.0.1）或使用局域网内另一台计算机&#x2F;手机的浏览器访问（http:&#x2F;&#x2F;服务器的IP） 来自GitHub大佬的分享来自各种生活的容器服务，上链接 搭建 Mattermost 私人聊天室命令方式安装 Docker 版 Mattermost 1234567docker run \\-d \\--name mattermost-preview \\--restart=always \\--publish 8065:8065 \\--add-host dockerhost:127.0.0.1 \\mattermost/mattermost-preview 设置 Mattermost 私人聊天室访问 127.0.0.1:8065 网址，输入邮箱用户名及密码进行初始账户注册选择第二项进入控制台，进入SITE CONFIGURATION - Localization更改语言为中文保存返回上一步，新建群组PQMing（可以自行改名），点击Finish完成新页面输入用户名，上传头像（可选）并保存，保存团队，不起用通知复制邀请链接，之后可以分享给朋友，稍等一会就完成设置默认的管理员账户仍然是英文，点击右上角设置，Display里改成中文即可新用户入群后会自动进入公共和闲聊这两个频道，用户之间可以选择群聊或私信 免费使用为知笔记访问用户主目录文件夹 1cd ~ 在主目录新建 wizdata 文件夹用于存储笔记数据 1mkdir wizdata 命令方式安装 Docker 版为知笔记 12345678910docker run \\-it \\-d \\--name wiz \\--restart=always \\-v ~/wizdata:/wiz/storage \\-v /etc/localtime:/etc/localtime \\-p 8080:80 \\-p 9269:9269/udp \\wiznote/wizserver 搭建个人博客 Wordpress安装 Docker 版 mariadb 数据库命令，可自行替换密码（默认为meimima） 1234567docker run -d \\ --name mariadb \\ -p 3306:3306 \\ -e MARIADB_ROOT_PASSWORD=meimima \\ -e MARIADB_DATABASE=wordpress \\ --restart=always \\ mariadb:latest 安装 Docker 版 Wordpress 命令，需要自行替换为本机 IP 地址（采用上一步数据库密码meimima） 1234567891011docker run \\ -d \\ --name wordpress \\ -e WORDPRESS_DB_HOST=服务器IP:3306 \\ -e WORDPRESS_DB_USER=root \\ -e WORDPRESS_DB_PASSWORD=meimima \\ -e WORDPRESS_DB_NAME=wordpress \\ -e WORDPRESS_TABLE_PREFIX=wp_ \\ -p 8081:80 \\ --restart=always \\ wordpress 使用浏览器登陆服务器 IP:8081（例：192.168.2.15:8081）访问博客 可选 安装 mariadb 数据库控制面板 phpmyadmin 手动管理数据库安装 Docker 版 phpmyadmin 数据库控制面板命令 12345678docker run \\ -d \\ --name phpmyadmin \\ --link mariadb \\ -e PMA_HOST=&quot;mariadb&quot; \\ -p 8082:80 \\ --restart=always \\ phpmyadmin 使用浏览器登陆服务器 IP:8082（例：192.168.2.15:8082）访问数据库控制面板使用安装 phpmyadmin 命令中的密码（默认为meimima）及用户名 root 登陆数据库点击控制面板左侧 新建 按钮，创建名为 wordpress 的数据库 免费网盘 SeaFile 安装教程docker-compose.yml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849version: &#x27;2.0&#x27;services: db: image: mariadb:10.5 container_name: seafile-mysql restart: always environment: - MYSQL_ROOT_PASSWORD=db_dev # 设置数据库根用户的密码 - MYSQL_LOG_CONSOLE=true volumes: - /home/seafile-mysql/db:/var/lib/mysql # 设置数据库存储位置 networks: - seafile-net memcached: image: memcached:1.5.6 container_name: seafile-memcached restart: always entrypoint: memcached -m 256 networks: - seafile-net seafile: image: seafileltd/seafile-mc:latest container_name: seafile ports: - &quot;81:80&quot; # 主机81端口映射至容器80端口http - &quot;4433:443&quot; # 主机4433端口映射至容器443端口https - &quot;8088:8080&quot; # 主机8088端口映射至容器8080端口webdav volumes: - /home/seafile-data:/shared # 设置Seafile数据存储位置 restart: always environment: - DB_HOST=db - DB_ROOT_PASSWD=db_dev # 与第一条注释所设置密码相同 - TIME_ZONE=Asia/Shanghai # 设定时区为上海 - SEAFILE_ADMIN_EMAIL=me@example.com # 设置管理员账户，默认为 &#x27;me@example.com&#x27; - SEAFILE_ADMIN_PASSWORD=asecret # 设置管理员密码，默认为 &#x27;asecret&#x27;# - SEAFILE_SERVER_LETSENCRYPT=false # 是否启用LETSENCRYPT提供的https加密证书，默认为 &#x27;false&#x27; - SEAFILE_SERVER_HOSTNAME=127.0.0.1:81 # 设置网盘域名地址 depends_on: - db - memcached networks: - seafile-netnetworks: seafile-net: docker-compose原版.yml 1234567891011121314151617181920212223242526272829303132333435363738394041424344version: &#x27;2.0&#x27;services: db: image: mariadb:10.5 container_name: seafile-mysql environment: - MYSQL_ROOT_PASSWORD=db_dev # Requested, set the root&#x27;s password of MySQL service. - MYSQL_LOG_CONSOLE=true volumes: - /opt/seafile-mysql/db:/var/lib/mysql # Requested, specifies the path to MySQL data persistent store. networks: - seafile-net memcached: image: memcached:1.5.6 container_name: seafile-memcached entrypoint: memcached -m 256 networks: - seafile-net seafile: image: seafileltd/seafile-mc:latest container_name: seafile ports: - &quot;80:80&quot;# - &quot;443:443&quot; # If https is enabled, cancel the comment. volumes: - /opt/seafile-data:/shared # Requested, specifies the path to Seafile data persistent store. environment: - DB_HOST=db - DB_ROOT_PASSWD=db_dev # Requested, the value shuold be root&#x27;s password of MySQL service.# - TIME_ZONE=Asia/Shanghai # Optional, default is UTC. Should be uncomment and set to your local time zone. - SEAFILE_ADMIN_EMAIL=me@example.com # Specifies Seafile admin user, default is &#x27;me@example.com&#x27;. - SEAFILE_ADMIN_PASSWORD=asecret # Specifies Seafile admin password, default is &#x27;asecret&#x27;. - SEAFILE_SERVER_LETSENCRYPT=false # Whether use letsencrypt to generate cert. - SEAFILE_SERVER_HOSTNAME=seafile.example.com # Specifies your host name. depends_on: - db - memcached networks: - seafile-netnetworks: seafile-net: 打开终端运行以下命令（输入密码界面不会显示密码） sudo apt-get update | sudo apt-get install docker-compose -y 将 docker-compose.yml 解压至用户主目录，并修改文件内邮箱密码 访问用户主目录 cd ~ 在终端运行以下命令 sudo docker-compose up -d 使用自带的火狐浏览器，访问 http://127.0.0.1:81 未更改 docker-compose.yml 文件内邮箱密码的话，默认用户名 &#109;&#101;&#64;&#x65;&#x78;&#x61;&#109;&#x70;&#x6c;&#101;&#x2e;&#99;&#x6f;&#x6d; 密码 asecret 请在路由器转发 http 使用的 81 端口至服务器 全平台客户端下载链接 https://www.seafile.com/download/ 免费网盘 SeaFile 配置教程 (https)于各个免费平台申请相应域名的 SSL 证书 创建 &#x2F;home&#x2F;seafile-data&#x2F;ssl 目录，然后拷贝证书文件和密钥文件至 ssl 目录下 如果网盘域名是 seafile.example.com，证书名称必须为 seafile.example.com.crt，密钥文件名称为 seafile.example.com.key 请在路由器转发 https 使用的 4433 端口至服务器","categories":[{"name":"Linux","slug":"Linux","permalink":"https://mrchenlearnspace.github.io/categories/Linux/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://mrchenlearnspace.github.io/tags/Ubuntu/"},{"name":"Ducker","slug":"Ducker","permalink":"https://mrchenlearnspace.github.io/tags/Ducker/"}]},{"title":"Games104第4节记录","slug":"Games104第4节记录","date":"2022-04-04T13:38:45.000Z","updated":"2022-11-14T14:23:36.908Z","comments":true,"path":"2022/04/04/Games104第4节记录/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/04/04/Games104%E7%AC%AC4%E8%8A%82%E8%AE%B0%E5%BD%95/","excerpt":"","text":"游戏渲染的挑战 渲染只能占最多20% 渲染在游戏引擎中 GPUSIMD and SIMT 数据从cpu到GPU 缓存的影响 其他平台的显卡架构 可绘制的网格渲染组件 法线顶点存法线 防止正方形的角部分的法线 材质绘制物体在引擎中坐标系统和转换MVP转化 提高性能实例化 如果可以复用的化 材质排序哇，GPU：你他妈就这样换数据，到底烦不烦呀 GPU批处理渲染 使用包围盒裁剪 四叉树进行裁剪 PVS GPU Culling 纹理压缩 美术工具 网格管线 总结","categories":[{"name":"计算机图形学","slug":"计算机图形学","permalink":"https://mrchenlearnspace.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}],"tags":[{"name":"引擎制作","slug":"引擎制作","permalink":"https://mrchenlearnspace.github.io/tags/%E5%BC%95%E6%93%8E%E5%88%B6%E4%BD%9C/"}]},{"title":"透光效果模拟","slug":"透光效果模拟","date":"2022-04-02T18:38:45.000Z","updated":"2022-11-14T14:22:39.704Z","comments":true,"path":"2022/04/03/透光效果模拟/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/04/03/%E9%80%8F%E5%85%89%E6%95%88%E6%9E%9C%E6%A8%A1%E6%8B%9F/","excerpt":"","text":"向量1234float3 diffuse_color = _DiffuseColor;float3 normalDir = normalize(i.normalDir);float3 viewDir = normalize(_WorldSpaceCameraPos - i.posWorld.xyz);float3 lightDir = normalize(_WorldSpaceLightPos0.xyz); 漫反射12345float diff_term = max(0.0, dot(normalDir, lightDir));float3 diffuselight_color = diff_term * diffuse_color * _LightColor0.rgb;float sky_sphere = (dot(normalDir,float3(0,1,0)) + 1.0) * 0.5;float3 sky_light = sky_sphere * diffuse_color;float3 final_diffuse = diffuselight_color + sky_light * _Opacity + _AddColor.xyz; 穿透光12345float3 back_dir = -normalize(lightDir + normalDir * _BasePassDistortion);float VdotB = max(0.0, dot(viewDir, back_dir));float backlight_term = max(0.0,pow(VdotB, _BasePassPower)) * _BasePassScale;float thickness = 1.0 - tex2D(_ThicknessMap, i.uv).r;float3 backlight = backlight_term * thickness *_LightColor0.xyz * _BasePassColor.xyz; 环境光123456789101112131415float3 reflectDir = reflect(-viewDir,normalDir);half theta = _EnvRotate * UNITY_PI / 180.0f;float2x2 m_rot = float2x2(cos(theta), -sin(theta), sin(theta),cos(theta));float2 v_rot = mul(m_rot, reflectDir.xz);reflectDir = half3(v_rot.x, reflectDir.y, v_rot.y);float4 cubemap_color = texCUBE(_EnvMap,reflectDir);half3 env_color = DecodeHDR(cubemap_color, _EnvMap_HDR);//菲尼尔效应float fresnel = 1.0 - saturate(dot(normalDir, viewDir));fresnel = smoothstep(_FresnelMin, _FresnelMax, fresnel);float3 final_env = env_color * _EnvIntensity * fresnel; 混合123float3 combined_color = final_diffuse + final_env + backlight;float3 final_color = combined_color;return float4(final_color,1.0); 前向渲染叠加只需要将穿透光部分加过来就行。不需要加环境光之类的","categories":[{"name":"游戏","slug":"游戏","permalink":"https://mrchenlearnspace.github.io/categories/%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"Shader","slug":"Shader","permalink":"https://mrchenlearnspace.github.io/tags/Shader/"}]},{"title":"环境贴图技术","slug":"环境贴图技术","date":"2022-03-31T18:38:45.000Z","updated":"2022-11-14T14:21:48.260Z","comments":true,"path":"2022/04/01/环境贴图技术/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/04/01/%E7%8E%AF%E5%A2%83%E8%B4%B4%E5%9B%BE%E6%8A%80%E6%9C%AF/","excerpt":"","text":"大纲 环境贴图 立方体贴图采样如上 采样缺陷当同一角度，不同位置看过去会得到同样采样，所以不适合平面采样，解决方案后续说。 1234567891011121314151617181920212223242526272829303132333435v2f vert (appdata v) &#123; v2f o; o.pos = UnityObjectToClipPos(v.vertex); o.normal_world = normalize(mul((v.normal),unity_WorldToObject).xyz); o.tangent_world = normalize(mul((v.tangent),unity_WorldToObject).xyz); o.binormal_world=normalize(cross(o.normal_world,o.tangent_world) * v.tangent.w); o.pos_world = normalize(mul((v.vertex),unity_WorldToObject).xyz); o.uv = v.uv*_NormalMap_ST.xy+_NormalMap_ST.zw; return o; &#125; fixed4 frag (v2f i) : SV_Target &#123; // sample the texture //fixed4 base_col = tex2D(_MainTex, i.uv); fixed4 base_col = fixed4(0,0,0,0); half3 normaldata = UnpackNormal( tex2D(_NormalMap, i.uv)); half3 normal_world = normalize(i.normal_world); half3 tangent_world = normalize(i.tangent_world); half3 binormal_world = normalize(i.binormal_world); normal_world=mul(normaldata, float3x3(tangent_world,binormal_world,normal_world)); half3 view_dir = normalize(_WorldSpaceCameraPos.xyz-i.pos_world.xyz); half3 reflect_dir =reflect(-view_dir,normal_world); half4 finish_col = base_col; half4 Cube_col=texCUBE(_CubeMap,reflect_dir); half3 CubeHDR_col=DecodeHDR(Cube_col,_CubeMap_HDR); finish_col.rgb+=CubeHDR_col; return finish_col; &#125; IBL 基于图像的光照技术预计算卷积通过模糊，得到不同层次的mip Map，便于模拟相应的磨砂层次。 1half4 Cube_col=texCUBElod(_CubeMap,float4(reflect_dir,_Roughness)) 粗糙度变成非线性 1roughness=roughness*(1.7-0.7*roughness); 反射探针1half4 Cube_col = UNITY_SAMPLE_TEXCUBE_LOD(unity_SpecCube0,reflect_dir,_Roughness); 为了用反射探针 UNITY_SAMPLE_TEXCUBE_LOD(反射贴图，反射向量，mip) UNITY_SAMPLE_TEXCUBE(反射贴图，反射向量) 反射探针贴图 unity_SpecCube0 SH球谐光照造轮子shader将光照信息记录下来，实现间接光照。 属性 1234567custom_SHAr(&quot;Custom SHAr&quot;, Vector) = (0, 0, 0, 0)custom_SHAg(&quot;Custom SHAg&quot;, Vector) = (0, 0, 0, 0)custom_SHAb(&quot;Custom SHAb&quot;, Vector) = (0, 0, 0, 0)custom_SHBr(&quot;Custom SHBr&quot;, Vector) = (0, 0, 0, 0)custom_SHBg(&quot;Custom SHBg&quot;, Vector) = (0, 0, 0, 0)custom_SHBb(&quot;Custom SHBb&quot;, Vector) = (0, 0, 0, 0)custom_SHC(&quot;Custom SHC&quot;, Vector) = (0, 0, 0, 1) 片元 1234567891011121314151617181920212223float4 normalForSH = float4(normal_dir, 1.0);//SHEvalLinearL0L1half3 x;x.r = dot(custom_SHAr, normalForSH);x.g = dot(custom_SHAg, normalForSH);x.b = dot(custom_SHAb, normalForSH);//SHEvalLinearL2half3 x1, x2;// 4 of the quadratic (L2) polynomialshalf4 vB = normalForSH.xyzz * normalForSH.yzzx;x1.r = dot(custom_SHBr, vB);x1.g = dot(custom_SHBg, vB);x1.b = dot(custom_SHBb, vB);// Final (5th) quadratic (L2) polynomialhalf vC = normalForSH.x*normalForSH.x - normalForSH.y*normalForSH.y;x2 = custom_SHC.rgb * vC;float3 sh = max(float3(0.0, 0.0, 0.0), (x + x1 + x2));sh = pow(sh, 1.0 / 2.2);half3 env_color = sh; 部分函数可以放在顶点着色器中 获取属性工具SphericalHarmonicsCoefficient123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220/// &lt;summary&gt;/// 球谐光照因子计算方法,结果可以跟Unity内部的算法匹配上/// http://sunandblackcat.com/tipFullView.php?l=eng&amp;topicid=32&amp;topic=Spherical-Harmonics-From-Cube-Texture/// https://github.com/Microsoft/DirectXMath/// http://www.ppsloan.org/publications/StupidSH36.pdf/// &lt;/summary&gt;using UnityEngine;using UnityEditor;public static class SphericalHarmonicsCoefficient&#123; public static void sphericalHarmonicsFromCubemap9(Cubemap cubeTexture, ref Vector3[] output) &#123; // allocate memory for calculations float[] resultR = new float[9]; float[] resultG = new float[9]; float[] resultB = new float[9]; // initialize values float fWt = 0.0f; for (uint i = 0; i &lt; 9; i++) &#123; resultR[i] = 0; resultG[i] = 0; resultB[i] = 0; &#125; float[] shBuff = new float[9]; float[] shBuffB = new float[9]; // for each face of cube texture for (int face = 0; face &lt; 6; face++) &#123; // step between two texels for range [0, 1] float invWidth = 1.0f / cubeTexture.width; // initial negative bound for range [-1, 1] float negativeBound = -1.0f + invWidth; // step between two texels for range [-1, 1] float invWidthBy2 = 2.0f / cubeTexture.width; Color[] data = cubeTexture.GetPixels((CubemapFace)face); for (int y = 0; y &lt; cubeTexture.width; y++) &#123; // texture coordinate V in range [-1 to 1] float fV = negativeBound + y * invWidthBy2; for (int x = 0; x &lt; cubeTexture.width; x++) &#123; // texture coordinate U in range [-1 to 1] float fU = negativeBound + x * invWidthBy2; // determine direction from center of cube texture to current texel Vector3 dir; switch ((CubemapFace)face) &#123; case CubemapFace.PositiveX: dir.x = 1.0f; dir.y = 1.0f - (invWidthBy2 * y + invWidth); dir.z = 1.0f - (invWidthBy2 * x + invWidth); break; case CubemapFace.NegativeX: dir.x = -1.0f; dir.y = 1.0f - (invWidthBy2 * y + invWidth); dir.z = -1.0f + (invWidthBy2 * x + invWidth); break; case CubemapFace.PositiveY: dir.x = -1.0f + (invWidthBy2 * x + invWidth); dir.y = 1.0f; dir.z = -1.0f + (invWidthBy2 * y + invWidth); break; case CubemapFace.NegativeY: dir.x = -1.0f + (invWidthBy2 * x + invWidth); dir.y = -1.0f; dir.z = 1.0f - (invWidthBy2 * y + invWidth); break; case CubemapFace.PositiveZ: dir.x = -1.0f + (invWidthBy2 * x + invWidth); dir.y = 1.0f - (invWidthBy2 * y + invWidth); dir.z = 1.0f; break; case CubemapFace.NegativeZ: dir.x = 1.0f - (invWidthBy2 * x + invWidth); dir.y = 1.0f - (invWidthBy2 * y + invWidth); dir.z = -1.0f; break; default: return; &#125; // normalize direction dir = dir.normalized; // scale factor depending on distance from center of the face float fDiffSolid = 4.0f / ((1.0f + fU * fU + fV * fV) * Mathf.Sqrt(1.0f + fU * fU + fV * fV)); fWt += fDiffSolid; // calculate coefficients of spherical harmonics for current direction sphericalHarmonicsEvaluateDirection9(ref shBuff, dir); //XMSHEvalDirection(dir, ref shBuff); // index of texel in texture int pixOffsetIndex = x + y * cubeTexture.width; // get color from texture and map to range [0, 1] Vector3 clr= new Vector3(data[pixOffsetIndex].r, data[pixOffsetIndex].g, data[pixOffsetIndex].b); //if (data[pixOffsetIndex].a == 1) //&#123; // clr = new Vector3(data[pixOffsetIndex].r, data[pixOffsetIndex].g, data[pixOffsetIndex].b); //&#125; //else //&#123; // clr = DecodeHDR(data[pixOffsetIndex]); //&#125; if (PlayerSettings.colorSpace == ColorSpace.Gamma) &#123; clr.x = Mathf.GammaToLinearSpace(clr.x); clr.y = Mathf.GammaToLinearSpace(clr.y); clr.z = Mathf.GammaToLinearSpace(clr.z); &#125; // scale color and add to previously accumulated coefficients sphericalHarmonicsScale9(ref shBuffB, shBuff, clr.x * fDiffSolid); sphericalHarmonicsAdd9(ref resultR, resultR, shBuffB); sphericalHarmonicsScale9(ref shBuffB, shBuff, clr.y * fDiffSolid); sphericalHarmonicsAdd9(ref resultG, resultG, shBuffB); sphericalHarmonicsScale9(ref shBuffB, shBuff, clr.z * fDiffSolid); sphericalHarmonicsAdd9(ref resultB, resultB, shBuffB); &#125; &#125; &#125; // final scale for coefficients float fNormProj = (4.0f * Mathf.PI) / fWt; sphericalHarmonicsScale9(ref resultR, resultR, fNormProj); sphericalHarmonicsScale9(ref resultG, resultG, fNormProj); sphericalHarmonicsScale9(ref resultB, resultB, fNormProj); // save result for (uint i = 0; i &lt; 9; i++) &#123; output[i].x = resultR[i]; output[i].y = resultG[i]; output[i].z = resultB[i]; &#125; &#125; private static Vector3 DecodeHDR(Color clr) &#123; return new Vector3(clr.r, clr.g, clr.b) * clr.a;// * Mathf.Pow(clr.a, 2);// * (Mathf.Pow(clr.a, 0.1f) * 1); &#125; private static void sphericalHarmonicsEvaluateDirection9(ref float[] outsh, Vector3 dir) &#123; // 86 clocks // Make sure all constants are never computed at runtime const float kInv2SqrtPI = 0.28209479177387814347403972578039f; // 1 / (2*sqrt(kPI)) const float kSqrt3Div2SqrtPI = 0.48860251190291992158638462283835f; // sqrt(3) / (2*sqrt(kPI)) const float kSqrt15Div2SqrtPI = 1.0925484305920790705433857058027f; // sqrt(15) / (2*sqrt(kPI)) const float k3Sqrt5Div4SqrtPI = 0.94617469575756001809268107088713f; // 3 * sqrtf(5) / (4*sqrt(kPI)) const float kSqrt15Div4SqrtPI = 0.54627421529603953527169285290135f; // sqrt(15) / (4*sqrt(kPI)) const float kOneThird = 0.3333333333333333333333f; // 1.0/3.0 outsh[0] = kInv2SqrtPI; outsh[1] = -dir.y * kSqrt3Div2SqrtPI; outsh[2] = dir.z * kSqrt3Div2SqrtPI; outsh[3] = -dir.x * kSqrt3Div2SqrtPI; outsh[4] = dir.x * dir.y * kSqrt15Div2SqrtPI; outsh[5] = -dir.y * dir.z * kSqrt15Div2SqrtPI; outsh[6] = (dir.z * dir.z - kOneThird) * k3Sqrt5Div4SqrtPI; outsh[7] = -dir.x * dir.z * kSqrt15Div2SqrtPI; outsh[8] = (dir.x * dir.x - dir.y * dir.y) * kSqrt15Div4SqrtPI; &#125; private static void sphericalHarmonicsAdd9(ref float[] result, float[] inputA, float[] inputB) &#123; for (int i = 0; i &lt; 9; i++) &#123; result[i] = inputA[i] + inputB[i]; &#125; &#125; private static void sphericalHarmonicsScale9(ref float[] result, float[] input, float scale) &#123; for (int i = 0; i &lt; 9; i++) &#123; result[i] = input[i] * scale; &#125; &#125; public static readonly float s_fSqrtPI = Mathf.Sqrt(Mathf.PI); public static readonly float fC0 = 1.0f / (2.0f * s_fSqrtPI); public static readonly float fC1 = Mathf.Sqrt(3.0f) / (3.0f * s_fSqrtPI); public static readonly float fC2 = Mathf.Sqrt(15.0f) / (8.0f * s_fSqrtPI); public static readonly float fC3 = Mathf.Sqrt(5.0f) / (16.0f * s_fSqrtPI); public static readonly float fC4 = 0.5f * fC2; public static void ConvertSHConstants(Vector3[] sh, ref Vector4[] SHArBrC) &#123; int iC; for (iC = 0; iC &lt; 3; iC++) &#123; SHArBrC[iC].x = -fC1 * sh[3][iC]; SHArBrC[iC].y = -fC1 * sh[1][iC]; SHArBrC[iC].z = fC1 * sh[2][iC]; SHArBrC[iC].w = fC0 * sh[0][iC] - fC3 * sh[6][iC]; &#125; for (iC = 0; iC &lt; 3; iC++) &#123; SHArBrC[iC + 3].x = fC2 * sh[4][iC]; SHArBrC[iC + 3].y = -fC2 * sh[5][iC]; SHArBrC[iC + 3].z = 3.0f * fC3 * sh[6][iC]; SHArBrC[iC + 3].w = -fC2 * sh[7][iC]; &#125; SHArBrC[6].x = fC4 * sh[8][0]; SHArBrC[6].y = fC4 * sh[8][1]; SHArBrC[6].z = fC4 * sh[8][2]; SHArBrC[6].w = 1.0f; &#125;&#125; CubemapSHProjector123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196using System.Collections;using System.Collections.Generic;using UnityEngine;using UnityEditor;public class CubemapSHProjector : EditorWindow&#123; //PUBLIC FIELDS public Texture envMap; public Transform go; //PRIVATE FIELDS private Material view_mat; private float view_mode; private Vector4[] coefficients; private SerializedObject so; private SerializedProperty sp_input_cubemap; private Texture2D tmp = null; private static void CheckAndConvertEnvMap(ref Texture envMap, ref Vector4[] sh_out) &#123; if (!envMap) return; string map_path = AssetDatabase.GetAssetPath(envMap); if (string.IsNullOrEmpty(map_path)) return; TextureImporter ti = AssetImporter.GetAtPath(map_path) as TextureImporter; if (!ti) return; bool read_able = ti.isReadable; bool need_reimport = false; if (ti.textureShape != TextureImporterShape.TextureCube) &#123; ti.textureShape = TextureImporterShape.TextureCube; need_reimport = true; &#125; if (!ti.mipmapEnabled) &#123; ti.mipmapEnabled = true; need_reimport = true; &#125; if (!ti.sRGBTexture) &#123; ti.sRGBTexture = true; need_reimport = true; &#125; if (ti.filterMode != FilterMode.Trilinear) &#123; ti.filterMode = FilterMode.Trilinear; need_reimport = true; &#125; TextureImporterSettings tis = new TextureImporterSettings(); ti.ReadTextureSettings(tis); if (tis.cubemapConvolution != TextureImporterCubemapConvolution.Specular) &#123; tis.cubemapConvolution = TextureImporterCubemapConvolution.Specular; ti.SetTextureSettings(tis); need_reimport = true; &#125; //if (ti.GetDefaultPlatformTextureSettings().maxTextureSize != 128) //&#123; // TextureImporterPlatformSettings tips = new TextureImporterPlatformSettings(); // tips.maxTextureSize = 128; // ti.SetPlatformTextureSettings(tips); // ti.maxTextureSize = 128; // need_reimport = true; //&#125; if (!read_able) &#123; ti.isReadable = true; need_reimport = true; &#125; if (need_reimport) &#123; ti.SaveAndReimport(); &#125; envMap = AssetDatabase.LoadAssetAtPath&lt;Texture&gt;(map_path); if (!envMap) return; Vector3[] sh = new Vector3[9]; SphericalHarmonicsCoefficient.sphericalHarmonicsFromCubemap9((Cubemap)envMap, ref sh); SphericalHarmonicsCoefficient.ConvertSHConstants(sh, ref sh_out); if (ti.isReadable != read_able) &#123; ti.isReadable = read_able; ti.SaveAndReimport(); envMap = AssetDatabase.LoadAssetAtPath&lt;Texture&gt;(map_path); &#125; &#125; [MenuItem(&quot;美术/SH系数生成&quot;, false, 2100)] static void Init() &#123; CubemapSHProjector window = (CubemapSHProjector)EditorWindow.GetWindow(typeof(CubemapSHProjector)); window.Show(); window.titleContent = new GUIContent(&quot;SH生成器&quot;); &#125; private void OnFocus() &#123; Initialize(); &#125; private void OnEnable() &#123; Initialize(); &#125; private void Initialize() &#123; so = new SerializedObject(this); sp_input_cubemap = so.FindProperty(&quot;input_cubemap&quot;); &#125; private void OnGUI() &#123; EditorGUI.BeginChangeCheck(); envMap = EditorGUILayout.ObjectField(&quot;环境图&quot;, envMap, typeof(Texture), false) as Texture; if (envMap != null) &#123; EditorGUILayout.Space(); if (GUILayout.Button(&quot;Calc&quot;)) &#123; if (envMap != null) &#123; coefficients = new Vector4[7]; CheckAndConvertEnvMap(ref envMap, ref coefficients); &#125; SceneView.RepaintAll(); &#125; EditorGUILayout.Space(); go = EditorGUILayout.ObjectField(&quot;Obj&quot;, go, typeof(Transform), true) as Transform; if (go != null) &#123; if (GUILayout.Button(&quot;Apply&quot;)) &#123; List&lt;Material&gt; mat_list = new List&lt;Material&gt;(); var renders = go.GetComponentsInChildren&lt;Renderer&gt;(); foreach (var render in renders) &#123; mat_list.AddRange(render.sharedMaterials); &#125; foreach (var mat in mat_list) &#123; mat.SetVector(&quot;custom_SHAr&quot;, coefficients[0]); mat.SetVector(&quot;custom_SHAg&quot;, coefficients[1]); mat.SetVector(&quot;custom_SHAb&quot;, coefficients[2]); mat.SetVector(&quot;custom_SHBr&quot;, coefficients[3]); mat.SetVector(&quot;custom_SHBg&quot;, coefficients[4]); mat.SetVector(&quot;custom_SHBb&quot;, coefficients[5]); mat.SetVector(&quot;custom_SHC&quot;, coefficients[6]); &#125; mat_list.Clear(); SceneView.RepaintAll(); &#125; &#125; EditorGUILayout.Space(); //print the 9 coefficients if (coefficients != null) &#123; EditorGUILayout.LabelField(&quot;custom_SHAr&quot; + &quot;: &quot; + coefficients[0].ToString(&quot;F4&quot;)); EditorGUILayout.LabelField(&quot;custom_SHAg&quot; + &quot;: &quot; + coefficients[1].ToString(&quot;F4&quot;)); EditorGUILayout.LabelField(&quot;custom_SHAb&quot; + &quot;: &quot; + coefficients[2].ToString(&quot;F4&quot;)); EditorGUILayout.LabelField(&quot;custom_SHBr&quot; + &quot;: &quot; + coefficients[3].ToString(&quot;F4&quot;)); EditorGUILayout.LabelField(&quot;custom_SHBg&quot; + &quot;: &quot; + coefficients[4].ToString(&quot;F4&quot;)); EditorGUILayout.LabelField(&quot;custom_SHBb&quot; + &quot;: &quot; + coefficients[5].ToString(&quot;F4&quot;)); EditorGUILayout.LabelField(&quot;custom_SHC&quot; + &quot;: &quot; + coefficients[6].ToString(&quot;F4&quot;)); &#125; &#125; EditorGUILayout.Space(); if (tmp != null) GUILayout.Label(tmp); &#125;&#125; Unity内置函数换上小皮肤 1234567Tags&#123;&quot;LightMode&quot;=&quot;ForwardBase&quot;&#125;CGPROGRAM#pragma vertex vert#pragma fragment frag#pragma multi_compile_fwdbase#include &quot;AutoLight.cginc&quot;#include &quot;UnityCG.cginc&quot; 片元 1half3 env_color = ShadeSH9(float4(normal_dir,1.0)); 完成 光照探测器光照探测器的小球记录下问题的球谐数值，然后物体在范围内时，用物体周围小球的球谐数值做插值。","categories":[{"name":"游戏","slug":"游戏","permalink":"https://mrchenlearnspace.github.io/categories/%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"Shader","slug":"Shader","permalink":"https://mrchenlearnspace.github.io/tags/Shader/"}]},{"title":"色调映射视差偏移","slug":"色调映射视差偏移","date":"2022-03-25T18:38:45.000Z","updated":"2022-11-14T14:22:10.595Z","comments":true,"path":"2022/03/26/色调映射视差偏移/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/03/26/%E8%89%B2%E8%B0%83%E6%98%A0%E5%B0%84%E8%A7%86%E5%B7%AE%E5%81%8F%E7%A7%BB/","excerpt":"","text":"Blinn-Phong半角向量&#x3D;观察方向V+光照方向L； 12345half3 view_dir = normalize(_WorldSpaceCameraPos.xyz - i.pos_world); half3 light_dir =normalize( _WorldSpaceLightPos0.xyz ); half3 half_dir = normalize(view_dir+light_dir);half NotH = max(dot(normal_dir,half_dir),0);half3 specular = pow(max(NotH,0),_Shininess)* _LightColor0.xyz*_SpecularIntensity*spec_mask; 色彩映射高光部分过曝，使得颜色直接变白色为了体现更多细节，将色调重新映射,注意一般这个处理都在后处理完成。实现如下。 123456789101112float3 ACESFilm(float3 x) &#123; float a = 2.51f; float b = 0.03f; float c = 2.43f; float d = 0.59f; float e = 0.14f; return saturate((x*(a*x + b)) / (x*(c*x + d) + e)); &#125;;base_color =pow(base_color,2.2);half3 tone_color = ACESFilm(col.xyz);col.xyz=pow(tone_color,1.0/2.2); 视察偏移用高度图模拟侧面的观察的遮挡问题 1234567891011float3 view_tangentspace = normalize(mul(TBN,view_dir)); half2 uv_parallax = i.uv; for(int j=0;j&lt;_HeightTime;j++) &#123; half height = tex2D(_Parallax,uv_parallax); uv_parallax = uv_parallax - (0.5 - height) * (view_tangentspace.xy/view_tangentspace.z+0.42) *_ParallaxIntensity*0.01f; &#125; half3 base_color = tex2D(_MainTex, uv_parallax).xyz; base_color =pow(base_color,2.2); half3 AO = tex2D(_AOMap,uv_parallax).xyz; half3 spec_mask = tex2D(_SpecMask,uv_parallax).xyz; 阴影 实时阴影理论知识全适用，但代码只适用于内置渲染管线 传统实时阴影 阴影距离决定定向光的拍摄位置位置大概是 1//摄像头的 forword 向量*阴影距离 向光照反方向 + 阴影距离 在光源位置做摄像机，拍摄一张深度图 将光源摄像头内的顶点转入光源相机空间用z坐标z1和shadowMap的灰度值z2进行比对，z1&lt;z2，则不再阴影区，最佳理解：就是单纯的摄像机深度剔除的部分，把光源看作摄像机，看到的就被照亮，没看到的就是阴影咯。 Unity屏幕空间阴影用摄像头view渲染深度图，渲染的深度图可以还原屏幕需要的片元的世界坐标空间进行优化 然后从Camera直接转到光照摄像头坐标系下。 联级阴影 CSM以下是个人通过unity猜测出来的，暂未找资料 分成四个区域，越靠近物体联级越多，把所有得到的联级进行均值混合原理还是前两种方法 证明 无联级，阴影距离3.3 两联级，阴影距离10 得到的阴影效果会胡一点，可能是混合了 阴影相关的内置函数只计算实时阴影记得把v2f结构体中的vertex改成pos。 123SHADOW_COORDS(5)TRANSFER_SHADOW(o)half shadow = SHADOW_ATTENUATION(i); 多光源 混合光源计算1234LIGHTING_COORDS(5,6)TRANSFER_VERTEX_TO_FRAGMENT(o);half atten = LIGHT_ATTENUATION (i);half NotL = min(atten,max(dot(normal_dir,light_dir),0)); 在forwardadd中一定把环境光删除，否则出现阴影锯齿。 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270Shader &quot;lit/Blin-Phong&quot;&#123; Properties &#123; _MainTex (&quot;Texture&quot;, 2D) = &quot;white&quot; &#123;&#125; _NormalMap(&quot;Normal Map&quot;,2D)=&quot;bump&quot;&#123;&#125; _NormalIntensity(&quot;Normal Intensity&quot;,Range(0.0,5.0))= 1.0 _AOMap(&quot;AO Map&quot;,2D)=&quot;white&quot;&#123;&#125; _SpecMask(&quot;Spec Mask&quot;,2D)=&quot;white&quot;&#123;&#125; _Shininess (&quot;Shininess&quot;, Float) = 1 _SpecularIntensity(&quot;SpecularIntensity&quot;,Range(0.01,5))= 1.0 _Parallax(&quot;Parallax&quot;,2D)=&quot;black&quot;&#123;&#125; _ParallaxIntensity(&quot;Parallax Intensity&quot;,Float)=1.0 _HeightTime(&quot;Height Time&quot;,Range(0,10))=1.0 //_AmbientColor(&quot;Ambient Color&quot;,Color)=(0,0,0,0) // __AmbientIntensity(&quot;Ambient Intensity&quot;,Float)=0 &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot;=&quot;Opaque&quot; &#125; LOD 100 Pass &#123; Tags &#123; &quot;LightMode&quot; = &quot;ForwardBase&quot;&#125; CGPROGRAM #pragma vertex vert #pragma fragment frag #pragma multi_compile_fwdbase #include &quot;UnityCG.cginc&quot; #include &quot;AutoLight.cginc&quot; struct appdata &#123; float4 vertex : POSITION; float2 uv : TEXCOORD0; float3 normal:NORMAL; float4 tangent:TANGENT; &#125;; struct v2f &#123; float2 uv : TEXCOORD0; float4 pos : SV_POSITION; float3 normali_dir:TEXCOORD1; float3 tangent_dir:TEXCOORD2; float3 binormal_dir:TEXCOORD3; float3 pos_world:TEXCOORD4; SHADOW_COORDS(5) &#125;; sampler2D _MainTex; float4 _MainTex_ST; sampler2D _AOMap; float4 _AOMap_ST; float4 _LightColor0; float _Shininess; float _SpecularIntensity; //float4 _AmbientColor; sampler2D _SpecMask; float _SpecMask_ST; sampler2D _NormalMap; float4 _NormalMap_ST; float _NormalIntensity; sampler2D _Parallax; float _ParallaxIntensity; float _HeightTime; //float __AmbientIntensity; float3 ACESFilm(float3 x) &#123; float a = 2.51f; float b = 0.03f; float c = 2.43f; float d = 0.59f; float e = 0.14f; return saturate((x*(a*x + b)) / (x*(c*x + d) + e)); &#125;; v2f vert (appdata v) &#123; v2f o; o.pos = UnityObjectToClipPos(v.vertex); o.normali_dir = normalize(mul(float4(v.normal,0.0),unity_WorldToObject).xyz); o.tangent_dir = normalize(mul(float4(v.tangent.xyz,0.0),unity_WorldToObject).xyz); o.binormal_dir = normalize(cross(o.normali_dir,o.tangent_dir))* v.tangent.w; o.pos_world = mul(unity_ObjectToWorld,v.vertex).xyz; o.uv = TRANSFORM_TEX(v.uv, _MainTex); TRANSFER_SHADOW(o) return o; &#125; fixed4 frag (v2f i) : SV_Target &#123; fixed4 col=fixed4(0,0,0,0); half shadow = SHADOW_ATTENUATION(i); half4 normalmap = tex2D(_NormalMap,i.uv); half3 view_dir = normalize(_WorldSpaceCameraPos.xyz - i.pos_world); half3 light_dir =normalize( _WorldSpaceLightPos0.xyz ); half3 half_dir = normalize(view_dir+light_dir); //Normal half3 normal_dir =normalize(i.normali_dir); half3 tangent_dir =normalize(i.tangent_dir)*_NormalIntensity; half3 binormal_dir =normalize(i.binormal_dir)*_NormalIntensity; half3 normal_data = UnpackNormal(normalmap); float3x3 TBN = float3x3(tangent_dir,binormal_dir,normal_dir); normal_dir =normalize(mul(normal_data,TBN)); //normal_dir=tangent_dir*normal_data.x*_NormalIntensity+binormal_dir*normal_data.y*_NormalIntensity+normal_dir*normal_data.z ; float3 view_tangentspace = normalize(mul(TBN,view_dir)); half2 uv_parallax = i.uv; for(int j=0;j&lt;_HeightTime;j++) &#123; half height = tex2D(_Parallax,uv_parallax); uv_parallax = uv_parallax - (0.5 - height) * (view_tangentspace.xy/view_tangentspace.z+0.42) *_ParallaxIntensity*0.01f; &#125; half3 base_color = tex2D(_MainTex, uv_parallax).xyz; base_color =pow(base_color,2.2); half3 AO = tex2D(_AOMap,uv_parallax).xyz; half3 spec_mask = tex2D(_SpecMask,uv_parallax).xyz; half NotL = min(shadow,max(dot(normal_dir,light_dir),0)); half NotH = max(dot(normal_dir,half_dir),0); half3 diffuse = NotL*_LightColor0.xyz; half3 specular = pow(max(NotH,0),_Shininess)* _LightColor0.xyz*_SpecularIntensity*spec_mask*NotL; // half3 ambient = _AmbientColor.xyz*__AmbientIntensity; //col.xyz+= AO; col.xyz += diffuse; col.xyz += specular; col.xyz += UNITY_LIGHTMODEL_AMBIENT.xyz; // sample the texture col.xyz *=base_color; col.xyz *=AO; half3 tone_color = ACESFilm(col.xyz); col.xyz=pow(tone_color,1.0/2.2); // apply fog return col; &#125; ENDCG &#125; Pass &#123; Tags &#123; &quot;LightMode&quot; = &quot;ForwardAdd&quot;&#125; Blend One One CGPROGRAM #pragma vertex vert #pragma fragment frag #pragma multi_compile_fwdadd #include &quot;UnityCG.cginc&quot; #include &quot;AutoLight.cginc&quot; struct appdata &#123; float4 vertex : POSITION; float2 uv : TEXCOORD0; float3 normal:NORMAL; float4 tangent:TANGENT; &#125;; struct v2f &#123; float2 uv : TEXCOORD0; float4 pos : SV_POSITION; float3 normali_dir:TEXCOORD1; float3 tangent_dir:TEXCOORD2; float3 binormal_dir:TEXCOORD3; float3 pos_world:TEXCOORD4; LIGHTING_COORDS(5,6) &#125;; sampler2D _MainTex; float4 _MainTex_ST; sampler2D _AOMap; float4 _AOMap_ST; float4 _LightColor0; float _Shininess; float _SpecularIntensity; //float4 _AmbientColor; sampler2D _SpecMask; float _SpecMask_ST; sampler2D _NormalMap; float4 _NormalMap_ST; float _NormalIntensity; sampler2D _Parallax; float _ParallaxIntensity; float _HeightTime; //float __AmbientIntensity; v2f vert (appdata v) &#123; v2f o; o.pos = UnityObjectToClipPos(v.vertex); o.normali_dir = normalize(mul(float4(v.normal,0.0),unity_WorldToObject).xyz); o.tangent_dir = normalize(mul(float4(v.tangent.xyz,0.0),unity_WorldToObject).xyz); o.binormal_dir = normalize(cross(o.normali_dir,o.tangent_dir))* v.tangent.w; o.pos_world = mul(unity_ObjectToWorld,v.vertex).xyz; o.uv = TRANSFORM_TEX(v.uv, _MainTex); TRANSFER_VERTEX_TO_FRAGMENT(o); return o; &#125; fixed4 frag (v2f i) : SV_Target &#123; fixed4 col=fixed4(0,0,0,0); half atten = LIGHT_ATTENUATION (i); half4 normalmap = tex2D(_NormalMap,i.uv); half3 view_dir = normalize(_WorldSpaceCameraPos.xyz - i.pos_world); half3 light_dir_point =normalize( _WorldSpaceLightPos0.xyz - i.pos_world); half3 light_dir =normalize( _WorldSpaceLightPos0.xyz ); light_dir = lerp(light_dir,light_dir_point,_WorldSpaceLightPos0.w); half3 half_dir = normalize(view_dir+light_dir); //Normal half3 normal_dir =normalize(i.normali_dir); half3 tangent_dir =normalize(i.tangent_dir)*_NormalIntensity; half3 binormal_dir =normalize(i.binormal_dir)*_NormalIntensity; half3 normal_data = UnpackNormal(normalmap); float3x3 TBN = float3x3(tangent_dir,binormal_dir,normal_dir); normal_dir =normalize(mul(normal_data,TBN)); //normal_dir=tangent_dir*normal_data.x*_NormalIntensity+binormal_dir*normal_data.y*_NormalIntensity+normal_dir*normal_data.z ; float3 view_tangentspace = normalize(mul(TBN,view_dir)); half2 uv_parallax = i.uv; for(int j=0;j&lt;_HeightTime;j++) &#123; half height = tex2D(_Parallax,uv_parallax); uv_parallax = uv_parallax - (0.5 - height) * (view_tangentspace.xy/view_tangentspace.z+0.42) *_ParallaxIntensity*0.01f; &#125; half3 base_color = tex2D(_MainTex, uv_parallax).xyz; half3 AO = tex2D(_AOMap,uv_parallax).xyz; half3 spec_mask = tex2D(_SpecMask,uv_parallax).xyz; half NotL = min(atten,max(dot(normal_dir,light_dir),0)); half NotH = max(dot(normal_dir,half_dir),0); half3 diffuse = NotL*_LightColor0.xyz; half3 specular = pow(max(NotH,0),_Shininess)* _LightColor0.xyz*_SpecularIntensity*spec_mask*NotL; col.xyz += diffuse; col.xyz += specular; // sample the texture col.xyz *=base_color; col.xyz *=AO; // apply fog return col; &#125; ENDCG &#125; &#125; FallBack &quot;Diffuse&quot;&#125;","categories":[{"name":"游戏","slug":"游戏","permalink":"https://mrchenlearnspace.github.io/categories/%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"Shader","slug":"Shader","permalink":"https://mrchenlearnspace.github.io/tags/Shader/"}]},{"title":"OpenCV的边缘计算","slug":"OpenCV的边缘计算","date":"2022-03-22T13:38:45.000Z","updated":"2022-11-14T14:24:32.841Z","comments":true,"path":"2022/03/22/OpenCV的边缘计算/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/03/22/OpenCV%E7%9A%84%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/","excerpt":"","text":"基于梯度的检测器 梯边缘，顶边缘，坡边缘 有限差分最简单的梯度算子$$gx&#x3D;f(x+1,y)-f(x,y) \\gy&#x3D;f(x,y+1)-f(x,y)$$ Sobel算子对于具有噪声的图有很好的效果$$gx&#x3D;\\frac{1}{8}\\left[ \\begin{matrix} -1 &amp; 0 &amp; 1 \\ -2 &amp; 0 &amp; 2 \\ -1 &amp; 0 &amp; 1 \\end{matrix} \\right]\\gy&#x3D;\\frac{1}{8}\\left[ \\begin{matrix} 1 &amp; 2 &amp; 1 \\ 0 &amp; 0 &amp; 0 \\ -1 &amp; -2 &amp; -1 \\end{matrix} \\right]$$ 基于曲率的检测器缺点，对于薄边缘在精准定位边缘没有优势 Marr-Hildreth$$gx-g(x-1)&#x3D;f(x+1,y)-f(x,y) -(f(x,y)-f(x-1,y) )&#x3D;f(x+1,y)-f(x-1,y)-2f(x,y)$$ 高斯的拉普拉斯滤波器LoG考虑四边的核$$\\frac{1}{8}\\left[ \\begin{matrix} 0 &amp; -1 &amp; 0 \\ -1 &amp; 4 &amp; -1 \\ 0 &amp; -1 &amp; 0 \\end{matrix} \\right]$$考虑全部八个方向$$\\frac{1}{8}\\left[ \\begin{matrix} -1 &amp; -1 &amp; -1 \\ -1 &amp; 8 &amp; -1 \\ -1 &amp; -1 &amp; -1 \\end{matrix} \\right]$$ Canny边缘检测canny的四步法 使用低通滤波器抑制噪声 计算梯度幅度和方向图 对梯度幅度图使用非极大值抑制 运用迟滞和连通分析检测边缘 123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/opencv.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;#include &lt;iostream&gt;using namespace cv;using namespace std;int main() &#123; Mat srcImage, grayImage; srcImage = imread(&quot;Lena.png&quot;); imshow(&quot;Lena.png&quot;, srcImage); Mat srcImage1 = srcImage.clone(); //图形转换: cvtColor(srcImage, grayImage, COLOR_BGR2GRAY); Mat dstImage, edge; //均值滤波 blur(srcImage1, grayImage, Size(3, 3)); imshow(&quot;grayImage.png&quot;, grayImage); GaussianBlur(grayImage, grayImage, Size(5, 5), 0.8); /* 边缘检测 低于阈值1的像素点会被认为不是边缘； 高于阈值2的像素点会被认为是边缘； 在阈值1和阈值2之间的像素点,若与第2步得到的边缘像素点相邻，则被认为是边缘，否则被认为不是边缘。 */ Canny(grayImage, edge, 150, 100, 3); dstImage.create(srcImage1.size(), srcImage1.type()); dstImage = Scalar::all(0); /* image.copyTo(imageROI)。作用是把image的内容复制粘贴到imageROI上； image.copyTo(imageROI，mask)。 作用是把mask和image重叠以后把mask中像素值为0（black）的点对应的image中的点变为透明，而保留其他点。 */ srcImage1.copyTo(dstImage, edge); imwrite(&quot;canny.jpg&quot;, dstImage); imshow(&quot;canny.jpg&quot;, dstImage); waitKey(0); return 0;&#125; fast算子参考这个代码 计算步骤 从图片中选取一个坐标点,获取该点的像素值,接下来判定该点是否为特征点. 选取一个以选取点坐标为圆心的半径等于三的Bresenham圆(一个计算圆的轨迹的离散算法,得到整数级的圆的轨迹点),一般来说,这个圆上有16个点 现在选取一个阈值,假设为t,关键步骤,假设这16个点中,有N个连续的像素点,他们的亮度值与中心点的像素值的差大于或者小于t,那么这个点就是一个特征点.(n的取值一般取值12或者9,实验证明9可以取得更好的效果,因为可以获取更多的特征点,后面进行处理时,数据样本额相对多一些). 加入每个轨迹点都需要遍历的话,那么需要的时间比较长,有一种比较简单的方法可以选择,那就是仅仅检查在位置1，9，5和13四个位置的像素，首先检测位置1和位置9，如果它们都比阈值暗或比阈值亮，再检测位置5和位置13,该满足判断条件。如果不满足中心点不可能是一个角点。对于所有点做上面这一部分初步的检测后，符合条件的将成为候选的角点，我们再对候选的角点，做完整的测试，即检测圆上的所有点. 但是,这种检测方法会带来一个问题,就是造成特征点的聚簇效应,多个特征点在图像的某一块重复高频率的出现,FAST算法提出了一种非极大值抑制的办法来消除这种情况,具体办法如下 对所有检测到的角点构建一个打分函数。就是像素点与周围16个像素点差值的绝对值之和。 考虑两个相邻的角点，并比较它们的值。 值较低的角点将会被删除。 12345678910111213141516171819202122232425262728#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/opencv.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;#include &lt;iostream&gt;using namespace cv;using namespace std;int main() &#123; Mat srcImage, grayImage; srcImage = imread(&quot;Lena.png&quot;); imshow(&quot;Lena.png&quot;, srcImage); Mat gray; cvtColor(srcImage, gray, COLOR_BGR2GRAY); Mat LenaFast; vector&lt;KeyPoint&gt;detectKeyPoint; Mat keyPointImage1; Ptr&lt;FastFeatureDetector&gt; fast = FastFeatureDetector::create(); fast-&gt;detect(gray, detectKeyPoint); drawKeypoints(srcImage, detectKeyPoint, keyPointImage1, Scalar(0, 0, 255), DrawMatchesFlags::DRAW_RICH_KEYPOINTS); imshow(&quot;keyPoint image1&quot;, keyPointImage1); //imshow(&quot;keyPoint image2&quot;, keyPointImage2); waitKey(0); return 0;&#125; 1234567891011enum struct DrawMatchesFlags&#123; DEFAULT = 0, //!&lt; 将创建输出图像矩阵(Mat::create), //!&lt; i.e. 输出图像的现有内存可以重用. //!&lt; 将绘制两个源图像，匹配和单个关键点. //!&lt; 对于每个关键点，只有中心点将被绘制(没有带关键点大小和方向的圆点) DRAW_OVER_OUTIMG = 1, //!&lt; 输出图像矩阵将不会被创建 (Mat::create). //!&lt; 匹配将绘制在输出图像的现有内容上. NOT_DRAW_SINGLE_POINTS = 2, //!&lt; 不会绘制单个关键点。 DRAW_RICH_KEYPOINTS = 4 //!&lt; 对于每个关键点，将绘制具有关键点大小和方向的圆。&#125;; Harris算子步骤如下： 生成梯度图像gx，gy 一个颜色块A，A1到A9 3x3，一个颜色块B，B1到B9 3x3 w x（Ai-Bi）的平方。w是权值比如A5到Ai的距离。 得到两个特征值下x，y如果两个值都很小，没有特征。如果一个很大就存在一条边，都很大，这个点有一个角点。 c++的实现 1234567891011121314151617181920212223#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/opencv.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;#include &lt;iostream&gt;using namespace cv;using namespace std;int main() &#123; Mat srcImage, grayImage; srcImage = imread(&quot;Lena.png&quot;); imshow(&quot;Lena.png&quot;, srcImage); Mat gray; cvtColor(srcImage, gray, COLOR_BGR2GRAY); Mat LenaHarris; cornerHarris(gray, LenaHarris, 7,7, 0.1); imshow(&quot;LenaHarris.jpg&quot;, LenaHarris); waitKey(0); return 0;&#125;","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://mrchenlearnspace.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"https://mrchenlearnspace.github.io/tags/OpenCV/"}]},{"title":"Games104第2节记录","slug":"Games104第2节记录","date":"2022-03-22T08:38:45.000Z","updated":"2022-11-14T14:23:22.436Z","comments":true,"path":"2022/03/22/Games104第2节记录/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/03/22/Games104%E7%AC%AC2%E8%8A%82%E8%AE%B0%E5%BD%95/","excerpt":"","text":"前言Tool Layer 给予开发者使用的工具 Function Layer Resource Layer Core Layer 核心层 Platform Layer 为了适应各种平台 越往上越灵活 越往下越稳定 怎样做一个animation system Resource将其他资源转化为引擎的资产，引擎化。 需要加载进入游戏的文件 将文件全局资产编号GUID Handle管理所有的资源周期 延迟加载 Function1.Tick循环 2.多线程 Core核心层数学库，基本线代，取决于你系统的效率。 simd，如下四个数据一次性处理。 数据结构，无内存碎片，查找效率高 Memory Management，有点像操作系统，进行更高效率的处理。 Platforms平台层去除平台差异 比如将常用的GraphicsAPI抽象出来，用多态解决不同平台的问题。 Tool工具层允许任何人可以创造游戏，开发效率优先。 数据的导入器导出器，能支持其他的3d软件资产 简单ecs框架 总结引擎是分层架构的 越底层越稳定，越上层越灵活 通过Ticks进行驱动虚拟世界","categories":[{"name":"计算机图形学","slug":"计算机图形学","permalink":"https://mrchenlearnspace.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}],"tags":[{"name":"引擎制作","slug":"引擎制作","permalink":"https://mrchenlearnspace.github.io/tags/%E5%BC%95%E6%93%8E%E5%88%B6%E4%BD%9C/"}]},{"title":"Games104第2节记录","slug":"Games104第3节记录","date":"2022-03-22T08:38:45.000Z","updated":"2022-11-14T14:23:29.948Z","comments":true,"path":"2022/03/22/Games104第3节记录/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/03/22/Games104%E7%AC%AC3%E8%8A%82%E8%AE%B0%E5%BD%95/","excerpt":"","text":"如何构建游戏世界如何让游戏世界活起来将物体变成GO（ Game Object） 动态物体 静态物体 环境 ​ 天空，地形，植被 其他物体 ​ 空气墙，规则 如何去描述虚拟世界的物体将物体的属性和行为封装在一起，成为一个对象。 假如但有两个功能时我怎么处理 Component每一个Component类都需要一个tick()函数 多功能物体我们用组合方法来解决。 怎么让游戏动起来进行单个系统进行tick()。 一个一个系统进行tick，而不是一个物体一个物体进行tick，这样的架构会更高效 如何在游戏引爆炸弹事件如果写在一个爆炸类里用switch判断，随着系统的复杂类会越来越大。变得不可调试。爆炸类只需要将这给消息传给其他组件让其他类添加相关方法。 如何管理Game ObjectScene Management每一个物体都需要一个特别的UID 每个物体都需要一个位置 简单的空间分割不需要划分物体较少的情况下直接遍历 优点：特别简单，无脑 缺点：但物体多就效率低 进行网格划分对格子进行编号，发生事件找邻近格子的部分物体 优点：对比上一种方法能减轻弊端 缺点：对于空间不均匀不适用 四叉树对目标块不断的划分。 空间数据管理最常用的是BVH方法。 小结一切都是对象 游戏对象可以用基于组件的方式来描述 游戏对象的状态会在tick循环中更新 游戏对象是通过有效的策略在场景中管理的 物体tick的先后顺序多线程通信问题，当你访问其他线程时先通过一个邮局，然后由邮局统一相互发送消息。保证时序一定一致。比如你的精彩时刻是记录玩家的输入，如果是多核执行可能导致结果不一样。","categories":[{"name":"计算机图形学","slug":"计算机图形学","permalink":"https://mrchenlearnspace.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}],"tags":[{"name":"引擎制作","slug":"引擎制作","permalink":"https://mrchenlearnspace.github.io/tags/%E5%BC%95%E6%93%8E%E5%88%B6%E4%BD%9C/"}]},{"title":"全景图传输","slug":"全景图传输","date":"2022-03-20T17:38:45.000Z","updated":"2022-03-20T20:23:40.682Z","comments":true,"path":"2022/03/21/全景图传输/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/03/21/%E5%85%A8%E6%99%AF%E5%9B%BE%E4%BC%A0%E8%BE%93/","excerpt":"","text":"全景图知识储备将全景图转变为Byte数组12345Camera.main.RenderToCubemap(cm);texture2D = new Texture2D(width, hight);texture2D.SetPixels(cm.GetPixels(CubemapFace.NegativeZ));texture2D.Apply();byt = texture2D.EncodeToPNG(); 将Byte数组变成全景图1234texture2DFix.LoadImage(byt);texture2DFix.Applycm1.SetPixels(texture2DFix.GetPixels(), CubemapFace.PositiveZ);cm1.Apply(); 网络传输名字设为 I P 地址名 1.发送连接信号并在服务器创建位置 图像处理1for (int i = 1; i &lt; width + 1; i++) Array.Copy(cmmcolors, width * (width - i), ReCmmcolors, width * (i - 1), width);//上下翻转 协议处理1234567print(point.Right.Length); string str = pos.x.ToString() + &quot; &quot; + pos.y.ToString() + &quot; &quot; + pos.z.ToString() + &quot; &quot; + &quot;PX &quot;; byte[] bytstr= System.Text.Encoding.UTF8.GetBytes(str);//单独编译 byte[] sendByt = new byte[point.Right.Length+ bytstr.Length]; bytstr.CopyTo(sendByt, 0); point.Right.CopyTo(sendByt, bytstr.Length);//合并编码 123456 Texture2D = new Texture2D(width, width); byte[] image = sendByt.Skip(bytstr.Length).ToArray();//需要using System.Linq;//截取字节 print(image.Length);// Array.Reverse(image);//可以使图像旋转180度 print(Texture2D.LoadImage(image)); Texture2D.Apply();5.4.1 获取本地 I P 地址123456789101112131415public string GetLocalIp() &#123; ///获取本地的IP地址 string AddressIP = string.Empty; foreach (IPAddress _IPAddress in Dns.GetHostEntry(Dns.GetHostName()).AddressList) &#123; if (_IPAddress.AddressFamily.ToString() == &quot;InterNetwork&quot;) &#123; AddressIP = _IPAddress.ToString(); &#125; &#125; return AddressIP; &#125; 基本网络架构服务器端 Connection1234567891011121314151617181920212223242526272829303132public CloudService() &#123; msgHandle = new MsgHandle(); &#125; public int NewIndex() &#123; if (conns == null) &#123; return -1; &#125; for (int i = 0; i &lt; conns.Length; i++) &#123; if (conns[i] == null) &#123; conns[i] = new Conn(); return i; &#125; else if (conns[i].isUse == false) &#123; return i; &#125; &#125; return -1; &#125; public void ServiceStart(string host, int port) &#123; conns = new Conn[maxConn]; for (int i = 0; i &lt; maxConn; i++) &#123; conns[i] = new Conn(); &#125; Listerfd = new Socket(AddressFamily.InterNetwork, SocketType.Stream, ProtocolType.Tcp); IPAddress ipAdr = IPAddress.Parse(host); IPEndPoint ipEp = new IPEndPoint(ipAdr, port); Listerfd.Bind(ipEp); Listerfd.Listen(maxConn); Listerfd.BeginAccept(AcceptCb, null); status = true; NetCloudServerManager.instance.debug.text+=(&quot;\\n&quot;+&quot;[服务器]启动成功&quot;); &#125; Accept Cb 异步监听12345678910111213141516171819202122public void AcceptCb(IAsyncResult ar) &#123; Socket socket = Listerfd.EndAccept(ar);//要放在try外面 try &#123; //接收客户端 int index = NewIndex(); if (index &lt; 0) &#123; socket.Close(); Debug.Log(&quot;[警告]连接已满&quot;); &#125; else &#123; Conn conn = conns[index]; conn.Init(socket); string host = conn.GetAdress(); Debug.Log(&quot;客户端连接:[&quot; + host + &quot;] conn池ID:&quot; + index); conn.socket.BeginReceive(conn.readBuff, conn.buffCount, conn.BuffRemain(), SocketFlags.None, ReciveCb, conn);//接收的同时调用ReciveCb回调函数 &#125; Listerfd.BeginAccept(AcceptCb, null);//再次调用AcceprCb回调函数 &#125; catch (Exception e) &#123; Debug.Log(&quot;AccpetCb 失败:&quot; + e.Message); &#125; &#125; 出现莫名其妙的问题，等待异步需要放在 try 外面，不然会抛出 AcceptCb只能在主线程调用，要我放在awake和start中 Recive Cb异步接收123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public void ReciveCb(IAsyncResult ar) &#123; Conn conn = (Conn)ar.AsyncState;//这个AsyncState就是上面那个BeginRecive函数里面最后一个参数 lock (conn) &#123; try &#123; int count = conn.socket.EndReceive(ar);//返回接收的字节数 //没有信息就关闭 if (count &lt;= 0) &#123; Debug.Log(&quot;收到[&quot; + conn.GetAdress() + &quot;] 断开连接&quot;); conn.Close(); return; &#125; conn.buffCount += count; ProcessData(conn); //继续接收 conn.socket.BeginReceive(conn.readBuff, conn.buffCount, conn.BuffRemain(), SocketFlags.None, ReciveCb, conn); &#125; catch (Exception e) &#123; Debug.Log(&quot;Recive失败&quot; + e.Message); &#125; &#125; &#125; public void ProcessData(Conn conn) &#123; //小于字节长度 if (conn.buffCount &lt; sizeof(Int32)) &#123; return; &#125; Debug.Log(&quot;接收到了 &quot; + conn.buffCount + &quot; 个字节&quot;); Array.Copy(conn.readBuff, conn.lenByte, sizeof(Int32)); conn.msgLength = BitConverter.ToInt32(conn.lenByte, 0); //小于最小要求长度则返回表示未接收完全 if (conn.buffCount &lt; conn.msgLength + sizeof(Int32)) &#123; return; &#125; //这里接收信息有个细节，因为之前发送回来的信息又被加了一次长度，相当于要把他所有的信息接收完了 //才算接收成功，然后再把前面的sizeof(Int32)去掉，剩下的就是带长度的信息了 ProtocolByte proto = new ProtocolByte(); ProtocolByte protoStr = new ProtocolByte(); ProtocolByte protocol = proto.Decode(conn.readBuff, sizeof(Int32), conn.msgLength) as ProtocolByte; protoStr.AddString(conn.GetAdress()); protocol.bytes = protoStr.bytes.Concat(protocol.bytes).ToArray(); lock(msgHandle.msgList) &#123; msgHandle.msgList.Add(protocol); &#125; Debug.Log( protocol.GetDesc()); //清除已处理的消息 int count = conn.buffCount - conn.msgLength - sizeof(Int32); Array.Copy(conn.readBuff, sizeof(Int32) + conn.msgLength, conn.readBuff, 0, count); conn.buffCount = count; //如果还有多余信息就继续处理 if (conn.buffCount &gt; 0) &#123; ProcessData(conn); &#125; Conn类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class Conn &#123; public const int BUFFER_SIZE = 16384; public Socket socket; public bool isUse = false; public byte[] readBuff = new byte[BUFFER_SIZE]; public int buffCount = 0; public Int32 msgLength = 0; public byte[] lenByte = new byte[sizeof(Int32)]; public ProtocolByte assistProtolByte; public Conn() &#123; readBuff = new byte[BUFFER_SIZE]; assistProtolByte = new ProtocolByte(); &#125; public void Init(Socket socket) &#123; this.socket = socket; isUse = true; buffCount = 0; &#125; public int BuffRemain() &#123; return BUFFER_SIZE - buffCount; &#125; public string GetAdress() &#123; if (!isUse) &#123; return &quot;无法获取地址&quot;; &#125; return socket.RemoteEndPoint.ToString(); &#125; public void Close() &#123; if (!isUse) &#123; return; &#125; Console.WriteLine(&quot;[断开连接]&quot; + GetAdress()); socket.Close(); isUse = false; &#125; public bool SendMsg(ProtocolBase protol) &#123; string proName = protol.GetName(); ; return SendMsg(protol, proName); &#125; public bool SendMsg(ProtocolBase protol, string protolName) &#123; ProtocolByte protocolByte1 = new ProtocolByte(); protocolByte1.AddString(protolName); byte[] protolNameByte = protocolByte1.bytes; byte[] b = protol.Encode(); byte[] len1 = BitConverter.GetBytes(protolNameByte.Length + b.Length); byte[] sendByte = len1.Concat(protolNameByte).Concat(b).ToArray(); socket.Send(sendByte); Debug.Log(&quot;sendByte &quot; + sendByte.Length); Debug.Log(&quot;sendBytes &quot; + GetDesc(sendByte)); return true; &#125; public string GetDesc(byte[] bytes) &#123; string str = &quot;&quot;; if (bytes == null) return str; for (int i = 0; i &lt; bytes.Length; i++) &#123; int b = (int)bytes[i]; str += b.ToString() + &quot; &quot;; &#125; return str; &#125;&#125; 消息处理类区别于客户端消息类，处理消息时，需要在接收的消息中加入传来的消息IP地址防止找不到回溯玩家。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495public class MsgHandle &#123; public int num = NetCloudServerManager.instance.HandleMsgNum; Dictionary&lt;string, ProtocolBase&gt; oneMessager = new Dictionary&lt;string, ProtocolBase&gt;(); public List&lt;ProtocolBase&gt; msgList = new List&lt;ProtocolBase&gt;(); ProtocolByte assistProtocol; public void Running() &#123; while(msgList.Count&gt;0&amp;&amp;num&gt;0) &#123; num--; //处理长度和将协议分开 assistProtocol = msgList[0] as ProtocolByte; if(assistProtocol==null) &#123; Debug.Log(&quot;消息转化失败&quot;); lock (msgList) &#123; msgList.RemoveAt(0); &#125; return; &#125; int start = 0; string IpAddress = assistProtocol.GetString(start, ref start); string protocolName=assistProtocol.GetString(start, ref start); //int protocolNameLen=System.Text.Encoding.UTF8.GetBytes(protocolName).Length + sizeof(Int32); switch (protocolName) &#123; case &quot;ProtocolCubeTexture&quot;: ProtocolCubeTexture protocolCubeTexture = new ProtocolCubeTexture(); ProtocolCubeTexture aprotocol = protocolCubeTexture.Decode(assistProtocol.bytes, start, assistProtocol.bytes.Length) as ProtocolCubeTexture; if (aprotocol == null) break; PointMessage point = new PointMessage(); point.ResolveToPointMessage(aprotocol.Coord, aprotocol.CubemapFace, aprotocol.srcTexture); NetCloudServerManager.instance.PM.Add(point); break; case &quot;Start&quot;: StartProcessData(assistProtocol, start, IpAddress); break; &#125; lock(msgList) &#123; msgList.RemoveAt(0); &#125; //ProtocolCubeTexture protocol = msgList[0] as ProtocolCubeTexture; &#125; num = NetCloudServerManager.instance.HandleMsgNum; &#125; private void StartProcessData(ProtocolByte protocol,int start,string SendIPAddress) &#123; ProtocolStr protocolStr = new ProtocolStr(); Debug.Log(&quot;start&quot; + start + &quot; lenth&quot; + assistProtocol.bytes.Length); ProtocolStr protocolstr = protocolStr.Decode(assistProtocol.bytes, start, assistProtocol.bytes.Length-start) as ProtocolStr; NetCloudServerManager.instance.debug.text += (&quot;\\n&quot; + protocolstr.str); string[] CoordStrs = protocolstr.str.Split(&#x27;,&#x27;); float[] Coord = new float[3]; for (int i = 0; i &lt; 3; i++) Coord[i] = float.Parse(CoordStrs[i]); Camera camm = NetCloudServerManager.instance.cam; camm.transform.position = new Vector3( Coord[0], Coord[1], Coord[2]); PointMessage point = new PointMessage(); if ( camm.RenderToCubemap(point.cubemap)) &#123; int index = -1; Conn[] conns = NetCloudServerManager.cs.conns; for (int i = 0; i &lt; conns.Length; i++) &#123; if (conns[i] == null) continue; if (!conns[i].isUse) continue; if(conns[i].GetAdress()==SendIPAddress) &#123; index = i; &#125; //print(&quot; 将消息传播&quot; + conns[i].GetAdress()); &#125; if (index &lt; 0) return; int width = NetCloudServerManager.instance.width; ProtocolCubeTexture protocolCube = new ProtocolCubeTexture(); protocolCube.srcTexture = new Texture2D(width, width); for (int i = 0; i &lt; 3; i++) protocolCube.Coord[i] = int.Parse(CoordStrs[i]); for (int i=0;i&lt;6;i++) &#123; protocolCube.CubemapFace = i; protocolCube.srcTexture.SetPixels(point.cubemap.GetPixels((CubemapFace)i)); protocolCube.srcTexture.Apply(); conns[index].SendMsg(protocolCube); &#125; &#125; else &#123; NetCloudServerManager.instance.debug.text+= (&quot;\\n&quot; + protocolstr.str+&quot;渲染失败&quot;); &#125; &#125;&#125; PointMessage 点消息类1234567891011public class PointMessage &#123; public Vector3 pos; public Cubemap cubemap; static int width; public PointMessage() &#123; pos = Vector3.zero; width = NetCloudServerManager.instance.width; cubemap = new Cubemap(width, TextureFormat.RGBA32, false); &#125;&#125; 客户端Connect 类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148public class Connect &#123; // Start is called before the first frame update public static Socket socket; int BUFFER_SIZE = NetCloudClientManager.instance.BUFFER_SIZE; byte[] readBuff ; private int buffCount = 0; private Int32 msgLength = 0; private byte[] lenByte = new byte[sizeof(Int32)]; public ProtocolByte assistProtolByte; public MsgHandle msgHandle = new MsgHandle(); public enum Status &#123; None,Connect &#125;; public Status status = Status.None; public static int width = 256; public Connect() &#123; readBuff = new byte[BUFFER_SIZE]; assistProtolByte = new ProtocolByte(); &#125; public bool Connetion(string host, int port) &#123; //清理text try &#123; //Socket socket = new Socket(AddressFamily.InterNetwork, SocketType.Stream, ProtocolType.Tcp); if (host.Length == 0) &#123; host = &quot;192.168.50.142&quot;; port = 1234; &#125; socket.Connect(host, port); status = Status.Connect; NetCloudClientManager.instance.debug.text += (&quot;\\n&quot; + &quot;客户端地址&quot; + socket.LocalEndPoint.ToString()); socket.BeginReceive(readBuff, buffCount, BUFFER_SIZE - buffCount, SocketFlags.None, ReceiveCb, readBuff); return true; &#125; catch(Exception e) &#123; NetCloudClientManager.instance.debug.text += (&quot;\\n&quot; + &quot;客户端失败&quot;+e.Message ); return false; &#125; // clientText.text = &quot;客户端地址&quot; + socket.LocalEndPoint.ToString(); //Recv &#125; private void ReceiveCb(IAsyncResult ar) &#123; try &#123; //count是接收数据的大小 int count = socket.EndReceive(ar); buffCount += count; ProcessData(); socket.BeginReceive(readBuff,buffCount , BUFFER_SIZE-buffCount, SocketFlags.None, ReceiveCb, readBuff); &#125; catch (Exception e) &#123; // recvText.text += &quot;连接已断开&quot;; socket.Close(); status = Status.None; &#125; &#125; private void ProcessData() &#123; if (buffCount &lt; sizeof(Int32)) return; Array.Copy(readBuff, lenByte, sizeof(Int32)); msgLength = BitConverter.ToInt32(lenByte, 0); if (buffCount &lt; msgLength + sizeof(Int32)) return; ProtocolBase protocol = assistProtolByte.Decode(readBuff, sizeof(Int32), msgLength); lock(msgHandle.msgList) &#123; msgHandle.msgList.Add(protocol); &#125; int count = buffCount - msgLength - sizeof(Int32); Array.Copy(readBuff, sizeof(Int32) + msgLength, readBuff, 0, count); buffCount = count; if (buffCount &gt; 0) ProcessData(); &#125; public bool Close() &#123; try &#123; socket.Close(); return true; &#125; catch (Exception e) &#123; Debug.Log(&quot;关闭失败:&quot; + e.Message); return false; &#125; &#125; public bool SendMsg( ProtocolBase protol) &#123; string proName = protol.GetName(); ; return SendMsg(protol, proName); &#125; public bool SendMsg(ProtocolBase protol,string protolName) &#123; if (status != Status.Connect) &#123; Debug.Log(&quot;404 Not Found&quot;); return false; &#125; ProtocolByte protocolByte1 = new ProtocolByte(); protocolByte1.AddString(protolName); byte[] protolNameByte = protocolByte1.bytes; byte[] b = protol.Encode(); byte[] len1 = BitConverter.GetBytes(protolNameByte.Length + b.Length); byte[] sendByte = len1.Concat(protolNameByte).Concat(b).ToArray(); socket.Send(sendByte); Debug.Log(GetStr(sendByte)); return true; &#125; public string GetStr(byte[] bytes) &#123; string str = &quot;&quot;; if (bytes == null) return str; for (int i = 0; i &lt; bytes.Length; i++) &#123; int b = (int)bytes[i]; str += b.ToString() + &quot; &quot;; &#125; return str; &#125; #region 地址辅助方法 public string GetClientAddress() &#123; return socket.LocalEndPoint.ToString(); &#125; public string GetLocalIp() &#123; ///获取本地的IP地址 string AddressIP = string.Empty; foreach (IPAddress _IPAddress in Dns.GetHostEntry(Dns.GetHostName()).AddressList) &#123; if (_IPAddress.AddressFamily.ToString() == &quot;InterNetwork&quot;) &#123; AddressIP = _IPAddress.ToString(); &#125; &#125; return AddressIP; &#125; #endregion&#125; 消息处理类在处理消息队列时一定需要上lock 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556using System;using System.Collections;using System.Collections.Generic;using UnityEngine;public class MsgHandle &#123; public int num = NetCloudClientManager.instance.HandleMsgNum; public List&lt;ProtocolBase&gt; msgList = new List&lt;ProtocolBase&gt;(); ProtocolByte assistProtocol; public void Running() &#123; while(msgList.Count&gt;0&amp;&amp;num&gt;0) &#123; num--; //处理长度和将协议分开 assistProtocol = msgList[0] as ProtocolByte; if(assistProtocol==null) &#123; Debug.Log(&quot;消息转化失败&quot;); lock (msgList) &#123; msgList.RemoveAt(0); &#125; return; &#125; string protocolName=assistProtocol.GetName(); int protocolNameLen=System.Text.Encoding.UTF8.GetBytes(protocolName).Length + sizeof(Int32); switch (protocolName) &#123; case &quot;ProtocolCubeTexture&quot;: ProtocolCubeTexture protocolCubeTexture = new ProtocolCubeTexture(); ProtocolCubeTexture aprotocol = protocolCubeTexture.Decode(assistProtocol.bytes, protocolNameLen, assistProtocol.bytes.Length) as ProtocolCubeTexture; if (aprotocol == null) break; Vector3 pos = new Vector3(aprotocol.Coord[0], aprotocol.Coord[1], aprotocol.Coord[2]); PointMessage point = NetCloudClientManager.instance.PM.Find((PointMessage p) =&gt; p.pos.Equals(pos)); if(point==null) point = new PointMessage(); point.ResolveToPointMessage(aprotocol.Coord, aprotocol.CubemapFace, aprotocol.srcTexture); NetCloudClientManager.instance.PM.Add(point); break; case &quot;Start&quot;: ProtocolStr protocolStr = new ProtocolStr(); ProtocolStr protocolstr = protocolStr.Decode(assistProtocol.bytes, protocolNameLen, assistProtocol.bytes.Length) as ProtocolStr; NetCloudClientManager.instance.debug.text += (&quot;\\n&quot; + protocolstr.str); break; &#125; lock(msgList) &#123; msgList.RemoveAt(0); &#125; //ProtocolCubeTexture protocol = msgList[0] as ProtocolCubeTexture; &#125; num = NetCloudClientManager.instance.HandleMsgNum; &#125; &#125; PointMessage 点消息类区别于服务端，需要把相应的字节流变成texture，并将其贴到点消息的CubeMap上 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081using System.Collections;using System.Collections.Generic;using System.Linq;using UnityEngine;public class PointMessage &#123; public Vector3 pos; public Cubemap cubemap; static int width; bool[] FaceFlags ; int size; public PointMessage() &#123; pos = Vector3.zero; width = NetCloudClientManager.instance.width; size = 0; FaceFlags = new bool[] &#123; false, false, false, false, false, false &#125;; cubemap = new Cubemap(width, TextureFormat.RGBA32, false); &#125; public void ResolveToPointMessage(byte[] byt ) &#123; string str = System.Text.Encoding.UTF8.GetString(byt); string[] strs = str.Split(&#x27; &#x27;); pos.x = float.Parse(strs[0]); pos.y = float.Parse(strs[1]); pos.z = float.Parse(strs[2]); string CF = strs[3]; int bytCount = System.Text.Encoding.UTF8.GetBytes(pos.x.ToString() + &quot; &quot; + pos.y.ToString() + &quot; &quot; + pos.z.ToString() + &quot; &quot; + CF + &quot; &quot;).Length; byte[] image = byt.Skip(bytCount).ToArray(); switch (CF) &#123; case &quot;PX&quot;: cubemap.SetPixels(ColorToCubemap(image), CubemapFace.PositiveX); break; case &quot;NX&quot;: cubemap.SetPixels(ColorToCubemap(image), CubemapFace.NegativeX); break; case &quot;PY&quot;: cubemap.SetPixels(ColorToCubemap(image), CubemapFace.PositiveY); break; case &quot;NY&quot;: cubemap.SetPixels(ColorToCubemap(image), CubemapFace.NegativeY); break; case &quot;PZ&quot;: cubemap.SetPixels(ColorToCubemap(image), CubemapFace.PositiveZ); break; case &quot;NZ&quot;: cubemap.SetPixels(ColorToCubemap(image), CubemapFace.NegativeZ); break; &#125; cubemap.Apply(); size++; //Texture2DClient.LoadImage(image); //Texture2DClient.Apply(); &#125; public void ResolveToPointMessage(int[] Coord,int CubeMapFace,Texture2D texture) &#123; pos.x = Coord[0]; pos.y = Coord[1]; pos.z = Coord[2]; switch (CubeMapFace) &#123; case 0: cubemap.SetPixels( texture.GetPixels(), CubemapFace.PositiveX); break; case 1: cubemap.SetPixels( texture.GetPixels(), CubemapFace.NegativeX); break; case 2: cubemap.SetPixels( texture.GetPixels(), CubemapFace.PositiveY); break; case 3: cubemap.SetPixels( texture.GetPixels(), CubemapFace.NegativeY); break; case 4: cubemap.SetPixels( texture.GetPixels(), CubemapFace.PositiveZ); break; case 5: cubemap.SetPixels( texture.GetPixels(), CubemapFace.NegativeZ); break; &#125; Debug.Log(&quot;cubeface &quot; + CubeMapFace); FaceFlags[CubeMapFace] = true; cubemap.Apply(); &#125; Color[] ColorToCubemap(byte[] byt) &#123; Texture2D textureTest = new Texture2D(width, width); textureTest.LoadImage(byt); textureTest.Apply(); return textureTest.GetPixels() ; &#125; public int GetSize() &#123; size = 0; for(int i=0; i&lt;FaceFlags.Length;i++) &#123; if (FaceFlags[i]) size++; &#125; return size; &#125; public void aa() &#123; Debug.Log(&quot;aaaaa&quot;); &#125;&#125; 协议个人理解：字节流协议和字符串流协议算是中间层协议，其他协议类可以聚合两个中间层协议进行编写。 协议基类123456789101112131415161718192021using System.Collections;using System.Collections.Generic;using UnityEngine;public class ProtocolBase &#123; //解码器 public virtual ProtocolBase Decode(byte[] readBuff,int start,int length) &#123; return new ProtocolBase(); &#125; //编码器 public virtual byte[] Encode() &#123; return new byte[] &#123; &#125;; &#125; public virtual string GetName() &#123; return &quot;Base&quot;; &#125; public virtual string GetDesc() &#123; return &quot;&quot;; &#125; &#125; 字节流协议123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103using System;using System.Collections;using System.Collections.Generic;using UnityEngine;using System.Linq;public class ProtocolByte : ProtocolBase &#123; public byte[] bytes; public override ProtocolBase Decode(byte[] readBuff, int start, int length) &#123; ProtocolByte proByte = new ProtocolByte(); proByte.bytes = new byte[length]; Array.Copy(readBuff, start, proByte.bytes, 0, length); return (ProtocolBase)proByte; &#125; public override byte[] Encode() &#123; return bytes; &#125; public override string GetName() &#123; return GetString(0); &#125; public override string GetDesc() &#123; string str = &quot;&quot;; if (bytes == null) return str; for(int i=0;i&lt;bytes.Length;i++) &#123; int b = (int)bytes[i]; str += b.ToString() + &quot; &quot;; &#125; return str; &#125; #region 字节辅助流 public void AddString(string str) &#123; Int32 len = str.Length; byte[] lenBytes = BitConverter.GetBytes(len); byte[] strBytes = System.Text.Encoding.UTF8.GetBytes(str); if (bytes == null) bytes = lenBytes.Concat(strBytes).ToArray(); else bytes = bytes.Concat(lenBytes).Concat(strBytes).ToArray(); &#125; public string GetString(int start, ref int end) &#123; if (bytes == null) return &quot;&quot;; if (bytes.Length &lt; start + sizeof(Int32)) return &quot;&quot;; Int32 strLen = BitConverter.ToInt32(bytes, start); if (bytes.Length &lt; start + sizeof(Int32) + strLen) return &quot;&quot;; string str = System.Text.Encoding.UTF8.GetString(bytes, start + sizeof(Int32) , strLen); end = start + sizeof(Int32) + strLen; return str; &#125; public string GetString(int start) &#123; int end = 0; return GetString(start,ref end); &#125; public void AddInt(int num) &#123; byte[] numBytes = BitConverter.GetBytes(num); if (bytes == null) bytes = numBytes; else bytes = bytes.Concat(numBytes).ToArray(); &#125; public int GetInt(int start,ref int end) &#123; if (bytes == null) return 0; if (bytes.Length &lt; start + sizeof(Int32)) return 0; end = start + sizeof(Int32); return BitConverter.ToInt32(bytes, start); &#125;public int GetInt(int start) &#123; int end = 0; return GetInt(start,ref end); &#125; public void AddFloat(float num) &#123; byte[] numBytes = BitConverter.GetBytes(num); if (bytes == null) bytes = numBytes; else bytes = bytes.Concat(numBytes).ToArray(); &#125; public float GetFloat(int start, ref int end) &#123; if (bytes == null) return 0; if (bytes.Length &lt; start + sizeof(float)) return 0; end = start + sizeof(float); return BitConverter.ToSingle(bytes, start); &#125; public float GetFloat(int start) &#123; int end = 0; return GetFloat(start, ref end); &#125; #endregion&#125; 字符串协议1234567891011121314151617181920212223using System.Collections;using System.Collections.Generic;using UnityEngine;public class ProtocolStr : ProtocolBase &#123; public string str; public override ProtocolBase Decode(byte[] readBuff, int start, int length) &#123; ProtocolStr proStr = new ProtocolStr(); proStr.str = System.Text.Encoding.UTF8.GetString(readBuff, start, length); return (ProtocolBase) proStr; &#125; public override byte[] Encode() &#123; return System.Text.Encoding.UTF8.GetBytes(str); &#125; public override string GetName() &#123; if (str.Length == 0) return &quot;&quot;; return str.Split(&#x27;,&#x27;)[0]; &#125; public override string GetDesc() &#123; return str; &#125;&#125; ProtocolCubeTexture 协议1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071using System.Collections;using System.Collections.Generic;using UnityEngine;using System.Linq;using System;public class ProtocolCubeTexture : ProtocolBase &#123; public int width = NetCloudClientManager.instance.width; public int[] Coord = new int[] &#123; 0, 0, 0 &#125;; public Texture2D srcTexture; public int CubemapFace = -1; //解码器 public override ProtocolBase Decode(byte[] readBuff, int start, int length) &#123; ProtocolCubeTexture proTexture = new ProtocolCubeTexture(); ProtocolByte proByte = new ProtocolByte(); proByte.bytes = readBuff; for(int i=0;i&lt;3;i++) &#123; proTexture.Coord[i] = proByte.GetInt(start, ref start); &#125; proTexture.CubemapFace = proByte.GetInt(start, ref start); //图片解析 int srcStart = start; int srcLength = readBuff.Length-start; byte[] srcbyte = new byte[srcLength]; Array.Copy(readBuff, srcStart, srcbyte, 0, srcLength); proTexture.srcTexture = new Texture2D(width,width); proTexture.srcTexture.LoadImage(srcbyte); proTexture.srcTexture.Apply(); //NetCloudClientManager.instance.tex[proTexture.CubemapFace] = proTexture.srcTexture; return (ProtocolBase) proTexture; &#125; //编码器 public override byte[] Encode() &#123; //立方体面编译 ProtocolByte proByte = new ProtocolByte(); for(int i=0;i&lt;3;i++) &#123; proByte.AddInt(Coord[i]); &#125; proByte.AddInt(CubemapFace); byte[] cubeFaceBytes = proByte.Encode(); //图片编译 if (srcTexture == null) return null; byte[] srcTextureByte = srcTexture.EncodeToJPG(); //byte[] lenByte = BitConverter.GetBytes(srcTextureByte.Length + cubeFaceBytes.Length); byte[] byt = cubeFaceBytes.Concat(srcTextureByte).ToArray(); return byt; &#125; public override string GetName() &#123; return &quot;ProtocolCubeTexture&quot;; &#125; public override string GetDesc() &#123; string str = &quot;&quot;; byte[] srcTextureByte = srcTexture.EncodeToJPG(); if (srcTextureByte == null) return str; for (int i = 0; i &lt; srcTextureByte.Length; i++) &#123; int b = (int)srcTextureByte[i]; str += b.ToString() + &quot; &quot;; &#125; return str; &#125;&#125;","categories":[{"name":"Unity","slug":"Unity","permalink":"https://mrchenlearnspace.github.io/categories/Unity/"}],"tags":[{"name":"网络","slug":"网络","permalink":"https://mrchenlearnspace.github.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"全景图","slug":"全景图","permalink":"https://mrchenlearnspace.github.io/tags/%E5%85%A8%E6%99%AF%E5%9B%BE/"}]},{"title":"视觉计算观后感","slug":"视觉计算观后感","date":"2022-03-13T08:38:45.000Z","updated":"2022-11-14T14:22:15.536Z","comments":true,"path":"2022/03/13/视觉计算观后感/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/03/13/%E8%A7%86%E8%A7%89%E8%AE%A1%E7%AE%97%E8%A7%82%E5%90%8E%E6%84%9F/","excerpt":"","text":"数据采样从样本数据提取数据，等距提取就是均匀采样，不等距就是非均匀采样。 噪声椒盐噪点可以用中值滤波器消除，有条纹状的噪声可以用陷波滤波器，比较细致模糊的噪点可以用低通滤波器 卷积线性滤波器全通没有消除和阻止任何一个频率。作用未知。 低通使频率越来越宽，可以让图片变得模糊和达到消除噪点的作用 盒式滤波器使用全为1的卷积核。 高斯滤波器特定的权重，离像素点越远权重越小 下图为高斯函数的3维图示： 0.05 0.25 0.40 0.25 0.05权值 降低频率采样n层：1 x 1 ··· n-1层：pow(2,n-1) x pow(2,n-1) n层：pow(2,n) x pow(2,n) 高斯金字塔 n-1层的一个网格对应相应的n层的4个网格 卷积细节 将滤波器与图像进行卷积时，要每个像素对齐非常重要，每个卷积的结果要单独保存，否则会影响之后的卷积结果 运算时先转化为浮点数再进行滤波最后滤波取整 如果颜色超过0，255设定最大值和最小值s 高通留下高频去除低频，能得到图形边缘特征。 如核为 -1&#x2F;3 2&#x2F;3 -1&#x2F;3的卷积核。 带通指留下低频和高频之间的信号。 非线性滤波器中值滤波器去核范围的中值代替像素，去椒盐噪点的，还可以制作腐蚀或膨胀效果。 几何变换平移旋转放缩opengl里面有 就不看了 透视变换裁剪距阵的推导取用这个坐标系，所以w是0 0 -1 0$$∠theta&#x3D;fov&#x2F;2 ,A&#x3D; N * tan (theta),B&#x3D; F * tan (theta) \\ A’&#x3D;N&#x3D;ACot(theta),B’&#x3D;F&#x3D;BCot(theta)$$所以Y轴是 0 cot(theta) 0 0。ASP是宽高比 123456$$C=A*ASP \\\\D=B*ASP \\\\C&#x27;=N=C*Cot(theta) / ASP \\\\ D&#x27;=F=D*Cot(theta) / ASP$$ 所以x是&#x3D;Cot(theta)&#x2F;ASP 0 0 0。 假设矩阵是线性的$$f(-N)&#x3D;-N,f(-F)&#x3D;F代入方程y&#x3D;sx+o$$解方程组$$s&#x3D;(f+n)&#x2F;(n-f),o&#x3D;2fn&#x2F;(n-f)$$z是0 0 s o； 得透视矩阵如下","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://mrchenlearnspace.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"}],"tags":[{"name":"计算机视觉","slug":"计算机视觉","permalink":"https://mrchenlearnspace.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"}]},{"title":"特效篇火焰","slug":"特效篇火焰","date":"2022-03-01T08:38:45.000Z","updated":"2022-11-14T14:22:20.462Z","comments":true,"path":"2022/03/01/特效篇火焰/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/03/01/%E7%89%B9%E6%95%88%E7%AF%87%E7%81%AB%E7%84%B0/","excerpt":"","text":"火焰制作原理利用裁剪方程，将噪点图进行向上流动达到火焰往上升的效果，用一张渐变图和噪点图相乘把上半部分进行裁剪，将颜色的HDR效果打开，现在得到初步的火焰加一点点细节，让火的边缘柔和一点。让噪声图减去一个变量，并钳制在0到1之间，调大变量会使边缘柔和化，接下来是让火焰外焰和内焰效果 透明度 噪点值 噪点图往上移动取R通道 渐变值和内焰边界 火焰边缘柔和 当Softness变大边缘柔和，注意必须要clamp函数 外焰和内焰 火焰的形状 最后","categories":[{"name":"游戏","slug":"游戏","permalink":"https://mrchenlearnspace.github.io/categories/%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"Shader","slug":"Shader","permalink":"https://mrchenlearnspace.github.io/tags/Shader/"}]},{"title":"后处理技术（下）","slug":"后处理技术3","date":"2022-02-24T08:38:45.000Z","updated":"2022-11-14T14:21:43.803Z","comments":true,"path":"2022/02/24/后处理技术3/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/02/24/%E5%90%8E%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF3/","excerpt":"","text":"HDRBloom（光晕）取亮光部分，进行降采样，在升采样的过程中，叠加降采样对应尺寸的图片，合并效果图和源图片 初处理如果放入的是HDR图片，可以在shader里面加float4 _MainTex_HDR; col.rgb &#x3D; DecodeHDR(col,_MainTex_HDR);进行解码。 取光亮部分先进行均值模糊，取亮色部分。 1234567float intensity = Mathf.Exp(_Intensity / 10.0f * 0.693f) - 1.0f;mat.SetFloat(&quot;_Threshold&quot;, _Threshold);mat.SetFloat(&quot;_Intensity&quot;, intensity);//取亮色Graphics.Blit(source, RT_Down[0], mat, 0); 1234567891011121314half4 frag_PreFilter(v2f_img i) : SV_Target//0&#123; half4 col = tex2D(_MainTex, i.uv); half4 d=_MainTex_TexelSize.xyxy*half4(1,1,-1,-1); col.rgb+=tex2D(_MainTex,i.uv+d.xy).rgb; col.rgb+=tex2D(_MainTex,i.uv+d.zy).rgb; col.rgb+=tex2D(_MainTex,i.uv+d.xw).rgb; col.rgb+=tex2D(_MainTex,i.uv+d.zw).rgb; col.rgb*=0.25; float br = max(max(col.r,col.g),col.b); br = max(0,(br - _Threshold))/max(0.00001,br); col.rgb*=br; return col;&#125; 降采样用双重盒状模糊的降采样方式 12345//降采样for(int i=0;i&lt;_Iteration;i++) &#123;//0-i-1 Graphics.Blit(RT_Down[i], RT_Down[i + 1], mat, 1); // print(&quot;downcode &quot; + i );&#125; 1234567891011half4 frag_DownsampleBox(v2f_img i) : SV_Target//1&#123; half4 col = tex2D(_MainTex, i.uv); half4 d=_MainTex_TexelSize.xyxy*half4(1,1,-1,-1); col.rgb+=tex2D(_MainTex,i.uv+d.xy).rgb; col.rgb+=tex2D(_MainTex,i.uv+d.zy).rgb; col.rgb+=tex2D(_MainTex,i.uv+d.xw).rgb; col.rgb+=tex2D(_MainTex,i.uv+d.zw).rgb; col.rgb*=0.25; return col;&#125; 升采样升采样过程中加同尺寸的降采样贴图 1234567Graphics.Blit(RT_Down[_Iteration], RT_Up[_Iteration]);for(int i=_Iteration;i&gt;0;i--) &#123; mat.SetTexture(&quot;_BloomTex&quot;, RT_Down[i-1]); Graphics.Blit(RT_Up[i], RT_Up[i-1], mat, 2); //print(&quot;upcode &quot; + i);&#125; 123456789101112half4 frag_UpsampleBox(v2f_img i) : SV_Target//2&#123; half4 col = tex2D(_MainTex, i.uv); half4 d=_MainTex_TexelSize.xyxy*half4(1,1,-1,-1); col.rgb+=tex2D(_MainTex,i.uv+d.xy).rgb; col.rgb+=tex2D(_MainTex,i.uv+d.zy).rgb; col.rgb+=tex2D(_MainTex,i.uv+d.xw).rgb; col.rgb+=tex2D(_MainTex,i.uv+d.zw).rgb; col.rgb*=0.25; half4 color2 = tex2D(_BloomTex, i.uv); return col + color2;&#125; 合并把升采样的最后一张图和原图合并,和释放贴图。 12345678910mat.SetTexture(&quot;_BloomTex&quot;, RT_Up[0]);Graphics.Blit(source, destination, mat, 3);//Release//RenderTexture.ReleaseTemporary(RT1);for (int i = 0; i &lt; _Iteration+1; i++) &#123; // print(&quot;Release &quot; + i); RenderTexture.ReleaseTemporary(RT_Down[i]); RenderTexture.ReleaseTemporary(RT_Up[i]);&#125; 1234567half4 frag_Combine(v2f_img i) : SV_Target//3&#123; half4 col = tex2D(_MainTex, i.uv); half3 color1 = tex2D(_BloomTex, i.uv).rgb; col.rgb+= color1.rgb*_Intensity; return col ;&#125; 最后小瑕疵在光晕的周围还有点不自然。可用如下解决方案。 12345678910111213141516171819float3 ACES_Tonemapping(float3 x)&#123; float a = 2.51f; float b = 0.03f; float c = 2.43f; float d = 0.59f; float e = 0.14f; float3 encode_color = saturate((x*(a*x + b)) / (x*(c*x + d) + e)); return encode_color;&#125;;half4 frag (v2f_img i) : SV_Target&#123; half4 col = tex2D(_MainTex, i.uv); half3 linear_color = pow(col.rgb, 2.2); half3 encode_color = ACES_Tonemapping(linear_color); half3 final_color = pow(encode_color, 1.0 / 2.2); return float4(final_color,col.a);&#125; 后处理的顺序 调整顺序：Bloom-&gt;Vignette-&gt;Tonemapping-&gt;ColorGrading","categories":[{"name":"游戏","slug":"游戏","permalink":"https://mrchenlearnspace.github.io/categories/%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"Shader","slug":"Shader","permalink":"https://mrchenlearnspace.github.io/tags/Shader/"}]},{"title":"后处理技术（中）","slug":"后处理技术2","date":"2022-02-22T08:38:45.000Z","updated":"2022-11-14T14:21:38.589Z","comments":true,"path":"2022/02/22/后处理技术2/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/02/22/%E5%90%8E%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF2/","excerpt":"","text":"模糊处理本文章参考毛星云大佬的文章学习，十分推荐看大佬的原文 降采样是常见的优化性能的方法减少中间贴图的尺寸大小 产生的中间贴图一定要记得释放内存，否则造成内存泄漏 在for循环的中间贴图也要记得释放内存 课程的4种常用的模糊算法盒状模糊或均值模糊（Box Blur）最简单的模糊方式，取一个2*2的卷积核，四个数权重都为0.25，取一个像素的四角的像素叠加乘0.25 （-1，-1）（1，-1）（-1，1）（1，1）四个点位叠加除4； 当然卷积核的值可自己调 代码BoxBlur.cs1234567891011121314151617181920212223242526272829303132333435363738394041424344454647using System.Collections;using System.Collections.Generic;using UnityEngine;[ExecuteInEditMode()]public class BoxBlur : MonoBehaviour &#123; public Material material; [Range(0, 10)] public int _Iteration = 4; [Range(0, 15)] public float _BlurRadius = 5.0f; [Range(1, 10)] public float _DownSample = 2.0f; void Start () &#123; if (material == null || SystemInfo.supportsImageEffects == false || material.shader == null || material.shader.isSupported == false) &#123; enabled = false; return; &#125; &#125; void OnRenderImage(RenderTexture source, RenderTexture destination) &#123; int width = (int)(source.width / _DownSample); int height = (int)(source.height / _DownSample); RenderTexture RT1 = RenderTexture.GetTemporary(width,height); RenderTexture RT2 = RenderTexture.GetTemporary(width, height); Graphics.Blit(source, RT1); material.SetVector(&quot;_BlurOffset&quot;, new Vector4(_BlurRadius / source.width, _BlurRadius / source.height, 0,0)); for (int i = 0; i &lt; _Iteration; i++) &#123; Graphics.Blit(RT1, RT2, material, 0); Graphics.Blit(RT2, RT1, material, 0); &#125; Graphics.Blit(RT1, destination); //release RenderTexture.ReleaseTemporary(RT1); RenderTexture.ReleaseTemporary(RT2); &#125;&#125; BoxBlur.shader123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172Shader &quot;Hidden/BoxBlur&quot;&#123; CGINCLUDE #include &quot;UnityCG.cginc&quot; sampler2D _MainTex; float4 _BlurOffset; half4 frag_BoxFilter_4Tap(v2f_img i) : SV_Target &#123; half4 d = _BlurOffset.xyxy * half4(-1,-1,1,1); half4 s = 0; s += tex2D(_MainTex, i.uv + d.xy); s += tex2D(_MainTex, i.uv + d.zy); s += tex2D(_MainTex, i.uv + d.xw); s += tex2D(_MainTex, i.uv + d.zw); s *= 0.25; return s; &#125; half4 frag_BoxFilter_9Tap(v2f_img i) : SV_Target &#123; //half4 d = _BlurOffset.xyxy * half4(-1,1,0,0); half4 d = _BlurOffset.xyxy * half4(-1, -1, 1, 1); half4 s = 0; s = tex2D(_MainTex, i.uv); s += tex2D(_MainTex, i.uv + d.xy); s += tex2D(_MainTex, i.uv + d.zy); s += tex2D(_MainTex, i.uv + d.xw); s += tex2D(_MainTex, i.uv + d.zw); s += tex2D(_MainTex, i.uv + half2(0.0, d.w)); // 0 1 s += tex2D(_MainTex, i.uv + half2(0.0, d.y)); // 0 -1 s += tex2D(_MainTex, i.uv + half2(d.z,0.0)); // 1 0 s += tex2D(_MainTex, i.uv + half2(d.x, 0.0)); // -1 0 s = s/ 9.0; return s; &#125; ENDCG Properties &#123; _MainTex (&quot;Texture&quot;, 2D) = &quot;white&quot; &#123;&#125; _BlurOffset(&quot;BlurOffset&quot;,Float) = 1 &#125; SubShader &#123; // No culling or depth Cull Off ZWrite Off ZTest Always //0pass 4tap Pass &#123; CGPROGRAM #pragma vertex vert_img #pragma fragment frag_BoxFilter_4Tap ENDCG &#125; //1pass 9tap Pass &#123; CGPROGRAM #pragma vertex vert_img #pragma fragment frag_BoxFilter_9Tap ENDCG &#125; &#125;&#125; 高斯模糊（Gaussian Blur）特定的权重，离像素点越远权重越小 下图为高斯函数的3维图示： 0.05 0.25 0.40 0.25 0.05权值 和盒状模糊差不多，效果会好一点 代码GaussianBlur.cs1234567891011121314151617181920212223242526272829303132333435363738394041424344454647using System.Collections;using System.Collections.Generic;using UnityEngine;[ExecuteInEditMode()]public class GaussianBlur : MonoBehaviour &#123; public Material material; [Range(0, 10)] public int _Iteration = 4; [Range(0, 15)] public float _BlurRadius = 5.0f; [Range(1, 10)] public float _DownSample = 2.0f; void Start () &#123; if (material == null || SystemInfo.supportsImageEffects == false || material.shader == null || material.shader.isSupported == false) &#123; enabled = false; return; &#125; &#125; void OnRenderImage(RenderTexture source, RenderTexture destination) &#123; int width = (int)(source.width / _DownSample); int height = (int)(source.height / _DownSample); RenderTexture RT1 = RenderTexture.GetTemporary(width,height); RenderTexture RT2 = RenderTexture.GetTemporary(width, height); Graphics.Blit(source, RT1); material.SetVector(&quot;_BlurOffset&quot;, new Vector4(_BlurRadius / source.width, _BlurRadius / source.height, 0,0)); for (int i = 0; i &lt; _Iteration; i++) &#123; Graphics.Blit(RT1, RT2, material, 0); //水平方向 Graphics.Blit(RT2, RT1, material, 1); //垂直方向 &#125; Graphics.Blit(RT1, destination); //release RenderTexture.ReleaseTemporary(RT1); RenderTexture.ReleaseTemporary(RT2); &#125;&#125; GaussianBlur.shader123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172Shader &quot;Hidden/GaussianBlur&quot;&#123; CGINCLUDE #include &quot;UnityCG.cginc&quot; sampler2D _MainTex; float4 _BlurOffset; half4 frag_HorizontalBlur(v2f_img i) : SV_Target &#123; half2 uv1 = i.uv + _BlurOffset.xy * half2(1, 0) * -2.0; half2 uv2 = i.uv + _BlurOffset.xy * half2(1, 0) * -1.0; half2 uv3 = i.uv; half2 uv4 = i.uv + _BlurOffset.xy * half2(1, 0) * 1.0; half2 uv5 = i.uv + _BlurOffset.xy * half2(1, 0) * 2.0; half4 s = 0; s += tex2D(_MainTex, uv1) * 0.05; s += tex2D(_MainTex, uv2) * 0.25; s += tex2D(_MainTex, uv3) * 0.40; s += tex2D(_MainTex, uv4) * 0.25; s += tex2D(_MainTex, uv5) * 0.05; return s; &#125; half4 frag_VerticalBlur(v2f_img i) : SV_Target &#123; half2 uv1 = i.uv + _BlurOffset.xy * half2(0, 1) * -2.0; half2 uv2 = i.uv + _BlurOffset.xy * half2(0, 1) * -1.0; half2 uv3 = i.uv; half2 uv4 = i.uv + _BlurOffset.xy * half2(0, 1) * 1.0; half2 uv5 = i.uv + _BlurOffset.xy * half2(0, 1) * 2.0; half4 s = 0; s += tex2D(_MainTex, uv1) * 0.05; s += tex2D(_MainTex, uv2) * 0.25; s += tex2D(_MainTex, uv3) * 0.40; s += tex2D(_MainTex, uv4) * 0.25; s += tex2D(_MainTex, uv5) * 0.05; return s; &#125; ENDCG Properties &#123; _MainTex (&quot;Texture&quot;, 2D) = &quot;white&quot; &#123;&#125; _BlurOffset(&quot;BlurOffset&quot;,Float) = 1 &#125; SubShader &#123; // No culling or depth Cull Off ZWrite Off ZTest Always //0 Pass &#123; CGPROGRAM #pragma vertex vert_img #pragma fragment frag_HorizontalBlur ENDCG &#125; //1 Pass &#123; CGPROGRAM #pragma vertex vert_img #pragma fragment frag_VerticalBlur ENDCG &#125; &#125;&#125; 双重模糊双重的核心思想是先降采样，然后升采样。 相较于Kawase Blur在两个大小相等的纹理之间进行乒乓blit的的思路，Dual Kawase Blur的核心思路在于blit过程中进行降采样和升采样,即对RT进行了降采样以及升采样。如下图所示： 双重 Kawase 模糊（Dual Kawase Blur）双重 Kawase 模糊和双重盒状模糊模糊是最常用的，前者常用于移动端，后者都行，两个的性能和质量都优于之前两种算法 Kawase模糊Kawase Blur的思路是对距离当前像素越来越远的地方对四个角进行采样 所以中间的权重为4&#x2F;8，其余四角为1&#x2F;8； 单独的Kawase算法性能太差了，淘汰。 Dual Kawase BlurDual Kawase Blur，简称Dual Blur，是SIGGRAPH 2015上ARM团队提出的一种衍生自Kawase Blur的模糊算法。其由两种不同的Blur Kernel构成，如下图所示。 这个贴图怕是只有我看的懂了，图一的1图代表红色的框框，第二个代表整个框框 代码DualKawaseBlur.cs1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677using System;using UnityEngine;using System.Collections.Generic;[RequireComponent(typeof(Camera))][ExecuteInEditMode]public class DualKawaseBlur : MonoBehaviour&#123; public Material material; [Range(0,15)] public float _BlurRadius = 5.0f; [Range(0, 10)] public int _Iteration = 4; [Range(1, 10)] public float _DownSample = 2.0f; List&lt;RenderTexture&gt; _tempRTList = new List&lt;RenderTexture&gt;(); void Start() &#123; if (!SystemInfo.supportsImageEffects || null == material || null == material.shader || !material.shader.isSupported) &#123; enabled = false; return; &#125; &#125; void OnRenderImage(RenderTexture source, RenderTexture destination) &#123; int RTWidth = (int)(source.width / _DownSample); int RTHeight = (int)(source.height / _DownSample); RenderTexture RT1 = RenderTexture.GetTemporary(RTWidth, RTHeight, 0); RenderTexture RT2 = null; material.SetFloat(&quot;_Offset&quot;, _BlurRadius); Graphics.Blit(source, RT1, material, 0);//降采样 for (int i = 0; i &lt; _Iteration; i++) &#123; RenderTexture.ReleaseTemporary(RT2); RTWidth = RTWidth / 2; RTHeight = RTHeight / 2; RT2 = RenderTexture.GetTemporary(RTWidth, RTHeight); Graphics.Blit(RT1, RT2, material, 0); RTWidth = RTWidth / 2; RTHeight = RTHeight / 2; RenderTexture.ReleaseTemporary(RT1); RT1 = RenderTexture.GetTemporary(RTWidth, RTHeight); Graphics.Blit(RT2, RT1, material, 0); &#125;//升采样 for (int i = 0; i &lt; _Iteration; i++) &#123; RenderTexture.ReleaseTemporary(RT2); RTWidth = RTWidth * 2; RTHeight = RTHeight * 2; RT2 = RenderTexture.GetTemporary(RTWidth, RTHeight); Graphics.Blit(RT1, RT2, material, 1); RTWidth = RTWidth * 2; RTHeight = RTHeight * 2; RenderTexture.ReleaseTemporary(RT1); RT1 = RenderTexture.GetTemporary(RTWidth, RTHeight); Graphics.Blit(RT2, RT1, material, 1); &#125; Graphics.Blit(RT1, destination, material, 1); // release RenderTexture.ReleaseTemporary(RT1); RenderTexture.ReleaseTemporary(RT2); &#125;&#125; DualKawaseBlur.shader123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119Shader &quot;Hidden/DualKawaseBlur&quot;&#123; CGINCLUDE #include &quot;UnityCG.cginc&quot; uniform sampler2D _MainTex; uniform float4 _MainTex_TexelSize; uniform half _Offset; struct v2f_DownSample &#123; float4 pos: SV_POSITION; float2 uv: TEXCOORD1; float4 uv01: TEXCOORD2; float4 uv23: TEXCOORD3; &#125;; struct v2f_UpSample &#123; float4 pos: SV_POSITION; float4 uv01: TEXCOORD1; float4 uv23: TEXCOORD2; float4 uv45: TEXCOORD3; float4 uv67: TEXCOORD4; &#125;; v2f_DownSample Vert_DownSample(appdata_img v) &#123; v2f_DownSample o; o.pos = UnityObjectToClipPos(v.vertex); _MainTex_TexelSize = 0.5 * _MainTex_TexelSize; float2 uv = v.texcoord; o.uv = uv; o.uv01.xy = uv - _MainTex_TexelSize * float2(1 + _Offset, 1 + _Offset);//top right o.uv01.zw = uv + _MainTex_TexelSize * float2(1 + _Offset, 1 + _Offset);//bottom left o.uv23.xy = uv - float2(_MainTex_TexelSize.x, -_MainTex_TexelSize.y) * float2(1 + _Offset, 1 + _Offset);//top left o.uv23.zw = uv + float2(_MainTex_TexelSize.x, -_MainTex_TexelSize.y) * float2(1 + _Offset, 1 + _Offset);//bottom right return o; &#125; half4 Frag_DownSample(v2f_DownSample i): SV_Target &#123; half4 sum = tex2D(_MainTex, i.uv) * 4; sum += tex2D(_MainTex, i.uv01.xy); sum += tex2D(_MainTex, i.uv01.zw); sum += tex2D(_MainTex, i.uv23.xy); sum += tex2D(_MainTex, i.uv23.zw); return sum * 0.125; &#125; v2f_UpSample Vert_UpSample(appdata_img v) &#123; v2f_UpSample o; o.pos = UnityObjectToClipPos(v.vertex); float2 uv = v.texcoord; _MainTex_TexelSize = 0.5 * _MainTex_TexelSize; _Offset = float2(1 + _Offset, 1 + _Offset); o.uv01.xy = uv + float2(-_MainTex_TexelSize.x * 2, 0) * _Offset;//-2,0 o.uv01.zw = uv + float2(-_MainTex_TexelSize.x, _MainTex_TexelSize.y) * _Offset;//-1 1 o.uv23.xy = uv + float2(0, _MainTex_TexelSize.y * 2) * _Offset;//0 2 o.uv23.zw = uv + _MainTex_TexelSize * _Offset;//1 1 o.uv45.xy = uv + float2(_MainTex_TexelSize.x * 2, 0) * _Offset;//2 0 o.uv45.zw = uv + float2(_MainTex_TexelSize.x, -_MainTex_TexelSize.y) * _Offset;//1 -1 o.uv67.xy = uv + float2(0, -_MainTex_TexelSize.y * 2) * _Offset;//0 -2 o.uv67.zw = uv - _MainTex_TexelSize * _Offset;// -1 -1 return o; &#125; half4 Frag_UpSample(v2f_UpSample i): SV_Target &#123; half4 sum = 0; sum += tex2D(_MainTex, i.uv01.xy); sum += tex2D(_MainTex, i.uv01.zw) * 2; sum += tex2D(_MainTex, i.uv23.xy); sum += tex2D(_MainTex, i.uv23.zw) * 2; sum += tex2D(_MainTex, i.uv45.xy); sum += tex2D(_MainTex, i.uv45.zw) * 2; sum += tex2D(_MainTex, i.uv67.xy); sum += tex2D(_MainTex, i.uv67.zw) * 2; return sum * 0.0833; &#125; ENDCG Properties &#123; _MainTex(&quot;&quot;, 2D) = &quot;white&quot; &#123;&#125; &#125; SubShader &#123; Cull Off ZWrite Off ZTest Always Pass &#123; CGPROGRAM #pragma vertex Vert_DownSample #pragma fragment Frag_DownSample ENDCG &#125; Pass &#123; CGPROGRAM #pragma vertex Vert_UpSample #pragma fragment Frag_UpSample ENDCG &#125; &#125;&#125; 双重盒状模糊（Dual Box Blur）对原来的Box进行双重采样就行，最常用的算法。 代码DualBoxBlur.cs123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172using System.Collections;using System.Collections.Generic;using UnityEngine;[ExecuteInEditMode()]public class DualBoxBlur : MonoBehaviour &#123; public Material material; [Range(0, 10)] public int _Iteration = 4; [Range(0, 15)] public float _BlurRadius = 5.0f; [Range(1, 10)] public float _DownSample = 2.0f; void Start () &#123; if (material == null || SystemInfo.supportsImageEffects == false || material.shader == null || material.shader.isSupported == false) &#123; enabled = false; return; &#125; &#125; void OnRenderImage(RenderTexture source, RenderTexture destination) &#123; int width = (int)(source.width / _DownSample); int height = (int)(source.height / _DownSample); RenderTexture RT1 = RenderTexture.GetTemporary(width,height); RenderTexture RT2 = RenderTexture.GetTemporary(width, height); Graphics.Blit(source, RT1); material.SetVector(&quot;_BlurOffset&quot;, new Vector4(_BlurRadius / source.width, _BlurRadius / source.height, 0,0)); //降采样 for (int i = 0; i &lt; _Iteration; i++) &#123; RenderTexture.ReleaseTemporary(RT2); width = width / 2; height = height / 2; RT2 = RenderTexture.GetTemporary(width, height); Graphics.Blit(RT1, RT2, material, 0); RenderTexture.ReleaseTemporary(RT1); width = width / 2; height = height / 2; RT1 = RenderTexture.GetTemporary(width, height); Graphics.Blit(RT2, RT1, material, 0); &#125; //升采样 for (int i = 0; i &lt; _Iteration; i++) &#123; RenderTexture.ReleaseTemporary(RT2); width = width * 2; height = height * 2; RT2 = RenderTexture.GetTemporary(width, height); Graphics.Blit(RT1, RT2, material, 0); RenderTexture.ReleaseTemporary(RT1); width = width * 2; height = height * 2; RT1 = RenderTexture.GetTemporary(width, height); Graphics.Blit(RT2, RT1, material, 0); &#125; Graphics.Blit(RT1, destination); //release RenderTexture.ReleaseTemporary(RT1); RenderTexture.ReleaseTemporary(RT2); &#125;&#125; 就之前的BoxBlur.shader。 其余算法可以参考毛星云大佬的其他算法。","categories":[{"name":"游戏","slug":"游戏","permalink":"https://mrchenlearnspace.github.io/categories/%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"Shader","slug":"Shader","permalink":"https://mrchenlearnspace.github.io/tags/Shader/"}]},{"title":"后处理技术（上）","slug":"后处理技术1","date":"2022-02-20T15:38:45.000Z","updated":"2022-11-14T14:21:32.647Z","comments":true,"path":"2022/02/20/后处理技术1/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/02/20/%E5%90%8E%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF1/","excerpt":"","text":"后处理（上）启用后处理在摄像头添加脚本 123456789101112131415161718192021using System.Collections;using System.Collections.Generic;using UnityEngine;[ExecuteInEditMode()]//编辑模式就能看到效果public class CameraPostPress : MonoBehaviour&#123; public Material mat; // Start is called before the first frame update void Start() &#123; if(mat==null||SystemInfo.supportsImageEffects==false||mat.shader==null||mat.shader.isSupported==false) &#123; enabled = false; return; &#125; &#125; private void OnRenderImage(RenderTexture source, RenderTexture destination) &#123; //当渲染图片启用 source是帧处理的图片 0是pass的顺序 Graphics.Blit(source,destination,mat, 0); &#125;&#125; 背景板 只要物体能拓展到屏幕上，就能让图片平铺到图片上，在片源部分做 12half2 screen_uv = i.screen_pos.xy / (i.screen_pos.w + 0.000001);screen_uv = (screen_uv + 1.0) * 0.5; 注意的是dx的y轴是反的 有三套解决方案 第一种12345678910111213141516171819v2f vert (appdata v)&#123; v2f o; o.vertex = UnityObjectToClipPos(v.vertex); o.uv = v.uv; o.screen_pos = o.vertex; o.screen_pos.y = -o.screen_pos.y; return o;&#125;fixed4 frag(v2f i) : SV_Target&#123; half2 screen_uv = i.screen_pos.xy / (i.screen_pos.w + 0.000001); screen_uv = (screen_uv + 1.0) * 0.5; // sample the texture fixed4 col = tex2D(_MainTex, screen_uv); return col;&#125; 第二种12345678910111213141516171819v2f vert (appdata v)&#123; v2f o; o.vertex = UnityObjectToClipPos(v.vertex); o.uv = v.uv; o.screen_pos = o.vertex; o.screen_pos.y = o.screen_pos.y * _ProjectionParams.x;//改变 return o;&#125;fixed4 frag(v2f i) : SV_Target&#123; half2 screen_uv = i.screen_pos.xy / (i.screen_pos.w + 0.000001); screen_uv = (screen_uv + 1.0) * 0.5; // sample the texture fixed4 col = tex2D(_MainTex, screen_uv); return col;&#125; 第三种123456789101112131415161718v2f vert (appdata v)&#123; v2f o; o.vertex = UnityObjectToClipPos(v.vertex); o.uv = v.uv; o.screen_pos=ComputeScreenPos(o.vertex);//改变 return o;&#125;cfixed4 frag(v2f i) : SV_Target&#123; half2 screen_uv = i.screen_pos.xy / (i.screen_pos.w + 0.000001); //改变 // sample the texture fixed4 col = tex2D(_MainTex, screen_uv); return col;&#125; 背景板代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162Shader &quot;Unlit/Quad&quot;&#123; Properties &#123; _MainTex (&quot;Texture&quot;, 2D) = &quot;white&quot; &#123;&#125; &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot;=&quot;Opaque&quot; &#125; LOD 100 Pass &#123; CGPROGRAM #pragma vertex vert #pragma fragment frag // make fog work #include &quot;UnityCG.cginc&quot; struct appdata &#123; float4 vertex : POSITION; float2 uv : TEXCOORD0; &#125;; struct v2f &#123; float2 uv : TEXCOORD0; float4 screen_pos:TEXCOORD1; float4 vertex : SV_POSITION; &#125;; sampler2D _MainTex; float4 _MainTex_ST; v2f vert (appdata v) &#123; v2f o; o.vertex = UnityObjectToClipPos(v.vertex); o.uv = v.uv; //o.screen_pos = o.vertex; //o.screen_pos.y = -o.screen_pos.y; o.screen_pos=ComputeScreenPos(o.vertex); return o; &#125; fixed4 frag(v2f i) : SV_Target &#123; half2 screen_uv = i.screen_pos.xy / (i.screen_pos.w + 0.000001); screen_uv = (screen_uv + 1.0) * 0.5; // sample the texture fixed4 col = tex2D(_MainTex, screen_uv); return col; &#125; ENDCG &#125; &#125;&#125; 调色 ASE 内容色调1234567891011121314151617float3 HSVToRGB(float3 c) &#123; float4 K = float4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0); float3 p = abs(frac(c.xxx + K.xyz) * 6.0 - K.www); return c.z * lerp(K.xxx, saturate(p - K.xxx), c.y);&#125;//RGB B*lerp(float3(1.0,1.0,1.0)) frac 取小数部分 色调（H），饱和度（S），明度（V）。//H=B*lerp(1.0f,saturate(abs(frac(R + 1.0) * 6.0 - 3.0) - 1.0f),G)//S=B*lerp(1.0f,saturate(abs(frac(R + 2.0 / 3.0) * 6.0 - 3.0) - 1.0f),G)//V=B*lerp(1.0f,saturate(abs(frac(R + 1.0 / 3.0) * 6.0 - 3.0) - 1.0f),G)float3 RGBToHSV(float3 c) &#123; float4 K = float4(0.0, -1.0 / 3.0, 2.0 / 3.0, -1.0); float4 p = lerp(float4(c.bg, K.wz), float4(c.gb, K.xy), step(c.b, c.g)); float4 q = lerp(float4(p.xyw, c.r), float4(c.r, p.yzx), step(p.x, c.r)); float d = q.x - min(q.w, q.y); float e = 1.0e-10; return float3(abs(q.z + (q.w - q.y) / (6.0 * d + e)), d / (q.x + e), q.x);&#125; 亮度简单粗暴直接乘 1col.rgb=col.rgb*_Brightness; 饱和度12float lumin=dot(col.rgb,float3(0.22,0.707,0.071));col.rgb=lerp(lumin,col.rgb,_Saturation); 对比度float3(0.5,0.5,0.5)是灰色 1col.rgb=lerp(float3(0.5,0.5,0.5),col.rgb,_Contrast); 暗角&#x2F;晕影1234float2 d=abs(i.uv-0.5)*_VignetteIntensity;d=pow(saturate(d),_VignetteRoundness);float dist=length(d);col.rgb=pow(saturate(1.0-dist*dist),_VignetteSmoothness)*col.rgb; 调色代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081Shader &quot;Hidden/Color_Code&quot;&#123; Properties &#123; _MainTex (&quot;Texture&quot;, 2D) = &quot;white&quot; &#123;&#125; _Brightness(&quot;Brightness&quot;, Float) = 1 _Saturation(&quot;Saturation&quot;,Float) = 1 _Contrast(&quot;Contrast&quot;,Float) = 1 _VignetteIntensity(&quot;VignetteIntensity&quot;,Range(0.05,3.0)) = 1.5 _VignetteRoundness(&quot;VignetteRoundness&quot;,Range(1,6)) = 5 _VignetteSmoothness(&quot;VignetteSmoothness&quot;,Range(0.05,5)) = 5 _HueShift(&quot;HueShift&quot;,Range(0,1)) = 0 &#125; SubShader &#123; // No culling or depth Cull Off ZWrite Off ZTest Always Pass &#123; CGPROGRAM #pragma vertex vert_img #pragma fragment frag #include &quot;UnityCG.cginc&quot; float3 HSVToRGB(float3 c) &#123; float4 K = float4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0); float3 p = abs(frac(c.xxx + K.xyz) * 6.0 - K.www); return c.z * lerp(K.xxx, saturate(p - K.xxx), c.y); &#125; //RGB B*lerp(float3(1.0,1.0,1.0)) frac 取小数部分 色调（H），饱和度（S），明度（V）。 //H=B*lerp(1.0f,saturate(abs(frac(R + 1.0) * 6.0 - 3.0) - 1.0f),G) //S=B*lerp(1.0f,saturate(abs(frac(R + 2.0 / 3.0) * 6.0 - 3.0) - 1.0f),G) //V=B*lerp(1.0f,saturate(abs(frac(R + 1.0 / 3.0) * 6.0 - 3.0) - 1.0f),G) float3 RGBToHSV(float3 c) &#123; float4 K = float4(0.0, -1.0 / 3.0, 2.0 / 3.0, -1.0); float4 p = lerp(float4(c.bg, K.wz), float4(c.gb, K.xy), step(c.b, c.g)); float4 q = lerp(float4(p.xyw, c.r), float4(c.r, p.yzx), step(p.x, c.r)); float d = q.x - min(q.w, q.y); float e = 1.0e-10; return float3(abs(q.z + (q.w - q.y) / (6.0 * d + e)), d / (q.x + e), q.x); &#125; sampler2D _MainTex; float _Brightness; float _Saturation; float _Contrast; float _VignetteIntensity; float _VignetteRoundness; float _VignetteSmoothness; float _HueShift; fixed4 frag (v2f_img i) : SV_Target &#123; fixed4 sourse = tex2D(_MainTex, i.uv); fixed4 col=sourse; //色相 fixed3 hsv = RGBToHSV(sourse.rgb); hsv.r= hsv.r +_HueShift; col.rgb=HSVToRGB(hsv); //亮度 col.rgb=col.rgb*_Brightness; //饱和度 float lumin=dot(col.rgb,float3(0.22,0.707,0.071)); col.rgb=lerp(lumin,col.rgb,_Saturation); //对比度 col.rgb=lerp(float3(0.5,0.5,0.5),col.rgb,_Contrast); //暗角/晕影 float2 d=abs(i.uv-0.5)*_VignetteIntensity; d=pow(saturate(d),_VignetteRoundness); float dist=length(d); col.rgb=pow(saturate(1.0-dist*dist),_VignetteSmoothness)*col.rgb; return col; &#125; ENDCG &#125; &#125;&#125; 破碎的玻璃 上玻璃12345float aspect = _ScreenParams.x / _ScreenParams.y; // x = width y = height z = 1 + 1.0/width w = 1 + 1.0/heightfloat2 glass_uv = float2(i.uv.x * aspect, i.uv.y) * _GlassMask_ST.xy + _GlassMask_ST.zw;half glass_opacity = tex2D(_GlassMask, glass_uv).r;finalcolor = lerp(finalcolor, _GlassCrack.xxx, glass_opacity); 上法线1half3 glass_normal = UnpackNormal(tex2D(_GlassNormal, glass_uv)); 解决边缘法线贴图重影12half2 d = 1.0 - smoothstep(0.95,1,abs(i.uv * 2.0 - 1.0));half vfactor = d.x * d.y; 解决法线贴图毛玻璃的问题1234float2 d_mask = step(0.005, abs(glass_normal.xy));float mask = d_mask.x * d_mask.y;half2 uv_distort = i.uv + glass_normal.xy * _Distort * vfactor * mask;half4 col = tex2D(_MainTex, uv_distort); 总代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455Shader &quot;Hidden/BrokenGlass&quot;&#123; Properties &#123; _MainTex (&quot;Texture&quot;, 2D) = &quot;white&quot; &#123;&#125; _GlassMask(&quot;GlassMask&quot;,2D) = &quot;black&quot;&#123;&#125; _GlassCrack(&quot;GlassCrack&quot;,Float) = 1 _GlassNormal(&quot;GlassNormal&quot;,2D) = &quot;bump&quot;&#123;&#125; _Distort(&quot;Distort&quot;,Float) = 1 &#125; SubShader &#123; // No culling or depth Cull Off ZWrite Off ZTest Always Pass &#123; CGPROGRAM #pragma vertex vert_img #pragma fragment frag #include &quot;UnityCG.cginc&quot; sampler2D _MainTex; sampler2D _GlassMask; float4 _GlassMask_ST; float _GlassCrack; sampler2D _GlassNormal; float _Distort; half4 frag (v2f_img i) : SV_Target &#123; float aspect = _ScreenParams.x / _ScreenParams.y; // x = width y = height z = 1 + 1.0/width w = 1 + 1.0/height float2 glass_uv = float2(i.uv.x * aspect, i.uv.y) * _GlassMask_ST.xy + _GlassMask_ST.zw; half glass_opacity = tex2D(_GlassMask, glass_uv).r; half3 glass_normal = UnpackNormal(tex2D(_GlassNormal, glass_uv)); half2 d = 1.0 - smoothstep(0.95,1,abs(i.uv * 2.0 - 1.0)); half vfactor = d.x * d.y; float2 d_mask = step(0.005, abs(glass_normal.xy)); float mask = d_mask.x * d_mask.y; half2 uv_distort = i.uv + glass_normal.xy * _Distort * vfactor * mask; half4 col = tex2D(_MainTex, uv_distort); half3 finalcolor = col.rgb; finalcolor = lerp(finalcolor, _GlassCrack.xxx, glass_opacity); return float4(finalcolor,col.a); &#125; ENDCG &#125; &#125;&#125;","categories":[{"name":"游戏","slug":"游戏","permalink":"https://mrchenlearnspace.github.io/categories/%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"Shader","slug":"Shader","permalink":"https://mrchenlearnspace.github.io/tags/Shader/"}]},{"title":"Shader的主要节点介绍","slug":"Shader的主要节点介绍","date":"2022-02-20T07:38:45.000Z","updated":"2022-11-14T14:24:55.690Z","comments":true,"path":"2022/02/20/Shader的主要节点介绍/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/02/20/Shader%E7%9A%84%E4%B8%BB%E8%A6%81%E8%8A%82%E7%82%B9%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"前言虽然学习很久了，但没有好好总结过shader用到的数学，以至于在用的过程中总是忘记，然后花时间去找，裂开，没有搞完的发现后后续补充。 正文长度length(a)简单的欧式距离，根号下平方的那个。 点乘dot（ a，b）点乘是通过将对应分量逐个相乘，然后再把所得积相加来计算的。就是高中学的向量的乘法 v¯⋅k¯&#x3D;||v¯||⋅||k¯||⋅cosθ 1(a1,a2,a3)⋅(b1,b2,b3)=a1*b1+a2* b2+a3*b3 用处当两个向量都是单位向量时就是两个向量的夹角的余弦值，常用于计算角度。 叉乘cross（Lhs，Rhs）叉乘只在3D空间中有定义，它需要两个不平行向量作为输入，生成一个正交于两个输入向量的第三个向量。如果输入的两个向量也是正交的，那么叉乘之后将会产生3个互相正交的向量。接下来的教程中这会非常有用。下面的图片展示了3D空间中叉乘的样子 ： 注意：顺序在此运算符上很重要，因为 AxB 输出的结果与 BxA 不同（其结果类似于 -AxB ）。 c&#x3D;cross（a,b） c1&#x3D;a2b3-a3b2 c2&#x3D;a3b1-a1b3 c3&#x3D;a1b2-a2b1 用处得到两个向量做成平面的法向量； Saturate饱和节点输出在其上设置的向量的值或单个分量饱和到[0 1]范围。 0：如果输入小于 0，则返回此值 输入：如果值介于 0 和 1 之间，则返回此值 1：如果值大于 1，则返回此值 线性插值lerf（a,b,weight）公式(1-weight)×a+weight×b比较均匀，比较生硬 clamp（input,min,max）Clamp 节点输出其输入值或夹紧在 Min， Max范围之间的矢量的各个分量。 最小值：如果输入值小于 Min，则返回此值 输入：如果输入值介于最小值和最大值之间，则返回此值 最大值：如果输入值大于 Max，则返回此值 平滑阶梯smoothstep(min,max,input)Clamp 节点输出其输入值或夹紧在 Min， Max范围之间的矢量的各个分量。 最小值：如果输入值小于 Min，则返回0 输入：如果输入值介于最小值和最大值之间，则返回clamp（（input-min）&#x2F;（max-min），0，1） 最大值：如果输入值大于 Max，则返回1 尾声还在总结中","categories":[{"name":"游戏","slug":"游戏","permalink":"https://mrchenlearnspace.github.io/categories/%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"Shader","slug":"Shader","permalink":"https://mrchenlearnspace.github.io/tags/Shader/"}]},{"title":"光照模型与法线贴图","slug":"光照模型与法线贴图","date":"2022-02-14T08:38:45.000Z","updated":"2022-11-14T14:21:27.243Z","comments":true,"path":"2022/02/14/光照模型与法线贴图/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/02/14/%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B%E4%B8%8E%E6%B3%95%E7%BA%BF%E8%B4%B4%E5%9B%BE/","excerpt":"","text":"渲染路径前向渲染对每一个物体每一个光源进行渲染，超出范围的灯光以顶点灯光渲染，适用于灯光较少的情况 ForwardBase在这个Pass里面，主方向灯以及超出范围的灯光作为顶点灯光传入SH， LightMap，Reflection， Probe等计算均在这个Pass里面完成。 ForwardAdd数量范围内的灯光，每个灯光的计算，均会调用一次这个pass，计算的结果通过Blend one one 叠加起来。 延迟渲染 使用MRT技术 ，RT0是物体的颜色，RT1是金属反射的颜色，RT2是法线数据，RT4是深度信息。 光源直接渲染一次。有带宽和设备支持的限制，ue4和HDRP默认。 法线贴图法线顶点垂直模型的线NORMAL 切线UV中u递增的线或者v递增的线，引擎帮我们生成的TANGENT 副切线 法线叉乘切线得到的。 unity的无光照shader获得光源信息实战ForwardBase Pass关键点需要将光照模式调为ForwardBase 1Tags &#123; &quot;LightMode&quot; = &quot;ForwardBase&quot;&#125; 在编写时加入如下引用文件以方便获取光照参数 12#pragma multi_compile_fwdbase#include &quot;AutoLight.cginc&quot; appadata 1234567struct appdata &#123; float4 vertex : POSITION; float2 uv : TEXCOORD0; float3 normal:NORMAL;//法线 float4 tangent:TANGENT;//切线注意是四维向量，w用来矫正平台的区别 &#125;; 片元数据 12345678910struct v2f &#123; float2 uv : TEXCOORD0; float4 vertex : SV_POSITION; float3 normali_dir:TEXCOORD1; float3 tangent_dir:TEXCOORD2; float3 binormal_dir:TEXCOORD3; float3 pos_world:TEXCOORD4; &#125;; 光源数据 1half3 light_dir =normalize( _WorldSpaceLightPos0.xyz );//定向光位置无意义所以代表光照方向 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105Pass &#123; Tags &#123; &quot;LightMode&quot; = &quot;ForwardBase&quot;&#125; CGPROGRAM #pragma vertex vert #pragma fragment frag #pragma multi_compile_fwdbase #include &quot;UnityCG.cginc&quot; #include &quot;AutoLight.cginc&quot; struct appdata &#123; float4 vertex : POSITION; float2 uv : TEXCOORD0; float3 normal:NORMAL; float4 tangent:TANGENT; &#125;; struct v2f &#123; float2 uv : TEXCOORD0; float4 vertex : SV_POSITION; float3 normali_dir:TEXCOORD1; float3 tangent_dir:TEXCOORD2; float3 binormal_dir:TEXCOORD3; float3 pos_world:TEXCOORD4; &#125;; sampler2D _MainTex; float4 _MainTex_ST; sampler2D _AOMap; float4 _AOMap_ST; float4 _LightColor0; float _Shininess; float _SpecularIntensity; float4 _AmbientColor; sampler2D _SpecMask; float _SpecMask_ST; sampler2D _NormalMap; float4 _NormalMap_ST; float _NormalIntensity; float __AmbientIntensity; float3 ACESFilm(float3 x) &#123; float a = 2.51f; float b = 0.03f; float c = 2.43f; float d = 0.59f; float e = 0.14f; return saturate((x*(a*x + b)) / (x*(c*x + d) + e)); &#125;; v2f vert (appdata v) &#123; v2f o; o.vertex = UnityObjectToClipPos(v.vertex); o.normali_dir = normalize(mul(float4(v.normal,0.0),unity_WorldToObject).xyz); o.tangent_dir = normalize(mul(float4(v.tangent.xyz,0.0),unity_WorldToObject).xyz); o.binormal_dir = normalize(cross(o.normali_dir,o.tangent_dir))* v.tangent.w; o.pos_world = mul(unity_ObjectToWorld,v.vertex).xyz; o.uv = TRANSFORM_TEX(v.uv, _MainTex); return o; &#125; fixed4 frag (v2f i) : SV_Target &#123; fixed4 col=fixed4(0,0,0,0); half3 AO = tex2D(_AOMap,i.uv).xyz; half3 spec_mask = tex2D(_SpecMask,i.uv).xyz; half4 normalmap = tex2D(_NormalMap,i.uv); half3 view_dir = normalize(_WorldSpaceCameraPos.xyz - i.pos_world); half3 light_dir =normalize( _WorldSpaceLightPos0.xyz ); //Normal half3 normal_dir =normalize(i.normali_dir); half3 tangent_dir =normalize(i.tangent_dir)*_NormalIntensity; half3 binormal_dir =normalize(i.binormal_dir)*_NormalIntensity; half3 normal_data = UnpackNormal(normalmap); float3x3 TBN = float3x3(tangent_dir,binormal_dir,normal_dir); normal_dir =normalize(mul(normal_data,TBN)); //normal_dir=tangent_dir*normal_data.x*_NormalIntensity+binormal_dir*normal_data.y*_NormalIntensity+normal_dir*normal_data.z ; half NotL = max(dot(normal_dir,light_dir),0); half3 diffuse = NotL*_LightColor0.xyz; half3 specular = pow(max(dot(reflect(-light_dir,normal_dir),view_dir),0),_Shininess)* _LightColor0.xyz*_SpecularIntensity*spec_mask; half3 ambient = _AmbientColor.xyz*__AmbientIntensity; //col.xyz+= AO; col.xyz += diffuse; col.xyz += specular; col.xyz += ambient; // sample the texture col.xyz *=tex2D(_MainTex, i.uv).xyz; col.xyz *=AO; // apply fog return col; &#125; ENDCG &#125; ForwardAdd Pass关键点需要将光照模式调为ForwardAdd 1Tags &#123; &quot;LightMode&quot; = &quot;ForwardAdd&quot;&#125; 要加混合模式 1Blend One One 在编写时加入如下引用文件以方便获取光照参数 12#pragma multi_compile_fwdadd#include &quot;AutoLight.cginc&quot; appadata 1234567struct appdata &#123; float4 vertex : POSITION; float2 uv : TEXCOORD0; float3 normal:NORMAL;//法线 float4 tangent:TANGENT;//切线注意是四维向量，w用来矫正平台的区别 &#125;; 片元数据 12345678910struct v2f &#123; float2 uv : TEXCOORD0; float4 vertex : SV_POSITION; float3 normali_dir:TEXCOORD1; float3 tangent_dir:TEXCOORD2; float3 binormal_dir:TEXCOORD3; float3 pos_world:TEXCOORD4; &#125;; 光源数据 如果是定向光的话和ForwardBase是一样的，但如果是点光源的话应考虑衰减量和光照方向 12345half3 light_dir =normalize( _WorldSpaceLightPos0.xyz-i.pos_world.xyz ); half distance=length(_WorldSpaceLightPos0.xyz-i.pos_world.xyz); float range = 1.0/unity_WorldToLight[0][0]; half attuenation =saturate((range-distance)/range); 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111 Pass &#123; Tags &#123; &quot;LightMode&quot; = &quot;ForwardAdd&quot;&#125; Blend One One CGPROGRAM #pragma vertex vert #pragma fragment frag #pragma multi_compile_fwdadd #include &quot;UnityCG.cginc&quot; #include &quot;AutoLight.cginc&quot; struct appdata &#123; float4 vertex : POSITION; float2 uv : TEXCOORD0; float3 normal:NORMAL; float4 tangent:TANGENT; &#125;; struct v2f &#123; float2 uv : TEXCOORD0; float4 vertex : SV_POSITION; float3 normali_dir:TEXCOORD1; float3 tangent_dir:TEXCOORD2; float3 binormal_dir:TEXCOORD3; float3 pos_world:TEXCOORD4; &#125;; sampler2D _MainTex; float4 _MainTex_ST; sampler2D _AOMap; float4 _AOMap_ST; float4 _LightColor0; float _Shininess; float _SpecularIntensity; float4 _AmbientColor; sampler2D _SpecMask; float _SpecMask_ST; sampler2D _NormalMap; float4 _NormalMap_ST; float _NormalIntensity; float3 ACESFilm(float3 x)&#123; float a = 2.51f; float b = 0.03f; float c = 2.43f; float d = 0.59f; float e = 0.14f; return saturate((x*(a*x + b)) / (x*(c*x + d) + e));&#125;; v2f vert (appdata v) &#123; v2f o; o.vertex = UnityObjectToClipPos(v.vertex); o.normali_dir = normalize(mul(float4(v.normal,0.0),unity_WorldToObject).xyz); o.tangent_dir = normalize(mul(float4(v.tangent.xyz,0.0),unity_WorldToObject).xyz); o.binormal_dir = normalize(cross(o.normali_dir,o.tangent_dir))*v.tangent.w; o.pos_world = mul(unity_ObjectToWorld,v.vertex).xyz; o.uv = TRANSFORM_TEX(v.uv, _MainTex); return o; &#125; fixed4 frag (v2f i) : SV_Target &#123; fixed4 col=fixed4(0,0,0,0); half3 spec_mask = tex2D(_SpecMask,i.uv).xyz; half4 normalmap = tex2D(_NormalMap,i.uv); half3 normal_dir =normalize(i.normali_dir); half3 tangent_dir =normalize(i.tangent_dir); half3 binormal_dir =normalize(i.binormal_dir); half3 normal_data = UnpackNormal(normalmap); normal_dir= tangent_dir*normal_data.x *_NormalIntensity+binormal_dir*normal_data.y*_NormalIntensity+normal_dir*normal_data.z ; half3 view_dir = normalize(_WorldSpaceCameraPos.xyz - i.pos_world); #if defined (DIRECTIONAL) half3 light_dir =normalize( _WorldSpaceLightPos0.xyz ); half attuenation=1.0; #elif defined (POINT) half3 light_dir =normalize( _WorldSpaceLightPos0.xyz-i.pos_world.xyz ); half distance=length(_WorldSpaceLightPos0.xyz-i.pos_world.xyz); float range = 1.0/unity_WorldToLight[0][0]; half attuenation =saturate((range-distance)/range); #endif half NotL = max(dot(normal_dir,light_dir),0); half3 diffuse = NotL*_LightColor0.xyz; half3 specular = pow(max(dot(reflect(-light_dir,normal_dir),view_dir),0),_Shininess)* _LightColor0.xyz*_SpecularIntensity*spec_mask; half3 AO = tex2D(_AOMap,i.uv).xyz; //col.xyz+= AO; col.xyz += diffuse; col.xyz += specular; // sample the texture col.xyz *=tex2D(_MainTex, i.uv).xyz; col.xyz *=AO; col.xyz *=attuenation; // apply fog return col; &#125; ENDCG &#125;","categories":[{"name":"游戏","slug":"游戏","permalink":"https://mrchenlearnspace.github.io/categories/%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"Shader","slug":"Shader","permalink":"https://mrchenlearnspace.github.io/tags/Shader/"}]},{"title":"魔镜世界","slug":"魔镜世界","date":"2022-02-13T02:38:45.000Z","updated":"2022-11-14T14:21:54.042Z","comments":true,"path":"2022/02/13/魔镜世界/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/02/13/%E9%AD%94%E9%95%9C%E4%B8%96%E7%95%8C/","excerpt":"","text":"魔镜世界 渲染队列和颜色遮罩Rendering Queue从小到大进行排序 几何体 2000 Alpha Test 2450 Transparent 3000 1&quot;Queue&quot; = &quot;AlphaTest+10&quot; Color Mask12ColorMask 0ColorMask 相应的颜色通道 模板测试（Stencil）Reference 参数便于判端和筛选 Comparison 判断方式‘ Pass 面 通过之后的进行操作，图中是替换的意思 Fail 失败之后的操作 ZFail 深度测试失败的操作 123456Stencil&#123; Ref 1 Comp always Pass Replace&#125; 深度测试（Depth）12345678ZWrite Off//深度测试的开关ZTest Less//深度小于当前缓存则通过ZTest Greater//深度大于当前缓存则通过ZTest LEqual//深度小于等于当前缓存则通过ZTest GEqual//深度大于等于当前缓存则通过ZTest Equal//深度等于当前缓存则通过ZTest NotEqual//深度不等于当前缓存则通过ZTest Always//不论如何都通过 制作过程将材质导入dome课程材料略 制作镜子ShaderASE图 核心代码1234567891011Tags &#123; &quot;Queue&quot; = &quot;AlphaTest+10&quot; &#125;Pass&#123; ColorMask 0 Stencil&#123; Ref 1 Comp always Pass Replace &#125; ZWrite Off&#125; 制作镜内世界ASE图 核心代码12345Tags &#123; &quot;Queue&quot; = &quot;AlphaTest+20&quot; &#125;Stencil&#123; Ref 1 Comp equal&#125; 制作深度测试球这一步是为了当模板测试未通过物体出现在魔镜后会出现在魔镜中的情况 ASE图 核心代码1234567Tags &#123; &quot;Queue&quot;=&quot;AlphaTest+15&quot; &#125; LOD 100 Stencil&#123; Ref 1 Comp equal &#125; ZTest always 完成效果","categories":[{"name":"游戏","slug":"游戏","permalink":"https://mrchenlearnspace.github.io/categories/%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"Shader","slug":"Shader","permalink":"https://mrchenlearnspace.github.io/tags/Shader/"}]},{"title":"藤曼生长","slug":"藤曼生长","date":"2022-02-10T15:38:45.000Z","updated":"2022-11-14T14:22:30.146Z","comments":true,"path":"2022/02/10/藤曼生长/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/02/10/%E8%97%A4%E6%9B%BC%E7%94%9F%E9%95%BF/","excerpt":"","text":"藤曼生长预览视图 PBR材质下的效果 显示更好看上ASE 简化版可以乘以顶点法线向量可以实现物体的缩放，用一个UV图的权重控制不同位置缩放部分，可以形成藤曼的样子 ASE 代码Properties12345678_MainTex (&quot;Texture&quot;, 2D) = &quot;white&quot; &#123;&#125;_Grow(&quot;Grow&quot;,Range(-1.0,1.0)) = 0.0_Expend(&quot;Expend&quot;,Float) = 0.0_Scale(&quot;Scale&quot;,Float) = 0.0_GrowMin(&quot;GrowMin&quot;, Range(0,1.0)) = 0.6_GrowMax(&quot;GrowMax&quot;, Range(0,1.5)) = 1.0_EndMin(&quot;EndMin&quot;, Range(0,1.0)) = 0.6_EndMax(&quot;EndMax&quot;, Range(0,1.5)) = 1.0 appdata123456struct appdata &#123; float4 vertex : POSITION; float2 uv : TEXCOORD0; float3 normal:NORMAL; &#125;; vert123456789101112v2f vert (appdata v)&#123; v2f o; half weight = max(smoothstep( _GrowMin, _GrowMax, v.uv.y - _Grow), smoothstep(_EndMin, _EndMax,v.uv.y )); half3 weight_combine = weight * _Expend * 0.01f*v.normal; half3 scale_combine = _Scale * 0.01f * v.normal; half3 normal_combine = weight_combine + scale_combine; v.vertex.xyz = v.vertex.xyz+ normal_combine; o.vertex = UnityObjectToClipPos(v.vertex); o.uv = TRANSFORM_TEX(v.uv, _MainTex); return o;&#125; frag1234567fixed4 frag(v2f i) : SV_Target&#123; clip(1 - (i.uv.y - _Grow)); // sample the texture fixed4 col = tex2D(_MainTex, i.uv); return col;&#125; 总代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475Shader &quot;Unlit/Vice1_Code&quot;&#123; Properties &#123; _MainTex (&quot;Texture&quot;, 2D) = &quot;white&quot; &#123;&#125; _Grow(&quot;Grow&quot;,Range(-1.0,1.0)) = 0.0 _Expend(&quot;Expend&quot;,Float) = 0.0 _Scale(&quot;Scale&quot;,Float) = 0.0 _GrowMin(&quot;GrowMin&quot;, Range(0,1.0)) = 0.6 _GrowMax(&quot;GrowMax&quot;, Range(0,1.5)) = 1.0 _EndMin(&quot;EndMin&quot;, Range(0,1.0)) = 0.6 _EndMax(&quot;EndMax&quot;, Range(0,1.5)) = 1.0 &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot;=&quot;Opaque&quot; &#125; LOD 100 Pass &#123; CGPROGRAM #pragma vertex vert #pragma fragment frag // make fog work #include &quot;UnityCG.cginc&quot; struct appdata &#123; float4 vertex : POSITION; float2 uv : TEXCOORD0; float3 normal:NORMAL; &#125;; struct v2f &#123; float2 uv : TEXCOORD0; float4 vertex : SV_POSITION; &#125;; sampler2D _MainTex; float4 _MainTex_ST; float _Grow; float _Expend; float _GrowMin; float _GrowMax; float _EndMin; float _EndMax; float _Scale; v2f vert (appdata v) &#123; v2f o; half weight = max(smoothstep( _GrowMin, _GrowMax, v.uv.y - _Grow), smoothstep(_EndMin, _EndMax,v.uv.y )); half3 weight_combine = weight * _Expend * 0.01f*v.normal; half3 scale_combine = _Scale * 0.01f * v.normal; half3 normal_combine = weight_combine + scale_combine; v.vertex.xyz = v.vertex.xyz+ normal_combine; o.vertex = UnityObjectToClipPos(v.vertex); o.uv = TRANSFORM_TEX(v.uv, _MainTex); return o; &#125; fixed4 frag(v2f i) : SV_Target &#123; clip(1 - (i.uv.y - _Grow)); // sample the texture fixed4 col = tex2D(_MainTex, i.uv); return col; &#125; ENDCG &#125; &#125;&#125; 总结最近有一点偷懒，更新有点慢，新年快乐，新的一年，冲冲冲；","categories":[{"name":"游戏","slug":"游戏","permalink":"https://mrchenlearnspace.github.io/categories/%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"Shader","slug":"Shader","permalink":"https://mrchenlearnspace.github.io/tags/Shader/"}]},{"title":"薄膜干涉效果","slug":"薄膜干涉效果","date":"2022-01-21T16:38:45.000Z","updated":"2022-11-14T14:20:29.860Z","comments":true,"path":"2022/01/22/薄膜干涉效果/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/01/22/%E8%96%84%E8%86%9C%E5%B9%B2%E6%B6%89%E6%95%88%E6%9E%9C/","excerpt":"","text":"薄膜干涉 材质捕捉效果（Material Capture）预览效果 ASE图 原理将观察坐标系的顶点法线xy当作材质的uv，将材质图片根据坐标平埔视角坐标系下的模型上，缺点当模型处于视野边缘时会有破绽。 代码Properties 123456_MainTex (&quot;diffuse&quot;, 2D) = &quot;white&quot; &#123;&#125; _MatCatAddTex (&quot;MatCatAdd&quot;, 2D) = &quot;white&quot; &#123;&#125; _MatCatAddIntensity (&quot;MatCatAddIntensity&quot;, Float) = 0.35 _MatCatTex (&quot;MatCat&quot;, 2D) = &quot;white&quot; &#123;&#125; _MatCatIntensity (&quot;MatCatIntensity&quot;, Float) = 5.0 Pass 12345678sampler2D _MatCatAddTex;float4 _MatCatAddTex_ST;float _MatCatAddIntensity;sampler2D _MatCatTex;float4 _MatCatTex_ST;float _MatCatIntensity; vert 1o.normal_world = mul(float4(v.normal,0.0) ,unity_WorldToObject);//获取worldnormal frag 1234fixed4 col_diffuse = tex2D(_MainTex, i.uv);half2 MatCat_uv = (mul(UNITY_MATRIX_V, half4(normal_world, 0.0)).xy + 1.0f) * 0.5f;fixed4 col_MatCatAdd = tex2D(_MatCatAddTex, MatCat_uv) * _MatCatAddIntensity;fixed4 col_MatCat = tex2D(_MatCatTex, MatCat_uv) * _MatCatIntensity; Ramp填充里面的颜色预览效果 过度颜色图 ASE图 原理利用菲涅尔方程的经验，1.0f - saturate(dot(normal_world, view_dir))在x和y上得到的是单调连续数值 代码Properties 1_RampTex(&quot;Ramp&quot;, 2D) = &quot;white&quot; &#123;&#125; vart 12float3 pos_world = mul(unity_ObjectToWorld, v.vertex);o.view_world = normalize( _WorldSpaceCameraPos - pos_world ); frag 123half3 view_dir = normalize(i.view_world);half fresnel = 1.0f - saturate(dot(normal_world, view_dir));fixed4 col_Ramp = tex2D(_RampTex, half2(fresnel, 0.5f)); 合并效果最终效果 ASE图 总代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697Shader &quot;Unlit/MatCat1_Code&quot;&#123; Properties &#123; _MainTex (&quot;diffuse&quot;, 2D) = &quot;white&quot; &#123;&#125; _MatCatAddTex (&quot;MatCatAdd&quot;, 2D) = &quot;white&quot; &#123;&#125; _MatCatAddIntensity (&quot;MatCatAddIntensity&quot;, Float) = 0.35 _MatCatTex (&quot;MatCat&quot;, 2D) = &quot;white&quot; &#123;&#125; _MatCatIntensity (&quot;MatCatIntensity&quot;, Float) = 5.0 _RampTex(&quot;Ramp&quot;, 2D) = &quot;white&quot; &#123;&#125; &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot;=&quot;Opaque&quot; &#125; LOD 100 Pass &#123; CGPROGRAM #pragma vertex vert #pragma fragment frag #include &quot;UnityCG.cginc&quot; struct appdata &#123; float4 vertex : POSITION; float2 uv : TEXCOORD0; float3 normal : NORMAL; &#125;; struct v2f &#123; float2 uv : TEXCOORD0; float3 normal_world : TEXCOORD1; float3 view_world : TEXCOORD2; float4 vertex : SV_POSITION; &#125;; sampler2D _MainTex; float4 _MainTex_ST; sampler2D _MatCatAddTex; float4 _MatCatAddTex_ST; float _MatCatAddIntensity; sampler2D _MatCatTex; float4 _MatCatTex_ST; float _MatCatIntensity; sampler2D _RampTex; float4 _RampTex_ST; v2f vert (appdata v) &#123; v2f o; o.vertex = UnityObjectToClipPos(v.vertex); o.uv = TRANSFORM_TEX(v.uv, _MainTex); o.normal_world = mul(float4(v.normal,0.0) ,unity_WorldToObject); float3 pos_world = mul(unity_ObjectToWorld, v.vertex); o.view_world = normalize( _WorldSpaceCameraPos - pos_world ); return o; &#125; fixed4 frag(v2f i) : SV_Target &#123; half3 normal_world = normalize(i.normal_world); fixed4 col; // MatCap fixed4 col_diffuse = tex2D(_MainTex, i.uv); half2 MatCat_uv = (mul(UNITY_MATRIX_V, half4(normal_world, 0.0)).xy + 1.0f) * 0.5f; fixed4 col_MatCatAdd = tex2D(_MatCatAddTex, MatCat_uv) * _MatCatAddIntensity; fixed4 col_MatCat = tex2D(_MatCatTex, MatCat_uv) * _MatCatIntensity; //Ramp half3 view_dir = normalize(i.view_world); half fresnel = 1.0f - saturate(dot(normal_world, view_dir)); fixed4 col_Ramp = tex2D(_RampTex, half2(fresnel, 0.5f)); col = col_diffuse * col_MatCat * col_Ramp; col += col_MatCatAdd ; // return fixed4(i.normal_world,0.0); return col; &#125; ENDCG &#125; &#125;&#125;","categories":[{"name":"游戏","slug":"游戏","permalink":"https://mrchenlearnspace.github.io/categories/%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"Shader","slug":"Shader","permalink":"https://mrchenlearnspace.github.io/tags/Shader/"}]},{"title":"人物扫光","slug":"人物扫光","date":"2022-01-21T10:38:45.000Z","updated":"2022-04-30T07:30:57.111Z","comments":true,"path":"2022/01/21/人物扫光/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/01/21/%E4%BA%BA%E7%89%A9%E6%89%AB%E5%85%89/","excerpt":"","text":"过程边缘光 流光 总结当一个三维向量补全为四维向量的时候，如果是点的话最后需要补成1.0，如果是向量的话需要补0.0","categories":[{"name":"游戏","slug":"游戏","permalink":"https://mrchenlearnspace.github.io/categories/%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"Shader","slug":"Shader","permalink":"https://mrchenlearnspace.github.io/tags/Shader/"}]},{"title":"Unity升级管线的注意事项","slug":"Unity升级管线的注意事项","date":"2022-01-18T15:38:45.000Z","updated":"2022-11-14T14:25:19.191Z","comments":true,"path":"2022/01/18/Unity升级管线的注意事项/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/01/18/Unity%E5%8D%87%E7%BA%A7%E7%AE%A1%E7%BA%BF%E7%9A%84%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/","excerpt":"","text":"升级渲染管线在PM中下载 Universal RP 材质记得替，不如会出现洋红色 使用的简单的建模工具 在pm包中有不错的东西 在游戏中进行简单的建模可以用ProBuilder和Polybrush这两个包进行修改地形的顶点 ProGrids做方格的校准 阴影部分百人计划说的很详细了 简单着色样例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107Shader &quot;CustomLit&quot;&#123; Properties &#123; _MainTex(&quot;主贴图&quot;, 2D) = &quot;white&quot; &#123;&#125; &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot; = &quot;Transparent&quot; &quot;Queue&quot; = &quot;Transparent&quot; &#125; Pass &#123; Blend SrcAlpha OneMinusSrcAlpha Tags &#123; &quot;LightMode&quot; = &quot;UniversalForward&quot; &#125; //Zwrite off HLSLPROGRAM #pragma vertex vert #pragma fragment frag #pragma multi_compile _ _MAIN_LIGHT_SHADOWS #pragma multi_compile _ _MAIN_LIGHT_SHADOWS_CASCADE #pragma multi_compile _ Anti_Aliasing_ON #include &quot;Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl&quot; #include &quot;Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl&quot; struct appdata &#123; float4 vertex : POSITION; float4 uv : TEXCOORD0; &#125;; struct v2f &#123; float4 pos : SV_POSITION; float2 uv : TEXCOORD0; float3 worldPos : TEXCOORD1; &#125;; sampler2D _MainTex; float4 _MainTex_ST; v2f vert(appdata v) &#123; v2f o; o.pos = mul(UNITY_MATRIX_MVP, v.vertex); o.worldPos = mul(unity_ObjectToWorld, v.vertex); o.uv = TRANSFORM_TEX(v.uv, _MainTex); return o; &#125; float4 _Color; float4 frag(v2f i) : SV_Target &#123; float4 SHADOW_COORDS = TransformWorldToShadowCoord(i.worldPos); Light mainLight = GetMainLight(SHADOW_COORDS); half shadow = MainLightRealtimeShadow(SHADOW_COORDS); return float4(shadow, shadow, shadow,1); &#125; ENDHLSL &#125; UsePass &quot;Universal Render Pipeline/Lit/ShadowCaster&quot; //pass &#123; // Name &quot;ShadowCast&quot; // Tags&#123; &quot;LightMode&quot; = &quot;ShadowCaster&quot; &#125; // HLSLPROGRAM // #pragma vertex vert // #pragma fragment frag // #include &quot;Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl&quot; // struct appdata // &#123; // float4 vertex : POSITION; // &#125;; // struct v2f // &#123; // float4 pos : SV_POSITION; // &#125;; // sampler2D _MainTex; // float4 _MainTex_ST; // v2f vert(appdata v) // &#123; // v2f o; // o.pos = mul(UNITY_MATRIX_MVP, v.vertex); // return o; // &#125; // float4 frag(v2f i) : SV_Target // &#123; // float4 color; // color.xyz = float3(0.0, 0.0, 0.0); // return color; // &#125; // ENDHLSL //&#125; &#125;&#125; HDR解码函数由于hlsl函数没有了。 12345678910111213141516 half3 DecodeHDR (half4 data, half4 decodeInstructions) &#123; // Take into account texture alpha if decodeInstructions.w is true(the alpha value affects the RGB channels) half alpha = decodeInstructions.w * (data.a - 1.0) + 1.0 ; // If Linear mode is not supported we can skip exponent part #if defined (UNITY_COLORSPACE_GAMMA) return (decodeInstructions.x * alpha) * data.rgb; #else #if defined (UNITY_USE_NATIVE_HDR) return decodeInstructions.x * data.rgb; // Multiplier for future HDRI relative to absolute conversion. #else return (decodeInstructions.x * pow (alpha, decodeInstructions.y)) * data.rgb; #endif #endif&#125;","categories":[{"name":"升级渲染管线","slug":"升级渲染管线","permalink":"https://mrchenlearnspace.github.io/categories/%E5%8D%87%E7%BA%A7%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/"},{"name":"游戏","slug":"升级渲染管线/游戏","permalink":"https://mrchenlearnspace.github.io/categories/%E5%8D%87%E7%BA%A7%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"Unity","slug":"Unity","permalink":"https://mrchenlearnspace.github.io/tags/Unity/"}]},{"title":"UnityShader入门","slug":"UnityShader入门","date":"2022-01-09T16:23:45.000Z","updated":"2022-11-14T14:25:24.784Z","comments":true,"path":"2022/01/10/UnityShader入门/","link":"","permalink":"https://mrchenlearnspace.github.io/2022/01/10/UnityShader%E5%85%A5%E9%97%A8/","excerpt":"","text":"总结基本操作平铺和偏移1234567//properties_Texture(&quot;Texture&quot;,2D)=&quot;white&quot;&#123;&#125;//SubPass/Passsampler2D _Texture;float4 _Texture_ST; o.uv=v.uv*_Texture_ST.xy+_Texture_ST.zw; 顶点坐标系MVP转换1234float4 pos_world = mul(unity_ObjectToWorld, v.vertex);float4 pos_view = mul(UNITY_MATRIX_V,pos_world);float4 pos_clip = mul(UNITY_MATRIX_P,pos_view);o.pos=pos_clip; 或者 1o.pos=UnityObjectToClipPos(v.vertex); CG变量用法123float = 32//坐标half = 16//uv，大部分向量fixed =8//颜色 图像处理面剔除单独写死1Cull off 在面板上显示12[Enum(UnityEngine.Rendering.CullMode)]_CullMode(&quot;CullMode&quot;,Float)=2//PropertiesCull [_CullMode]//SubPass/Pass 图片铺在模型上图片将平铺到x与y组成的平面上 1o.uv=v.vertex.xy*_Texture_ST.xy+_Texture_ST.zw; xy变成yx时 相当与x轴旋转180度y轴旋转-90度 1o.uv=v.vertex.yx*_Texture_ST.xy+_Texture_ST.zw; 1float4 pos_world = mul(unity_ObjectToWorld, v.vertex); 加面解决圆面失真的问题 水波的制作先制作动态圆盘123456_Float(&quot;Float&quot;,Float)=0.0_Vector(&quot;Vector&quot;,Vector)=(1,1,1,1)_Texture(&quot;Texture&quot;,2D)=&quot;white&quot;&#123;&#125;//Propertieshalf gradient=tex2D(_Texture,i.uv+_Time.y*_Vector.xy).x;clip(gradient-_Float);return gradient.xxxx;//fragment 噪声123_NoiseTex(&quot;NoiseTex&quot;,2D)=&quot;white&quot;&#123;&#125;//Propertieshalf noise=1.0f-tex2D(_NoiseTex,i.uv+_Time.y*_Vector.wz).x;clip(gradient-_Float-noise);//fragment 完善颜色,完整代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960Shader&quot;MyShader/03shader&quot;&#123; Properties&#123; _Float(&quot;Float&quot;,Float)=0.0 _Range(&quot;Range&quot;,Range(0,1))=0.0 _Vector(&quot;Vector&quot;,Vector)=(1,1,1,1) _Color(&quot;Color&quot;,Color)=(0.5,0.5,0.5,0.5) _Texture(&quot;Texture&quot;,2D)=&quot;white&quot;&#123;&#125; _NoiseTex(&quot;NoiseTex&quot;,2D)=&quot;white&quot;&#123;&#125; [Enum(UnityEngine.Rendering.CullMode)]_CullMode(&quot;CullMode&quot;,Float)=2 &#125; SubShader&#123; Pass&#123; Cull [_CullMode] CGPROGRAM #pragma vertex vert #pragma fragment frag #include&quot;UnityCG.cginc&quot; struct appdata&#123; float4 vertex:POSITION; float2 uv:TEXCOORD0; // float4 color:COLOR; &#125;; struct v2f&#123; float4 pos:SV_POSITION; float2 uv:TEXCOORD0; &#125;; sampler2D _Texture; float4 _Texture_ST; float _Float; float4 _Vector; sampler2D _NoiseTex; float2 _NoiseTex_ST; fixed4 _Color; v2f vert(appdata v) &#123; v2f o; float4 pos_world = mul(unity_ObjectToWorld, v.vertex); float4 pos_view = mul(UNITY_MATRIX_V,pos_world); float4 pos_clip = mul(UNITY_MATRIX_P,pos_view); //o.pos=pos_clip; o.pos=UnityObjectToClipPos(v.vertex); o.uv=v.uv.xy*_Texture_ST.xy+_Texture_ST.zw; return o; &#125; half4 frag(v2f i):SV_Target &#123; half gradient=tex2D(_Texture,i.uv+_Time.y*_Vector.xy).x; half noise=1.0f-tex2D(_NoiseTex,i.uv+_Time.y*_Vector.wz).x; clip(gradient-_Float-noise); return _Color; &#125; ENDCG &#125; &#125;&#125; 半透明混合参数意思 one 此输入的值是 one。该值用于使用源或目标的颜色的值。 Zero 此输入的值是 zero。该值用于删除源或目标值。 SrcColor GPU 将此输入的值乘以源颜色值。 SrcAlpha GPU 将此输入的值乘以源 Alpha 值。 DstColor GPU 将此输入的值乘以帧缓冲区的源颜色值。 DstAlpha GPU 将此输入的值乘以帧缓冲区的源 Alpha 值。 OneMinusSrcColor GPU 将此输入的值乘以（1 - 源颜色）。 OneMinusSrcAlpha GPU 将此输入的值乘以（1 - 源 Alpha）。 OneMinusDstColor GPU 将此输入的值乘以（1 - 目标颜色）。 OneMinusDstAlpha GPU 将此输入的值乘以（1 - 目标 Alpha）。 常见混合类型12345678Blend SrcAlpha OneMinusSrcAlpha // 传统透明度Blend SrcAlpha One//以上两种常用Blend One OneMinusSrcAlpha // 预乘透明度Blend One One // 加法Blend OneMinusDstColor One // 软加法Blend DstColor Zero // 乘法Blend DstColor SrcColor // 2x 乘法 代码修改1Tags &#123; &quot;Queue&quot; = &quot;Transparent&quot; &#125; 12ZWrite OffBlend SrcAlpha One//预乘透明度 123half3 col=_Color.xyz*_Float;half alpha=saturate(tex2D(_Texture,i.uv).r*_Color.a*_Float);return half4(col,alpha); 边缘光(fresnel)简版的菲涅尔方程菲涅尔边缘光实现口述： 菲涅耳系数&#x3D;pow (1.0f-saturate(dot(世界坐标到局部坐标的法线向量,世界坐标的顶点到摄像头的单位向量)) ,梯度系数) 123o.normal_world=normalize( mul(float4(v.normal,0),unity_WorldToObject));//世界坐标到局部坐标的法线向量float4 pos_world = mul(unity_ObjectToWorld, v.vertex);o.view_world=normalize(_WorldSpaceCameraPos.xyz-pos_world);//世界坐标的顶点到摄像头的单位向量 12345678float3 normal_world=normalize(i.normal_world);float3 view_world=normalize(i.view_world);//光栅化后向量需要标准化float NdotV=saturate(dot(normal_world,view_world));half3 col=_Color.xyz*_Float;float fresnel=pow(1.0f-NdotV,_Rim);//菲涅尔系数half alpha=saturate(_Float*fresnel);return half4(col,alpha); 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647Pass&#123; ZWrite Off Blend SrcAlpha One//预乘透明度 Cull [_CullMode] CGPROGRAM #pragma vertex vert #pragma fragment frag #include&quot;UnityCG.cginc&quot; struct appdata&#123; float4 vertex:POSITION; float2 uv:TEXCOORD0; float3 normal:NORMAL; // float4 color:COLOR; &#125;; struct v2f&#123; float4 pos:SV_POSITION; float2 uv:TEXCOORD0; float3 normal_world:TEXCOORD1; float3 view_world:TEXCOORD2; &#125;; sampler2D _Texture; float4 _Texture_ST; fixed4 _Color; float _Float; float _Rim; v2f vert(appdata v) &#123; v2f o; o.pos=UnityObjectToClipPos(v.vertex); o.normal_world=normalize( mul(float4(v.normal,0),unity_WorldToObject)); float4 pos_world = mul(unity_ObjectToWorld, v.vertex); o.view_world=normalize(_WorldSpaceCameraPos.xyz-pos_world); o.uv=v.uv*_Texture_ST.xy+_Texture_ST.zw; return o; &#125; half4 frag(v2f i):SV_Target &#123; float3 normal_world=normalize(i.normal_world); float3 view_world=normalize(i.view_world); float NdotV=saturate(dot(normal_world,view_world)); half3 col=_Color.xyz*_Float; float fresnel=pow(1.0f-NdotV,_Rim); half alpha=saturate(_Float*fresnel); return half4(col,alpha); &#125; 预先写深度修除内部透明小Bug，预先将前面的深度写入，但不写入颜色信息，用上面的pass第二遍时将后面的透明的给剔除掉， 1234567891011121314151617181920Pass &#123; Cull Off ZWrite On //深度写入 ColorMask 0//不写颜色信息 CGPROGRAM float4 _Color; #pragma vertex vert #pragma fragment frag float4 vert(float4 vertexPos : POSITION) : SV_POSITION &#123; return UnityObjectToClipPos(vertexPos); &#125; float4 frag(void) : COLOR &#123; return _Color; &#125; ENDCG &#125;","categories":[{"name":"计算机图形学","slug":"计算机图形学","permalink":"https://mrchenlearnspace.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"Unity","slug":"计算机图形学/Unity","permalink":"https://mrchenlearnspace.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/Unity/"},{"name":"游戏","slug":"计算机图形学/Unity/游戏","permalink":"https://mrchenlearnspace.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/Unity/%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"Shader","slug":"Shader","permalink":"https://mrchenlearnspace.github.io/tags/Shader/"}]},{"title":"OpenGL学习之路之光源大总结","slug":"OpenGL学习之路之光源大总结","date":"2021-12-19T10:38:45.000Z","updated":"2022-11-14T14:24:40.816Z","comments":true,"path":"2021/12/19/OpenGL学习之路之光源大总结/","link":"","permalink":"https://mrchenlearnspace.github.io/2021/12/19/OpenGL%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E4%B9%8B%E5%85%89%E6%BA%90%E5%A4%A7%E6%80%BB%E7%BB%93/","excerpt":"","text":"光源所需条件1.光照信息定向光 点光源 聚光灯的属性 2.法线向量将顶点着色器的法线信息接收，并进行标准化 1vec3 uNormal=normalize(Normal); 3.片元到摄像头的位置1vec3 dirToCamera=normalize(cameraPos-FragPos); 定向光主要光照信息12345struct LightDirectional&#123; vec3 pos;//光源坐标 vec3 color;//光颜色 vec3 dirToLight;//光照角度&#125;; 特点不需要光照衰弱，光照与位置无关 diffuse12diffuseIntersity=max(dot(light.dirToLight,Normal),0);diffuse=diffuseIntersity*light.color*texture(material.diffuse,TexCoord).rgb; specular12specularIntersity=pow(max(dot(normalize(reflect(-light.dirToLight,Normal)),dirToCamera),0),material.shininess);vec3 specular=specularIntersity*light.color*texture(material.specular,TexCoord).rgb; 点光源主要光照信息12345678struct LightPoint&#123; vec3 pos; vec3 color; vec3 dirToLight;//用不上 float constant;//1.0f float linear;//0.09f float quadratic;//0.032f&#125;; 特点与光照方向无关 attenuation12float distantes=length(light.pos-FragPos);float attenuation=1.0f/light.constant+light.linear*distantes+light.quadratic*distantes*distantes; diffuse12diffuseInyersity=max(dot(normalize(light.pos-FragPos),Normal),0);vec3 diffuse=diffuseIntensity*texture(material.diffuse,TexCoord).rgb*light.color; specular12float specularIntersity=pow(max(dot(normalize(reflect(-normalize(light.pos-FragPos),uNormal)),dirToCamera),0),material.shininess); vec3 specular=specularIntersity*light.color*texture(material.specular,TexCoord).rgb; 聚光灯主要光照信息12345678910struct LightSpot&#123; vec3 pos; vec3 color; vec3 dirToLight;//有用 float constant; float linear; float quadratic; float cosPhyInner; float cosPhyOutter;&#125;; 特点边缘模糊化，对比点光源需要会受角度影响 代码123456789101112131415161718192021222324252627282930vec3 result=vec3(0,0,0);//attenuationfloat distances= length(light.pos - FragPos);float attenuation=1.0f/(light.constant+light.linear*distances+light.quadratic*distances*distances);float spotRatio=0;float cosTheta=dot(normalize(FragPos-light.pos),-1.0f*light.dirToLight);//cosTheta=1;if(cosTheta &gt; light.cosPhyInner)&#123; spotRatio=1.0f;&#125;else if(cosTheta &gt; light.cosPhyOutter)&#123; //spotRatio=1.0f-(cosTheta-light.cosPhyInner)/(light.cosPhyOutter-light.cosPhyInner); spotRatio=(light.cosPhyOutter-cosTheta)/(light.cosPhyOutter - light.cosPhyInner);&#125;else&#123; spotRatio=0.0f;&#125;attenuation*=spotRatio;//diffusefloat diffuseIntensity=max(dot(normalize(light.pos-FragPos),uNormal),0);vec3 diffuse=texture(material.diffuse,TexCoord).rgb*light.color*diffuseIntensity;result+=diffuse;//specularfloat specularIntersity=pow(max(dot(normalize(reflect(-normalize(light.pos-FragPos),uNormal)),dirToCamera),0),material.shininess);vec3 specular = specularIntersity*texture(material.specular,TexCoord).rgb*light.color;result+=specular;//result*=attenuation;result*=spotRatio;return result;","categories":[{"name":"计算机图形学","slug":"计算机图形学","permalink":"https://mrchenlearnspace.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}],"tags":[{"name":"OpenGL","slug":"OpenGL","permalink":"https://mrchenlearnspace.github.io/tags/OpenGL/"}]},{"title":"OpenGL学习之路之光照贴图","slug":"OpenGL学习之路之光照贴图","date":"2021-12-07T11:30:45.000Z","updated":"2022-06-27T18:04:42.046Z","comments":true,"path":"2021/12/07/OpenGL学习之路之光照贴图/","link":"","permalink":"https://mrchenlearnspace.github.io/2021/12/07/OpenGL%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E4%B9%8B%E5%85%89%E7%85%A7%E8%B4%B4%E5%9B%BE/","excerpt":"","text":"Phong光照模型效果混合相加：diffuse + ambient + specular 图片混和相乘：(diffuse + ambient + specular) * objColor 1FragColor =vec4((diffuse + ambient + specular) * objColor,1.0f); 环境光–ambientambient具体能表现无光照区域的颜色，在物体较暗的部分加上漫反射贴图会更真实 1vec3 ambient=texture(material.diffuse, TexCoord).rgb * ambientColor; 漫反射贴图—diffuse出现的大概像表面的纹理像木箱的表面，相当于简单反射到眼睛的获得的颜色 12vec3 diffuse=texture(material.diffuse,TexCoord).rgb * max( dot( lightDir, Normal), 0) * lightColor; //vec3 diffuse=texture(material.diffuse,TexCoord).rgb; 镜面反射—specular可以将光照和高光进行反射，提高真实度 123vec3 reflectVec=reflect(-lightDir,Normal);float specularAmount=pow(max(dot(reflectVec,cameraVec),0),material.shininess); //高光的集中度，倍数越高，同一视角高光点越小vec3 specular=texture(material.specular,TexCoord).rgb * specularAmount * lightColor;//镜面反射图中为数值0或者为黑色表示不需要镜面反射，木块和铁最好对比 发射光贴图—emission1vec3 emission=texture(material.emission,TexCoord).rgb;","categories":[{"name":"计算机图形学","slug":"计算机图形学","permalink":"https://mrchenlearnspace.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}],"tags":[{"name":"OpenGL","slug":"OpenGL","permalink":"https://mrchenlearnspace.github.io/tags/OpenGL/"}]},{"title":"OpenGL学习之路之三角形绘制","slug":"OpenGL学习之路之三角形绘制","date":"2021-11-02T12:38:45.000Z","updated":"2022-03-21T03:09:44.460Z","comments":true,"path":"2021/11/02/OpenGL学习之路之三角形绘制/","link":"","permalink":"https://mrchenlearnspace.github.io/2021/11/02/OpenGL%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E4%B9%8B%E4%B8%89%E8%A7%92%E5%BD%A2%E7%BB%98%E5%88%B6/","excerpt":"","text":"先从几何阶段取出顶点转换成vbo转到vao如果有重复顶点可以转到EBoopenGL是一个状态机只能运行context的状态只能放一个vao状态机中必须要一个vao VAO123 unsigned int VAO;glGenVertexArrays(1, &amp;VAO);glBindVertexArray(VAO);//注意 VBO1234unsigned int VBO;glGenBuffers(1, &amp;VBO);//一个缓冲ID生成一个VBO对象建立顶点缓冲对象glBindBuffer(GL_ARRAY_BUFFER, VBO);//新创建的缓冲绑定到GL_ARRAY_BUFFER目标glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW);//它会把之前定义的顶点数据复制到缓冲的内存中 一定要绑定顶点数组 shader顶点着色器 1234 unsigned int vertexShader;vertexShader = glCreateShader(GL_VERTEX_SHADER);//由于我们正在创建一个顶点着色器，传递的参数是GL_VERTEX_SHADERglShaderSource(vertexShader, 1, &amp;vertexShaderSource, NULL);//这个着色器源码附加到着色器对象上glCompileShader(vertexShader);//编译着色器 片段着色器 1234unsigned int fragmentShader;fragmentShader = glCreateShader(GL_FRAGMENT_SHADER);glShaderSource(fragmentShader, 1, &amp;fragmentShaderSource, NULL);glCompileShader(fragmentShader); 着色器程序 1234567 unsigned int shaderProgram;shaderProgram = glCreateProgram();//建立着色器程序对象glAttachShader(shaderProgram, vertexShader);glAttachShader(shaderProgram, fragmentShader);//附加着色器glLinkProgram(shaderProgram);//连接着色器glDeleteShader(vertexShader);//着色器对象链接到程序对象以后，记得删除着色器对象，我们不再需要它们了glDeleteShader(fragmentShader); 序列化数据，可以得到数据的属性，是uv图片还是顶点信息 12glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0);glEnableVertexAttribArray(0); EBO的使用需要加人索引unsigned int indices[] &#x3D; { &#x2F;&#x2F; 注意索引从0开始! 0, 1, 3, &#x2F;&#x2F; 第一个三角形 1, 2, 3 &#x2F;&#x2F; 第二个三角形};来确定三角形放发与VBO类似当有点点区别绑定缓存时GL_ELEMENT_ARRAY_BUFFER， 1glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, EBO); 绑定缓存数据的是索引值 1glBufferData(GL_ELEMENT_ARRAY_BUFFER, sizeof(indices), indices, GL_STATIC_DRAW); 在具体绘画过程中 12glDrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_INT, 0); glBindVertexArray(0);//这是vao没有的 用的函数也是和VAO绘制有区别的三角形不用EBO的代码 四边形代码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163#define GLEW_STATIC#include&lt;GL/glew.h&gt;#include&lt;GLFW/glfw3.h&gt;#include&lt;iostream&gt;void CheckCompileShaderSuccess(unsigned int vertexShader);//检查着色器是否编译成功void CheckLinkShaderSuccess(unsigned int shaderProgram);void framebuffer_size_callback(GLFWwindow* window, int width, int height);void processInput(GLFWwindow* window);//float vertices[] = &#123;// -0.5f, -0.5f, 0.0f,// 0.5f, -0.5f, 0.0f,// 0.0f, 0.5f, 0.0f//&#125;;float vertices[] = &#123; 0.5f, 0.5f, 0.0f, // 右上角 0.5f, -0.5f, 0.0f, // 右下角 -0.5f, -0.5f, 0.0f, // 左下角 -0.5f, 0.5f, 0.0f // 左上角&#125;;unsigned int indices[] = &#123; // 注意索引从0开始! 0, 1, 3, // 第一个三角形 1, 2, 3 // 第二个三角形&#125;;const char* vertexShaderSource =&quot;#version 330 core\\n&quot;&quot;layout(location = 0) in vec3 aPos;\\n&quot;&quot;void main()&#123;\\n&quot;&quot; gl_Position = vec4(aPos.x, aPos.y, aPos.z, 1.0);&#125;\\n&quot;;const char* fragmentShaderSource =&quot;#version 330 core\\n&quot;&quot;out vec4 FragColor;\\n;&quot;&quot;void main()&#123;\\n&quot;&quot; FragColor=vec4(1.0f,0.5f,0.2f,1.0f);&#125;\\n&quot;;int main()&#123; glfwInit(); glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 3); glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 3); glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE); //glfwWindowHint(GLFW_OPENGL_FORWARD_COMPAT, GL_TRUE);MacOSX系统加上这一句 //以上是初始化Glfw，说明我们要使用的OPENGL版本是3.3，我们同样明确告诉GLFW我们使用的是核心模式(Core-profile)。明确告诉GLFW我们需要使用核心模式意味着我们只能使用OpenGL功能的一个子集。 GLFWwindow* window = glfwCreateWindow(800, 600, &quot;LearnOPENGL&quot;, NULL, NULL);//前两个参数代表生成窗口大小 if (window == NULL) &#123; std::cout &lt;&lt; &quot;GLFW窗口初始化失败&quot; &lt;&lt; std::endl; glfwTerminate();//程序终止函数 return -1; &#125; glfwMakeContextCurrent(window); //GLFW初始化 glewExperimental = GL_TRUE; if (glewInit() != GLEW_OK) &#123; std::cout &lt;&lt; &quot;GLEW初始化失败&quot; &lt;&lt; std::endl; return -1; &#125; //Glew的初始化 glViewport(0, 0, 800, 600);//渲染窗口大小 glfwSetFramebufferSizeCallback(window, framebuffer_size_callback);//注册函数 unsigned int VAO; glGenVertexArrays(1, &amp;VAO); glBindVertexArray(VAO); //顶点数据绑定 unsigned int VBO; glGenBuffers(1, &amp;VBO);//一个缓冲ID生成一个VBO对象建立顶点缓冲对象 glBindBuffer(GL_ARRAY_BUFFER, VBO);//新创建的缓冲绑定到GL_ARRAY_BUFFER目标 glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW);//它会把之前定义的顶点数据复制到缓冲的内存中 unsigned EBO; glGenBuffers(1, &amp;EBO); glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, EBO); glBufferData(GL_ELEMENT_ARRAY_BUFFER, sizeof(indices), indices, GL_STATIC_DRAW); //顶点着色器 unsigned int vertexShader; vertexShader = glCreateShader(GL_VERTEX_SHADER);//由于我们正在创建一个顶点着色器，传递的参数是GL_VERTEX_SHADER glShaderSource(vertexShader, 1, &amp;vertexShaderSource, NULL);//这个着色器源码附加到着色器对象上 glCompileShader(vertexShader);//编译着色器 CheckCompileShaderSuccess(vertexShader); //片段着色器 unsigned int fragmentShader; fragmentShader = glCreateShader(GL_FRAGMENT_SHADER); glShaderSource(fragmentShader, 1, &amp;fragmentShaderSource, NULL); glCompileShader(fragmentShader); //着色器程序 unsigned int shaderProgram; shaderProgram = glCreateProgram();//建立着色器程序对象 glAttachShader(shaderProgram, vertexShader); glAttachShader(shaderProgram, fragmentShader);//附加着色器 glLinkProgram(shaderProgram);//连接着色器 CheckLinkShaderSuccess(shaderProgram); glDeleteShader(vertexShader);//着色器对象链接到程序对象以后，记得删除着色器对象，我们不再需要它们了 glDeleteShader(fragmentShader); glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0); glEnableVertexAttribArray(0); while (!glfwWindowShouldClose(window)) &#123; //输入 processInput(window); //渲染指令 glClearColor(0.2f, 0.3f, 0.3f, 1.0f);//来设置清空屏幕所用的颜色,表示清除板的颜色 glClear(GL_COLOR_BUFFER_BIT);//清除颜色缓冲之后 glUseProgram(shaderProgram);//调用着色器 glBindVertexArray(VAO); //glDrawArrays(GL_TRIANGLES, 0, 3); glBindVertexArray(EBO); glDrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_INT, 0); glBindVertexArray(0);//这是vao没有的 //检查并调用事件，交换缓冲 glfwSwapBuffers(window);//进行屏幕缓冲 glfwPollEvents();//检查函数有没有触发事件 &#125; glfwTerminate(); return 0;&#125;void framebuffer_size_callback(GLFWwindow* window, int width, int height)&#123; glViewport(0, 0, width, height);&#125;void processInput(GLFWwindow* window) &#123; //输入 if (glfwGetKey(window, GLFW_KEY_ESCAPE) == GLFW_PRESS) &#123; glfwSetWindowShouldClose(window, GLFW_TRUE); &#125;&#125;void CheckCompileShaderSuccess(unsigned int vertexShader) &#123; //检查着色器是否编译成功 int success; char infoLog[512]; glGetShaderiv(vertexShader, GL_COMPILE_STATUS, &amp;success); if (!success) &#123; glGetShaderInfoLog(vertexShader, 512, NULL, infoLog); std::cout &lt;&lt; &quot;ERROR::SHADER::VERTEX::COMPILATION_FAILED\\n&quot; &lt;&lt; infoLog &lt;&lt; std::endl; &#125;&#125;void CheckLinkShaderSuccess(unsigned int shaderProgram) &#123; //检查shaderProgram连接成功 int success; char infoLog[512]; glGetProgramiv(shaderProgram, GL_LINK_STATUS, &amp;success); if (!success) &#123; glGetProgramInfoLog(shaderProgram, 512, NULL, infoLog); std::cout &lt;&lt; &quot;ERROR::SHADER::Program::Link_FAILED\\n&quot; &lt;&lt; infoLog &lt;&lt; std::endl; &#125;&#125;","categories":[{"name":"计算机图形学","slug":"计算机图形学","permalink":"https://mrchenlearnspace.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}],"tags":[{"name":"OpenGL","slug":"OpenGL","permalink":"https://mrchenlearnspace.github.io/tags/OpenGL/"}]},{"title":"OpenGL学习之路之窗口的建立","slug":"OpenGL学习之路之窗口的建立","date":"2021-11-02T10:38:45.000Z","updated":"2022-03-21T03:05:48.923Z","comments":true,"path":"2021/11/02/OpenGL学习之路之窗口的建立/","link":"","permalink":"https://mrchenlearnspace.github.io/2021/11/02/OpenGL%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%E4%B9%8B%E7%AA%97%E5%8F%A3%E7%9A%84%E5%BB%BA%E7%AB%8B/","excerpt":"","text":"环境配置先建立一个空项目，建立一个c++文件，然后设置解决方案的属性设置三个位置第一是c&#x2F;c++\\常规\\附加包含目录加入include的文件夹，glfw和glew都需要，第二，链接器\\常规\\附加库目录，lib文件夹，第三，链接器\\输入\\附加依赖库，opengl32.lib glfw3.lib glew32s.lib 创建自己的引擎将文件修改为main作为主函数 1#define GLEW_STATIC 这个注意小心拼写错误，本人搞了几小时 初始化声明版本号1234glfwInit(); glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 3); glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 3); glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE); 1glfwWindowHint(GLFW_OPENGL_FORWARD_COMPAT, GL_TRUE); MacOSX系统加上这一句以上是初始化Glfw，说明我们要使用的OPENGL版本是3.3，我们同样明确告诉GLFW我们使用的是核心模式(Core-profile)。明确告诉GLFW我们需要使用核心模式意味着我们只能使用OpenGL功能的一个子集。 创建窗口指针1GLFWwindow* window = glfwCreateWindow(800, 600, &quot;LearnOPENGL&quot;, NULL, NULL);//前两个参数代表生成窗口大小 接下来进行GLFW的初始化1234567if (window == NULL) &#123; std::cout &lt;&lt; &quot;GLFW窗口初始化失败&quot; &lt;&lt; std::endl; glfwTerminate();//程序终止函数 return -1; &#125;glfwMakeContextCurrent(window); 然后是GLEW的初始化123456glewExperimental = GL_TRUE; if (glewInit() != GLEW_OK) &#123; std::cout &lt;&lt; &quot;GLEW初始化失败&quot; &lt;&lt; std::endl; return -1; &#125; 确定渲染窗口123456glViewport(0, 0, 800, 600);//渲染窗口大小glfwSetFramebufferSizeCallback(window,framebuffer_size_callback);//注册函数void framebuffer_size_callback(GLFWwindow* window, int width, int height)&#123; glViewport(0, 0, width, height);&#125; framebuffer_size_callback自定义函数注册到当窗口大小改变的事件中能及时反映 确定基本架构1234567while(!glfwWindowShouldClose(window))&#123; //输入 //渲染指令 //检查并调用事件，交换缓冲 glfwSwapBuffers(window);//进行屏幕缓冲 glfwPollEvents();//检查函数有没有触发事件 &#125; 清理缓冲区颜色12glClearColor(0.2f, 0.3f, 0.3f, 1.0f);//来设置清空屏幕所用的颜色,表示清除板的颜色glClear(GL_COLOR_BUFFER_BIT);//清除颜色缓冲之后 输入1234567processInput(window)void processInput(GLFWwindow* window) &#123; //输入 if (glfwGetKey(window, GLFW_KEY_ESCAPE) == GLFW_PRESS) &#123; glfwSetWindowShouldClose(window, GLFW_TRUE); &#125;&#125; 代码如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#define GLEW_STATIC#include&lt;GL/glew.h&gt;#include&lt;GLFW/glfw3.h&gt;#include&lt;iostream&gt;void framebuffer_size_callback(GLFWwindow* window, int width, int height);void processInput(GLFWwindow* window);int main()&#123; glfwInit(); glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 3); glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 3); glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE); //glfwWindowHint(GLFW_OPENGL_FORWARD_COMPAT, GL_TRUE);MacOSX系统加上这一句 //以上是初始化Glfw，说明我们要使用的OPENGL版本是3.3，我们同样明确告诉GLFW我们使用的是核心模式(Core-profile)。明确告诉GLFW我们需要使用核心模式意味着我们只能使用OpenGL功能的一个子集。 GLFWwindow* window = glfwCreateWindow(800, 600, &quot;LearnOPENGL&quot;, NULL, NULL);//前两个参数代表生成窗口大小 if (window == NULL) &#123; std::cout &lt;&lt; &quot;GLFW窗口初始化失败&quot; &lt;&lt; std::endl; glfwTerminate();//程序终止函数 return -1; &#125; glfwMakeContextCurrent(window); //GLFW初始化 glewExperimental = GL_TRUE; if (glewInit() != GLEW_OK) &#123; std::cout &lt;&lt; &quot;GLEW初始化失败&quot; &lt;&lt; std::endl; return -1; &#125; //Glew的初始化 glViewport(0, 0, 800, 600);//渲染窗口大小 glfwSetFramebufferSizeCallback(window,framebuffer_size_callback);//注册函数 while(!glfwWindowShouldClose(window)) &#123; //输入 processInput(window); //渲染指令 glClearColor(0.2f, 0.3f, 0.3f, 1.0f);//来设置清空屏幕所用的颜色,表示清除板的颜色 glClear(GL_COLOR_BUFFER_BIT);//清除颜色缓冲之后 //检查并调用事件，交换缓冲 glfwSwapBuffers(window);//进行屏幕缓冲 glfwPollEvents();//检查函数有没有触发事件 &#125; glfwTerminate(); return 0;&#125;void framebuffer_size_callback(GLFWwindow* window, int width, int height)&#123; glViewport(0, 0, width, height);&#125;void processInput(GLFWwindow* window) &#123; //输入 if (glfwGetKey(window, GLFW_KEY_ESCAPE) == GLFW_PRESS) &#123; glfwSetWindowShouldClose(window, GLFW_TRUE); &#125;&#125;","categories":[{"name":"计算机图形学","slug":"计算机图形学","permalink":"https://mrchenlearnspace.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}],"tags":[{"name":"OpenGL","slug":"OpenGL","permalink":"https://mrchenlearnspace.github.io/tags/OpenGL/"}]},{"title":"搭建博客","slug":"搭建博客","date":"2021-11-01T10:38:45.000Z","updated":"2022-11-14T14:24:14.491Z","comments":true,"path":"2021/11/01/搭建博客/","link":"","permalink":"https://mrchenlearnspace.github.io/2021/11/01/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/","excerpt":"","text":"博客搭建文档格式需要git，Node.js，npm 做好准备安装好软件，配置好相关的环境 建立一个github仓库，由于在部署时未设置配置建议改成 用户名.github.io,方便网站进入导致只打开一个html，与整个页面脱节的情况 寻找材料到Hexo中找相关喜欢的主题，并找到相应的开源的GitHub，先hexo init在空文件夹中初始化，导入相关主题，修改全局中的theme变量 修改配置https://hexo.io/zh-cn/docs/configuration具体配置连接 网站 参数 || 描述 title || 网站标题 subtitle || 网站副标题 description || 网站描述 keywords || 网站的关键词。支持多个关键词。 author || 您的名字 language || 网站使用的语言。对于简体中文用户来说，使用不同的主题可能需要设置成不同的值，请参考你的主题的文档自行设置，常见的有 zh-Hans和 zh-CN。 timezone || 网站时区。Hexo 默认使用您电脑的时区。请参考 时区列表 进行设置，如 America&#x2F;New_York, Japan, 和 UTC 。一般的，对于中国大陆地区可以使用 Asia&#x2F;Shanghai。 网址 url || 网址, 必须以 http:&#x2F;&#x2F; 或 https:&#x2F;&#x2F; 开头 root || 网站根目录 url’s pathname permalink || 文章的 永久链接 格式 :year&#x2F;:month&#x2F;:day&#x2F;:title&#x2F; permalink_defaults || 永久链接中各部分的默认值 pretty_urls || 改写 permalink 的值来美化 URL pretty_urls.trailing_index || 是否在永久链接中保留尾部的index.html，设置为 false 时去除 true pretty_urls.trailing_html 是否在永久链接中保留尾部的 .html, 设置为 false 时去除 (对尾部的 index.html无效) 网站存放在子目录如果您的网站存放在子目录中，例如 http://example.com/blog，则请将您的 url 设为 http://example.com/blog 并把 root 设为 &#x2F;blog&#x2F;。例如：# 比如，一个页面的永久链接是 http://example.com/foo/bar/index.htmlpretty_urls: trailing_index: false此时页面的永久链接会变为 http://example.com/foo/bar/ 目录参数 || 描述 || 默认值 source_dir || 资源文件夹，这个文件夹用来存放内容。|| source public_dir || 公共文件夹，这个文件夹用于存放生成的站点文件。|| public tag_dir || 标签文件夹 || tags archive_dir 归档文件夹 archives category_dir 分类文件夹 categories code_dir Include code 文件夹，source_dir 下的子目录 downloads&#x2F;code i18n_dir 国际化（i18n）文件夹 :lang skip_render 跳过指定文件的渲染。匹配到的文件将会被不做改动地复制到 public 目录中。您可使用 glob 表达式来匹配路径。 文章参数 描述 默认值 new_post_name 新文章的文件名称 :title.md default_layout 预设布局 post auto_spacing 在中文和英文之间加入空格 false titlecase 把标题转换为 title case false external_link 在新标签中打开链接 true external_link.enable 在新标签中打开链接 true external_link.field 对整个网站（site）生效或仅对文章（post）生效 site external_link.exclude 需要排除的域名。主域名和子域名如 www 需分别配置 [] filename_case 把文件名称转换为 (1) 小写或 (2) 大写 0 render_drafts 显示草稿 false post_asset_folder 启动 Asset 文件夹 false relative_link 把链接改为与根目录的相对位址 false future 显示未来的文章 true highlight 代码块的设置, 请参考 Highlight.js 进行设置 prismjs 代码块的设置, 请参考 PrismJS 进行设置 默认情况下，Hexo 生成的超链接都是绝对地址。例如，如果您的网站域名为 example.com,您有一篇文章名为 hello，那么绝对链接可能像这样：http://example.com/hello.html，它是绝对于域名的。相对链接像这样：/hello.html，也就是说，无论用什么域名访问该站点，都没有关系，这在进行反向代理时可能用到。通常情况下，建议使用绝对地址。 分类 &amp; 标签 参数 描述 默认值 default_category 默认分类 uncategorized category_map 分类别名 tag_map 标签别名 日期 &#x2F; 时间格式 参数 描述 默认值 date_format 日期格式 YYYY-MM-DD time_format 时间格式 HH:mm:ss updated_option 当 Front Matter 中没有指定 updated 时 updated 的取值 mtime updated_optionupdated_option 控制了当 Front Matter 中没有指定 updated 时，updated 如何取值： mtime: 使用文件的最后修改时间。这是从 Hexo 3.0.0 开始的默认行为。date: 使用 date 作为 updated 的值。可被用于 Git 工作流之中，因为使用 Git 管理站点时，文件的最后修改日期常常会发生改变empty: 直接删除 updated。使用这一选项可能会导致大部分主题和插件无法正常工作。use_date_for_updated 选项已经被废弃，将会在下个重大版本发布时去除。请改为使用 updated_option: ‘date’。 use_date_for_updated | 启用以后，如果 Front Matter 中没有指定 updated， post.updated 将会使用 date 的值而不是文件的创建时间。在 Git 工作流中这个选项会很有用 | true 分页 参数 描述 默认值 per_page 每页显示的文章量 (0 &#x3D; 关闭分页功能) 10 pagination_dir 分页目录 page 扩展参数 描述 theme 当前主题名称。值为false时禁用主题 theme_config 主题的配置文件。在这里放置的配置会覆盖主题目录下的 _config.yml 中的配置 deploy 部署部分的设置 meta_generator Meta generator 标签。 值为 false 时 Hexo 不会在头部插入该标签 特别注意，记得修改配置中的连接和主题 开始部署配置好配置中的部署部分 1234deploy: type: git repository: https://github.com/MrChenLreanSpace/MrChenLreanSpace.github.io.git branch: main 用 npm 安装好hexo-deployer-git. 1npm install hexo-deployer-git 有些加入搜索功能，需要插件 1npm install hexo-generator-searchdb --save 配置hexo全局配置文件（请将生成的索引文件放在网站根目录或修改主题js文件的path值） 12345search: path: search.xml field: post format: html limit: 10000 在主题配置文件启用本地搜索 1234#本地搜索,请将索引文件放在网站根目录local_search: #是否启用 enable: true 开始生成本地站点 1hexo g 本地测试 1hexo s 或者 hexo serve 完成之后，连上github，需要GitHub的令牌，令牌生成后记得记住密钥，之后会看不到令牌在设置的开发者选项中第三个第一次上传需要登入和用用户名和令牌连上账户 1hexo clean&amp;&amp;hexo d 清除本地文件且部署到GitHub上","categories":[{"name":"博客开始","slug":"博客开始","permalink":"https://mrchenlearnspace.github.io/categories/%E5%8D%9A%E5%AE%A2%E5%BC%80%E5%A7%8B/"}],"tags":[{"name":"标签和分类可以多个","slug":"标签和分类可以多个","permalink":"https://mrchenlearnspace.github.io/tags/%E6%A0%87%E7%AD%BE%E5%92%8C%E5%88%86%E7%B1%BB%E5%8F%AF%E4%BB%A5%E5%A4%9A%E4%B8%AA/"}]},{"title":"Hello World","slug":"hello-world","date":"2021-11-01T06:24:34.691Z","updated":"2022-03-13T15:18:28.912Z","comments":true,"path":"2021/11/01/hello-world/","link":"","permalink":"https://mrchenlearnspace.github.io/2021/11/01/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"学习记录","slug":"C++学习记录","date":"2020-03-01T08:38:45.000Z","updated":"2022-11-14T14:23:12.818Z","comments":true,"path":"2020/03/01/C++学习记录/","link":"","permalink":"https://mrchenlearnspace.github.io/2020/03/01/C++%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/","excerpt":"","text":"第七章流操纵算子需要头文件#include整数dec10，oct8，hex16，setbase小数点setiosflags(ios::fixed)或fixed浮点精度precision，setprecision取消小数点resetiosflags(ios::fixed)科学计数法scientific设置宽域setw，width非负数显示正号showpos()非负数不显示正号noshowpos()填充符号setfill(‘’)数字的位置left，right 模板templatea&#x2F;&#x2F;T就变成了某个数据类型 第八章string类赋值12345678910string s1(&quot;Hello&quot;);cout &lt;&lt;s1.length()&lt;&lt;endl;//string类型长度输出cout&lt;&lt;s1&lt;&lt;endl;string s2(8,&#x27;x&#x27;);//s2是8个xcout&lt;&lt;s2&lt;&lt;endl;string month=&quot;march&quot;;//直接赋值cout &lt;&lt; month&lt;&lt;endl;string s;s=&#x27;n&#x27;;//可以单个赋值cout&lt;&lt;s&lt;&lt;endl; string的复制12345string s1(&quot;Hello&quot;),s3;//直接复制 s3.assign(s1); cout&lt;&lt;s3&lt;&lt;endl; string s1(&quot;Hello&quot;),s2,s3; s3.assign(s1,2,3);//从s1的第2个复制3个字符，2形同下标 读取string的字符12s[0]//不会检测 ，可能会越界s.at(0)//越界编译不会出错，但结果会提示出错 string连接​ 1234567string s1(&quot;Hello&quot;),s2(&quot;morning&quot;);s1+=s2;//直接连接cout&lt;&lt;s1&lt;&lt;endl;s1.append(s2);//append连接cout&lt;&lt;s1&lt;&lt;endl;s2.append(s1,3,s1.size());//从s1的第3个复制s1.size()在s2的尾部 比较string可以直接比较用bool类型记录结果 123456string s1(&quot;hello&quot;),s2(&quot;hello&quot;),s3(&quot;hell&quot;); int f1=s1.compare(s2);//0 hello==hello int f2=s1.compare(s3);//1 hello&gt;hell int f3=s3.compare(s1);//-1 hell&lt;hello int f4=s1.compare(1,2,s3,0,3);//-1el&lt;hell 数字是代表下标 int f5=s1.compare(0,s1.size(),s3);//1 hello&gt;hell第一个数是下标，第二个数字是s1比较的数量 子串123string s1(&quot;hello world&quot;),s2;s2=s1.substr(4,5);//下标4开始的5个字符cout&lt;&lt;s2&lt;&lt;endl;//o wor 搜索find()12345678string s1(&quot;hello worlld&quot;); cout&lt;&lt;s1.find(&quot;ll&quot;)&lt;&lt;endl;//2 cout&lt;&lt;s1.find(&quot;abc&quot;)&lt;&lt;endl;//4294967295正序查找没有的话出现一个很大的数 cout&lt;&lt;s1.rfind(&quot;ll&quot;)&lt;&lt;endl;//9逆序查找 cout&lt;&lt;s1.find_first_of(&quot;abcde&quot;)&lt;&lt;endl;//1 abcde中第一个字符的下标位置 cout&lt;&lt;s1.find_last_of(&quot;abcde&quot;)&lt;&lt;endl;//11 abcde中最后一个字符下标位置 cout&lt;&lt;s1.find_first_not_of(&quot;abcde&quot;)&lt;&lt;endl;//0在字符串中不是abcde的下标位置 cout&lt;&lt;s1.find_last_not_of(&quot;abcde&quot;)&lt;&lt;endl;//10逆序在字符串中不是abcde的下标位置 删除string元素1s1.erase(5)//会去掉下标5之后的字符 替换string元素12s1.replace(2,3,&quot;hahah&quot;)//将s1下标为2到3的字符换成hahahs1.replace(2,3,&quot;hahah&quot;,1,2)//将s1下标为2到3的字符换成hahah的下标1开始的2个字符 插入string元素12s1.insert(5,s2)//将s2插入下标5的位置s1.insert(2,s2,5,3)//将s2中下标5开始的3个字符插入s1下标2的位置 成员函数c_str()12string s1(&quot;hello world&quot;);printf(&quot;%s\\n&quot;,s1.c_str());//s1.c_str()返回传统的const char*类型字符串，且该字符串以\\0结尾 data()12string s1(&quot;hello world&quot;);const char*p1=s1.data();//s1.data()返回char*类型的字符串，对s1的修改可能会使p1出错 STL库（一）容器：可容纳各种数据类型的通用数据结构，是类模板迭代器：可用于依次存取容器中的元素，类似于指针算法：用来操作容器中的元素的函数模板 容器1.顺序容器 vector动态数组 ，deque双向队列，list双向链表2.关联容器set multset map multmap3.容器适配器stack queue priority_queue 顺序容器vector动态数组头文件：常数时间尾部性能最佳 deque双向队列头文件：随机存取任何元素常数时间，但次于vector，两端删减性能最佳head头 tail尾，空元素 list双向链表头文件元素不能在内存不连续存放，在任何位置都能常数时间，不支持随机存取 关联容器元素是排序的插入任何元素，都是按相应的排序规则来确定其位置在查找时具有非常好的性能通常以平衡二叉树实现，时间logN set&#x2F;multiset头文件set不允许相同的元素，multiset允许相同的元素 map&#x2F;multimap头文件：一个名为first另一个名为second，multimap允许相同的first值 容器适配器stack头文件：栈，是项的有限序列只能修改删除检索最佳插入的项后进后出 queue头文件队列，插入只能从尾部，删除修改检索只能在头部进行先进先出 priority_queue头文件优先级队列，最高优先级的元素总是第一个出列 顺序容器和关联容器中都有的成员函数begin 返回指向容器中第一个元素的迭代器end 返回指向容器中最后一个元素后面的位置的迭代器rbegin返回指向容器中最后一个元素的迭代器rend返回指向容器中第一个元素前面位置的迭代器erase 从容器中删除一个或几个元素clear 从容器中删除所有元素 顺序容器的常用成员函数front 返回容器中第一个元素的引用back 返回容器中最后一个元素的引用push_back 在容器末尾增加新元素pop_back删除容器末尾的元素erase 删除迭代器指向的元素（可能会使该迭代器失效），或删除一个区间，返回那个元素的迭代器 STL库（二）迭代器用于指向顺序容器和关联容器的元素迭代器的用法和指针类似有const 和非const两种通过迭代器可以读取它指向的元素通过非const迭代器还能修改其指向的元素 定义迭代器容器类名::iterator 变量名;容器类名::const_iterator 变量名;&#x2F;&#x2F;常量迭代器访问迭代器指向的元素*迭代器变量名容器类名::reverse_iterator 变量;&#x2F;&#x2F;反向迭代器 STL库（三）所有的vector都适用于dequelist特有的成员函数push_front 在前面插入pop_front删除前面的元素sort 排序（list不支持stl的算法sort）remove 删除和指定值相同的所有元素unique 删除所有和前一个元素相同的元素（做到不重复需要unique之前需要sort）merge合并两个链表，并清空被合并的那个reverse 颠倒链表splice在指定位置前面插入另一个链表中的一个或多个元素，并在另一个链表删除被插入的元素lst1.splice(p1,lst2,p2,p3)&#x2F;&#x2F;将[p2,p3)插入p1之前，并从lst2中删除[p2,p3) 第九章set与multisetiterator find:查找等于某个值的元素iterator lower_bound:查找某个下界iterator upper_bound:查找某个上界equal_range: 同时查找上界和下界int count:计算等于某个值的元素个数void insert：插入某个元素或某个区间 map与multimap1直接赋值，例如 mp[“Tom”]&#x3D;02通过插入一个类型为 pair&lt;Key, T&gt; 的值，例如 mp.insert(pair&lt;string,int&gt;(“Alan”,100));map&lt;string, int&gt;::iterator it;&#x2F;&#x2F;迭代器cout &lt;&lt; iter-&gt;first &lt;&lt; “ “ &lt;&lt; iter-&gt;second &lt;&lt; endl;&#x2F;&#x2F;不能用iter.first但是可以重载&lt;&lt;template&lt;class Key,class Value&gt;ostream&amp;operator&lt;&lt;(ostream&amp;o,const pair&lt;Key,Value&gt;&amp;p){ o&lt;&lt;”(“&lt;&lt;p.first&lt;&lt;”,”&lt;&lt;p.second&lt;&lt;”)”;}cout&lt;&lt;*s;&#x2F;&#x2F;map专用 Stackpush 插入元素pop 弹出元素top 返回栈顶的元素的引用queuepush 插入元素发生在尾部pop 弹出元素对头top 返回栈顶的元素的引用对头back 返回栈顶的元素的引用尾部priority_queue保证优先级最大的在前面，保证最大的在前面size 还有多少数empty 是否空 算法1不变序列算法min 求两个对象中较小的1max 求两个对象较大的min_element求区间最小的1max_element求区间最大的&#x2F;&#x2F;1有点问题for_each对区间每个元素都做这种操作count计算区间等于某值的元素个数count_if计算区间符合某种条件的元素个数find在区间查找某值的元素find_if区间符合某种条件的元素find_end从区间查找另一个区间出现的最后一次位置find_first_of从区间查找另一个区间出现的第一次的元素adjacent_find从区间查找第一次出现连续两个相等元素的位置search在区间查找另一个区间第一次出现的位置search_n在区间查找第一次出现等于某值的连续n个元素equal判断两个区间是否相等mismatch逐个比较两个区间的元素，返回第一次发生不相等的位置lexicographical_compare按字典比较两个区间的大小 2.变值算法for_each 对区间中的每个元素都做某种操作copy复制一个区间到别处copy_backward复制一个区间到别处但目标区前是从后往前被修改的transform将一个区间的元素变形后拷贝到另一个区间&#x2F;&#x2F;迭代器swap_ranges交换两个区间的内容fill用某个值填充区间fill_n用某个值代替区间的n个元素generate用某个操作的结果填充区间generate_n用某个操作的结果替换区间中的n个元素replace将区间中某个值替换为另一个值replace_if将区间中符合某种条件的值替换成另一个值replace_copy将一个区间拷贝到另一个区间，拷贝时某个值要换成新值拷过去replace_copy_if将一个区间拷贝到另一个区间，拷贝时符合某种条件的值要换成新值拷过去 accumulate(first,last,累加的数);求和 3删除算法remove 删除区间中等于某个值的元素unique删除区间中连续相等的元素，只留下一个 4变序算法random_shuffle(first,last);随机打乱reverse 颠倒区间次序next_permutation将区间改为下一个排列prev_permutation将区间改为上一个排列&#x2F;&#x2F;可以list 5排序算法随机访问迭代器 不支持关联容器和listsort()从小到大排序 6有序区间算法要求是从小到大排好的随机访问迭代器 不支持关联容器和listbinary_search判断区间是否又某个元素lower_bound查找最后一个不小于某个值的元素的位置upper_bound查找第一个大于某个值的元素位置equal_range同时获取upper_bound，lower_bound 7bitsetbitset&amp;set();全部为1bitset&amp;set(size_t pos,bool val&#x3D;true);设置某位bitset&amp;reset();全部为0bitset&amp;reset(size_t pos);某位设为0bitset&amp;flip();全部翻转bitset&amp;flip(size_t pos)翻转某位 第十章c++11的新特性 数组，容器可以直接用花括号初始化. auto关键字迭代器的时候可以用auto decltype关键字返回数据类型 智能指针shared_ptr头文件会自动delete，不能是指针数组 空指针nullpr转化bool等于false 基于范围for循环int ary[]&#x3D;{1,2,3,4,5};for(int &amp;e:ary)e*&#x3D;10&#x2F;&#x2F;输出10，20，30，40，50* *右值引用&amp;&amp;是右值引用减少进行深拷贝的次数 无序容器（哈希表）头文件用法和map一样，效率更高 正则表达式 1234567891011121314头文件&lt;regex&gt;regex reg(&quot;b.?p.*k&quot;)regex_match//匹配成功1匹配失败010。lambda表达式[外部变量访问方式说明符](参数表)-&gt;返回值类型&#123; 语句组&#125;[=]以传值的方式使用外部变量[] 不使用任何外部变量[&amp;]以引用的方式使用所有的外部变量[x,&amp;y]x传值，有引用[=,&amp;x,&amp;y]x，y引用，其他传值[&amp;,x,y]x，y传值，其他引用 强制转换static_cast reinterpret_castconst_cast dynamic_cast1.static_cast用于整型，实数型，字符型static_cast&lt;类型&gt;(数)2.reinterpret_cast不同类型的指针之间的转换，不同类型的引用之间的转换3.const_cast去除const的转换4.dynamic_cast将多态基类的指针或引用强制转换为派生类的指针和引用必须是多态 异常处理try{throw 类型}处理catch(参数){}多个catch如果程序异常没有被catch捕获，程序崩溃catch(…){}属于任何异常exception类bad_typeid转换异常bad_cast多态基类指针转换异常bad_alloc在用new运算符进行动态内存分配时，没有足够的内存ios_base::failure bad_error–&gt;out_of_range下标越界 易错点继承可以将子类赋值给父类，在继承时注意需要加public才能让子类继承父类，不然父类就成了私有类了 123456class C :public A &#123;public: virtual void Print() &#123; cout &lt;&lt; &quot;Class C&quot; &lt;&lt; endl; &#125;&#125;; 多态override是在c++11的时候加的在c++中可以全用virtual也可以子类在函数名后加override 123456789101112 class B :public A &#123;public: void Print() override &#123; cout &lt;&lt; &quot;Class B&quot; &lt;&lt; endl; &#125;&#125;;class C :public A &#123;public: virtual void Print() &#123; cout &lt;&lt; &quot;Class C&quot; &lt;&lt; endl; &#125;&#125;; 用子类指针调用基类其一是强制转换但可以是不安全的 个人觉得其二还是有很大局限性的，需要基类要虚函数其二是用dynamic_cast将多态基类的指针或引用强制转换为派生类的指针和引用必须是多态","categories":[{"name":"编程","slug":"编程","permalink":"https://mrchenlearnspace.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://mrchenlearnspace.github.io/tags/C/"}]}],"categories":[{"name":"Unity","slug":"Unity","permalink":"https://mrchenlearnspace.github.io/categories/Unity/"},{"name":"编程","slug":"编程","permalink":"https://mrchenlearnspace.github.io/categories/%E7%BC%96%E7%A8%8B/"},{"name":"数据库","slug":"数据库","permalink":"https://mrchenlearnspace.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"游戏","slug":"游戏","permalink":"https://mrchenlearnspace.github.io/categories/%E6%B8%B8%E6%88%8F/"},{"name":"计算机图形学","slug":"计算机图形学","permalink":"https://mrchenlearnspace.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"Linux","slug":"Linux","permalink":"https://mrchenlearnspace.github.io/categories/Linux/"},{"name":"人工智能","slug":"人工智能","permalink":"https://mrchenlearnspace.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"升级渲染管线","slug":"升级渲染管线","permalink":"https://mrchenlearnspace.github.io/categories/%E5%8D%87%E7%BA%A7%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/"},{"name":"游戏","slug":"升级渲染管线/游戏","permalink":"https://mrchenlearnspace.github.io/categories/%E5%8D%87%E7%BA%A7%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/%E6%B8%B8%E6%88%8F/"},{"name":"Unity","slug":"计算机图形学/Unity","permalink":"https://mrchenlearnspace.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/Unity/"},{"name":"游戏","slug":"计算机图形学/Unity/游戏","permalink":"https://mrchenlearnspace.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/Unity/%E6%B8%B8%E6%88%8F/"},{"name":"博客开始","slug":"博客开始","permalink":"https://mrchenlearnspace.github.io/categories/%E5%8D%9A%E5%AE%A2%E5%BC%80%E5%A7%8B/"}],"tags":[{"name":"强化学习","slug":"强化学习","permalink":"https://mrchenlearnspace.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"},{"name":"正则表达式","slug":"正则表达式","permalink":"https://mrchenlearnspace.github.io/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"name":"服务器","slug":"服务器","permalink":"https://mrchenlearnspace.github.io/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"资源导入","slug":"资源导入","permalink":"https://mrchenlearnspace.github.io/tags/%E8%B5%84%E6%BA%90%E5%AF%BC%E5%85%A5/"},{"name":"网络","slug":"网络","permalink":"https://mrchenlearnspace.github.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"Shader","slug":"Shader","permalink":"https://mrchenlearnspace.github.io/tags/Shader/"},{"name":"游戏","slug":"游戏","permalink":"https://mrchenlearnspace.github.io/tags/%E6%B8%B8%E6%88%8F/"},{"name":"设计模式","slug":"设计模式","permalink":"https://mrchenlearnspace.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"引擎制作","slug":"引擎制作","permalink":"https://mrchenlearnspace.github.io/tags/%E5%BC%95%E6%93%8E%E5%88%B6%E4%BD%9C/"},{"name":"C++","slug":"C","permalink":"https://mrchenlearnspace.github.io/tags/C/"},{"name":"Imgui","slug":"Imgui","permalink":"https://mrchenlearnspace.github.io/tags/Imgui/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://mrchenlearnspace.github.io/tags/Ubuntu/"},{"name":"Ducker","slug":"Ducker","permalink":"https://mrchenlearnspace.github.io/tags/Ducker/"},{"name":"OpenCV","slug":"OpenCV","permalink":"https://mrchenlearnspace.github.io/tags/OpenCV/"},{"name":"全景图","slug":"全景图","permalink":"https://mrchenlearnspace.github.io/tags/%E5%85%A8%E6%99%AF%E5%9B%BE/"},{"name":"计算机视觉","slug":"计算机视觉","permalink":"https://mrchenlearnspace.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"},{"name":"Unity","slug":"Unity","permalink":"https://mrchenlearnspace.github.io/tags/Unity/"},{"name":"OpenGL","slug":"OpenGL","permalink":"https://mrchenlearnspace.github.io/tags/OpenGL/"},{"name":"标签和分类可以多个","slug":"标签和分类可以多个","permalink":"https://mrchenlearnspace.github.io/tags/%E6%A0%87%E7%AD%BE%E5%92%8C%E5%88%86%E7%B1%BB%E5%8F%AF%E4%BB%A5%E5%A4%9A%E4%B8%AA/"}]}